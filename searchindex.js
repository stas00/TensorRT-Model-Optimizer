Search.setIndex({"docnames": ["deployment/1_tensorrt_llm_deployment", "examples/0_all_examples", "examples/1_cifar_resnet", "examples/2_bert_prune_distill_quantize", "getting_started/1_overview", "getting_started/2_installation", "getting_started/3_quantization", "getting_started/4_pruning", "getting_started/5_distillation", "getting_started/6_sparsity", "guides/1_quantization", "guides/2_pruning", "guides/3_nas", "guides/4_distillation", "guides/5_sparsity", "guides/6_save_load", "guides/6_speculative_decoding", "guides/_basic_quantization", "guides/_choosing_quant_methods", "guides/_onnx_quantization", "guides/_pytorch_quantization", "index", "reference/0_changelog", "reference/1_modelopt_api", "reference/generated/modelopt.deploy", "reference/generated/modelopt.deploy.llm", "reference/generated/modelopt.deploy.llm.generate", "reference/generated/modelopt.deploy.llm.nemo_utils", "reference/generated/modelopt.onnx", "reference/generated/modelopt.onnx.op_types", "reference/generated/modelopt.onnx.quantization", "reference/generated/modelopt.onnx.quantization.calib_utils", "reference/generated/modelopt.onnx.quantization.extensions", "reference/generated/modelopt.onnx.quantization.fp8", "reference/generated/modelopt.onnx.quantization.graph_utils", "reference/generated/modelopt.onnx.quantization.gs_patching", "reference/generated/modelopt.onnx.quantization.int4", "reference/generated/modelopt.onnx.quantization.int8", "reference/generated/modelopt.onnx.quantization.operators", "reference/generated/modelopt.onnx.quantization.ort_patching", "reference/generated/modelopt.onnx.quantization.ort_utils", "reference/generated/modelopt.onnx.quantization.partitioning", "reference/generated/modelopt.onnx.quantization.qdq_utils", "reference/generated/modelopt.onnx.quantization.quant_utils", "reference/generated/modelopt.onnx.quantization.quantize", "reference/generated/modelopt.onnx.utils", "reference/generated/modelopt.torch", "reference/generated/modelopt.torch.distill", "reference/generated/modelopt.torch.distill.config", "reference/generated/modelopt.torch.distill.distillation", "reference/generated/modelopt.torch.distill.distillation_model", "reference/generated/modelopt.torch.distill.loss_balancers", "reference/generated/modelopt.torch.distill.losses", "reference/generated/modelopt.torch.distill.mode", "reference/generated/modelopt.torch.distill.registry", "reference/generated/modelopt.torch.export", "reference/generated/modelopt.torch.export.distribute", "reference/generated/modelopt.torch.export.hf_config_map", "reference/generated/modelopt.torch.export.layer_utils", "reference/generated/modelopt.torch.export.model_config", "reference/generated/modelopt.torch.export.model_config_export", "reference/generated/modelopt.torch.export.model_config_utils", "reference/generated/modelopt.torch.export.postprocess", "reference/generated/modelopt.torch.export.scaling_factor_utils", "reference/generated/modelopt.torch.export.tensorrt_llm_type", "reference/generated/modelopt.torch.export.tensorrt_llm_utils", "reference/generated/modelopt.torch.export.transformer_engine", "reference/generated/modelopt.torch.export.unified_export_hf", "reference/generated/modelopt.torch.export.vllm", "reference/generated/modelopt.torch.nas", "reference/generated/modelopt.torch.nas.algorithms", "reference/generated/modelopt.torch.nas.autonas", "reference/generated/modelopt.torch.nas.config", "reference/generated/modelopt.torch.nas.conversion", "reference/generated/modelopt.torch.nas.hparams", "reference/generated/modelopt.torch.nas.hparams.concat", "reference/generated/modelopt.torch.nas.hparams.container", "reference/generated/modelopt.torch.nas.mode", "reference/generated/modelopt.torch.nas.modules", "reference/generated/modelopt.torch.nas.modules.container", "reference/generated/modelopt.torch.nas.modules.conv", "reference/generated/modelopt.torch.nas.modules.linear", "reference/generated/modelopt.torch.nas.modules.norm", "reference/generated/modelopt.torch.nas.modules.utils", "reference/generated/modelopt.torch.nas.plugins", "reference/generated/modelopt.torch.nas.registry", "reference/generated/modelopt.torch.nas.search_space", "reference/generated/modelopt.torch.nas.traced_hp", "reference/generated/modelopt.torch.nas.utils", "reference/generated/modelopt.torch.opt", "reference/generated/modelopt.torch.opt.config", "reference/generated/modelopt.torch.opt.conversion", "reference/generated/modelopt.torch.opt.dynamic", "reference/generated/modelopt.torch.opt.hparam", "reference/generated/modelopt.torch.opt.mode", "reference/generated/modelopt.torch.opt.plugins", "reference/generated/modelopt.torch.opt.plugins.huggingface", "reference/generated/modelopt.torch.opt.searcher", "reference/generated/modelopt.torch.opt.utils", "reference/generated/modelopt.torch.prune", "reference/generated/modelopt.torch.prune.config", "reference/generated/modelopt.torch.prune.fastnas", "reference/generated/modelopt.torch.prune.gradnas", "reference/generated/modelopt.torch.prune.mcore_gpt_minitron", "reference/generated/modelopt.torch.prune.mode", "reference/generated/modelopt.torch.prune.plugins", "reference/generated/modelopt.torch.prune.pruning", "reference/generated/modelopt.torch.quantization", "reference/generated/modelopt.torch.quantization.algorithms", "reference/generated/modelopt.torch.quantization.calib", "reference/generated/modelopt.torch.quantization.calib.calibrator", "reference/generated/modelopt.torch.quantization.calib.histogram", "reference/generated/modelopt.torch.quantization.calib.max", "reference/generated/modelopt.torch.quantization.config", "reference/generated/modelopt.torch.quantization.conversion", "reference/generated/modelopt.torch.quantization.extensions", "reference/generated/modelopt.torch.quantization.mode", "reference/generated/modelopt.torch.quantization.model_calib", "reference/generated/modelopt.torch.quantization.model_quant", "reference/generated/modelopt.torch.quantization.nn", "reference/generated/modelopt.torch.quantization.nn.functional", "reference/generated/modelopt.torch.quantization.nn.modules", "reference/generated/modelopt.torch.quantization.nn.modules.clip", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling", "reference/generated/modelopt.torch.quantization.nn.modules.quant_rnn", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer", "reference/generated/modelopt.torch.quantization.optim", "reference/generated/modelopt.torch.quantization.plugins", "reference/generated/modelopt.torch.quantization.qtensor", "reference/generated/modelopt.torch.quantization.qtensor.base_qtensor", "reference/generated/modelopt.torch.quantization.qtensor.int4_tensor", "reference/generated/modelopt.torch.quantization.qtensor.nf4_tensor", "reference/generated/modelopt.torch.quantization.quant_modules", "reference/generated/modelopt.torch.quantization.tensor_quant", "reference/generated/modelopt.torch.quantization.utils", "reference/generated/modelopt.torch.sparsity", "reference/generated/modelopt.torch.sparsity.config", "reference/generated/modelopt.torch.sparsity.magnitude", "reference/generated/modelopt.torch.sparsity.mode", "reference/generated/modelopt.torch.sparsity.module", "reference/generated/modelopt.torch.sparsity.plugins", "reference/generated/modelopt.torch.sparsity.searcher", "reference/generated/modelopt.torch.sparsity.sparsegpt", "reference/generated/modelopt.torch.sparsity.sparsification", "reference/generated/modelopt.torch.speculative", "reference/generated/modelopt.torch.speculative.config", "reference/generated/modelopt.torch.speculative.medusa", "reference/generated/modelopt.torch.speculative.medusa.conversion", "reference/generated/modelopt.torch.speculative.medusa.medusa_model", "reference/generated/modelopt.torch.speculative.mode", "reference/generated/modelopt.torch.speculative.plugins", "reference/generated/modelopt.torch.speculative.speculative_decoding", "reference/generated/modelopt.torch.trace", "reference/generated/modelopt.torch.trace.analyzer", "reference/generated/modelopt.torch.trace.modules", "reference/generated/modelopt.torch.trace.modules.concat", "reference/generated/modelopt.torch.trace.modules.nn", "reference/generated/modelopt.torch.trace.plugins", "reference/generated/modelopt.torch.trace.symbols", "reference/generated/modelopt.torch.trace.tracer", "reference/generated/modelopt.torch.utils", "reference/generated/modelopt.torch.utils.cpp_extension", "reference/generated/modelopt.torch.utils.dataset_utils", "reference/generated/modelopt.torch.utils.distributed", "reference/generated/modelopt.torch.utils.graph", "reference/generated/modelopt.torch.utils.list", "reference/generated/modelopt.torch.utils.logging", "reference/generated/modelopt.torch.utils.network", "reference/generated/modelopt.torch.utils.perf", "reference/generated/modelopt.torch.utils.random", "reference/generated/modelopt.torch.utils.tensor", "support/1_contact", "support/2_faqs"], "filenames": ["deployment/1_tensorrt_llm_deployment.rst", "examples/0_all_examples.rst", "examples/1_cifar_resnet.ipynb", "examples/2_bert_prune_distill_quantize.rst", "getting_started/1_overview.rst", "getting_started/2_installation.rst", "getting_started/3_quantization.rst", "getting_started/4_pruning.rst", "getting_started/5_distillation.rst", "getting_started/6_sparsity.rst", "guides/1_quantization.rst", "guides/2_pruning.rst", "guides/3_nas.rst", "guides/4_distillation.rst", "guides/5_sparsity.rst", "guides/6_save_load.rst", "guides/6_speculative_decoding.rst", "guides/_basic_quantization.rst", "guides/_choosing_quant_methods.rst", "guides/_onnx_quantization.rst", "guides/_pytorch_quantization.rst", "index.rst", "reference/0_changelog.rst", "reference/1_modelopt_api.rst", "reference/generated/modelopt.deploy.rst", "reference/generated/modelopt.deploy.llm.rst", "reference/generated/modelopt.deploy.llm.generate.rst", "reference/generated/modelopt.deploy.llm.nemo_utils.rst", "reference/generated/modelopt.onnx.rst", "reference/generated/modelopt.onnx.op_types.rst", "reference/generated/modelopt.onnx.quantization.rst", "reference/generated/modelopt.onnx.quantization.calib_utils.rst", "reference/generated/modelopt.onnx.quantization.extensions.rst", "reference/generated/modelopt.onnx.quantization.fp8.rst", "reference/generated/modelopt.onnx.quantization.graph_utils.rst", "reference/generated/modelopt.onnx.quantization.gs_patching.rst", "reference/generated/modelopt.onnx.quantization.int4.rst", "reference/generated/modelopt.onnx.quantization.int8.rst", "reference/generated/modelopt.onnx.quantization.operators.rst", "reference/generated/modelopt.onnx.quantization.ort_patching.rst", "reference/generated/modelopt.onnx.quantization.ort_utils.rst", "reference/generated/modelopt.onnx.quantization.partitioning.rst", "reference/generated/modelopt.onnx.quantization.qdq_utils.rst", "reference/generated/modelopt.onnx.quantization.quant_utils.rst", "reference/generated/modelopt.onnx.quantization.quantize.rst", "reference/generated/modelopt.onnx.utils.rst", "reference/generated/modelopt.torch.rst", "reference/generated/modelopt.torch.distill.rst", "reference/generated/modelopt.torch.distill.config.rst", "reference/generated/modelopt.torch.distill.distillation.rst", "reference/generated/modelopt.torch.distill.distillation_model.rst", "reference/generated/modelopt.torch.distill.loss_balancers.rst", "reference/generated/modelopt.torch.distill.losses.rst", "reference/generated/modelopt.torch.distill.mode.rst", "reference/generated/modelopt.torch.distill.registry.rst", "reference/generated/modelopt.torch.export.rst", "reference/generated/modelopt.torch.export.distribute.rst", "reference/generated/modelopt.torch.export.hf_config_map.rst", "reference/generated/modelopt.torch.export.layer_utils.rst", "reference/generated/modelopt.torch.export.model_config.rst", "reference/generated/modelopt.torch.export.model_config_export.rst", "reference/generated/modelopt.torch.export.model_config_utils.rst", "reference/generated/modelopt.torch.export.postprocess.rst", "reference/generated/modelopt.torch.export.scaling_factor_utils.rst", "reference/generated/modelopt.torch.export.tensorrt_llm_type.rst", "reference/generated/modelopt.torch.export.tensorrt_llm_utils.rst", "reference/generated/modelopt.torch.export.transformer_engine.rst", "reference/generated/modelopt.torch.export.unified_export_hf.rst", "reference/generated/modelopt.torch.export.vllm.rst", "reference/generated/modelopt.torch.nas.rst", "reference/generated/modelopt.torch.nas.algorithms.rst", "reference/generated/modelopt.torch.nas.autonas.rst", "reference/generated/modelopt.torch.nas.config.rst", "reference/generated/modelopt.torch.nas.conversion.rst", "reference/generated/modelopt.torch.nas.hparams.rst", "reference/generated/modelopt.torch.nas.hparams.concat.rst", "reference/generated/modelopt.torch.nas.hparams.container.rst", "reference/generated/modelopt.torch.nas.mode.rst", "reference/generated/modelopt.torch.nas.modules.rst", "reference/generated/modelopt.torch.nas.modules.container.rst", "reference/generated/modelopt.torch.nas.modules.conv.rst", "reference/generated/modelopt.torch.nas.modules.linear.rst", "reference/generated/modelopt.torch.nas.modules.norm.rst", "reference/generated/modelopt.torch.nas.modules.utils.rst", "reference/generated/modelopt.torch.nas.plugins.rst", "reference/generated/modelopt.torch.nas.registry.rst", "reference/generated/modelopt.torch.nas.search_space.rst", "reference/generated/modelopt.torch.nas.traced_hp.rst", "reference/generated/modelopt.torch.nas.utils.rst", "reference/generated/modelopt.torch.opt.rst", "reference/generated/modelopt.torch.opt.config.rst", "reference/generated/modelopt.torch.opt.conversion.rst", "reference/generated/modelopt.torch.opt.dynamic.rst", "reference/generated/modelopt.torch.opt.hparam.rst", "reference/generated/modelopt.torch.opt.mode.rst", "reference/generated/modelopt.torch.opt.plugins.rst", "reference/generated/modelopt.torch.opt.plugins.huggingface.rst", "reference/generated/modelopt.torch.opt.searcher.rst", "reference/generated/modelopt.torch.opt.utils.rst", "reference/generated/modelopt.torch.prune.rst", "reference/generated/modelopt.torch.prune.config.rst", "reference/generated/modelopt.torch.prune.fastnas.rst", "reference/generated/modelopt.torch.prune.gradnas.rst", "reference/generated/modelopt.torch.prune.mcore_gpt_minitron.rst", "reference/generated/modelopt.torch.prune.mode.rst", "reference/generated/modelopt.torch.prune.plugins.rst", "reference/generated/modelopt.torch.prune.pruning.rst", "reference/generated/modelopt.torch.quantization.rst", "reference/generated/modelopt.torch.quantization.algorithms.rst", "reference/generated/modelopt.torch.quantization.calib.rst", "reference/generated/modelopt.torch.quantization.calib.calibrator.rst", "reference/generated/modelopt.torch.quantization.calib.histogram.rst", "reference/generated/modelopt.torch.quantization.calib.max.rst", "reference/generated/modelopt.torch.quantization.config.rst", "reference/generated/modelopt.torch.quantization.conversion.rst", "reference/generated/modelopt.torch.quantization.extensions.rst", "reference/generated/modelopt.torch.quantization.mode.rst", "reference/generated/modelopt.torch.quantization.model_calib.rst", "reference/generated/modelopt.torch.quantization.model_quant.rst", "reference/generated/modelopt.torch.quantization.nn.rst", "reference/generated/modelopt.torch.quantization.nn.functional.rst", "reference/generated/modelopt.torch.quantization.nn.modules.rst", "reference/generated/modelopt.torch.quantization.nn.modules.clip.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_rnn.rst", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer.rst", "reference/generated/modelopt.torch.quantization.optim.rst", "reference/generated/modelopt.torch.quantization.plugins.rst", "reference/generated/modelopt.torch.quantization.qtensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.base_qtensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.int4_tensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.nf4_tensor.rst", "reference/generated/modelopt.torch.quantization.quant_modules.rst", "reference/generated/modelopt.torch.quantization.tensor_quant.rst", "reference/generated/modelopt.torch.quantization.utils.rst", "reference/generated/modelopt.torch.sparsity.rst", "reference/generated/modelopt.torch.sparsity.config.rst", "reference/generated/modelopt.torch.sparsity.magnitude.rst", "reference/generated/modelopt.torch.sparsity.mode.rst", "reference/generated/modelopt.torch.sparsity.module.rst", "reference/generated/modelopt.torch.sparsity.plugins.rst", "reference/generated/modelopt.torch.sparsity.searcher.rst", "reference/generated/modelopt.torch.sparsity.sparsegpt.rst", "reference/generated/modelopt.torch.sparsity.sparsification.rst", "reference/generated/modelopt.torch.speculative.rst", "reference/generated/modelopt.torch.speculative.config.rst", "reference/generated/modelopt.torch.speculative.medusa.rst", "reference/generated/modelopt.torch.speculative.medusa.conversion.rst", "reference/generated/modelopt.torch.speculative.medusa.medusa_model.rst", "reference/generated/modelopt.torch.speculative.mode.rst", "reference/generated/modelopt.torch.speculative.plugins.rst", "reference/generated/modelopt.torch.speculative.speculative_decoding.rst", "reference/generated/modelopt.torch.trace.rst", "reference/generated/modelopt.torch.trace.analyzer.rst", "reference/generated/modelopt.torch.trace.modules.rst", "reference/generated/modelopt.torch.trace.modules.concat.rst", "reference/generated/modelopt.torch.trace.modules.nn.rst", "reference/generated/modelopt.torch.trace.plugins.rst", "reference/generated/modelopt.torch.trace.symbols.rst", "reference/generated/modelopt.torch.trace.tracer.rst", "reference/generated/modelopt.torch.utils.rst", "reference/generated/modelopt.torch.utils.cpp_extension.rst", "reference/generated/modelopt.torch.utils.dataset_utils.rst", "reference/generated/modelopt.torch.utils.distributed.rst", "reference/generated/modelopt.torch.utils.graph.rst", "reference/generated/modelopt.torch.utils.list.rst", "reference/generated/modelopt.torch.utils.logging.rst", "reference/generated/modelopt.torch.utils.network.rst", "reference/generated/modelopt.torch.utils.perf.rst", "reference/generated/modelopt.torch.utils.random.rst", "reference/generated/modelopt.torch.utils.tensor.rst", "support/1_contact.rst", "support/2_faqs.rst"], "titles": ["TensorRT-LLM Deployment", "All GitHub Examples", "ResNet20 on CIFAR-10: Pruning", "HF BERT: Prune, Distill &amp; Quantize", "Overview", "Installation", "Quick Start: Quantization", "Quick Start: Pruning", "Quick Start: Distillation", "Quick Start: Sparsity", "Quantization", "Pruning", "NAS", "Distillation", "Sparsity", "Saving &amp; Restoring", "Speculative Decoding", "Basic Concepts", "Best practices to choose the right quantization methods", "ONNX Quantization (Beta)", "PyTorch Quantization", "Welcome to Model Optimizer (ModelOpt) documentation!", "Changelog", "modelopt API", "deploy", "llm", "generate", "nemo_utils", "onnx", "op_types", "quantization", "calib_utils", "extensions", "fp8", "graph_utils", "gs_patching", "int4", "int8", "operators", "ort_patching", "ort_utils", "partitioning", "qdq_utils", "quant_utils", "modelopt.onnx.quantization.quantize", "utils", "torch", "distill", "config", "distillation", "distillation_model", "loss_balancers", "losses", "mode", "registry", "export", "distribute", "hf_config_map", "layer_utils", "model_config", "model_config_export", "model_config_utils", "postprocess", "scaling_factor_utils", "tensorrt_llm_type", "tensorrt_llm_utils", "transformer_engine", "unified_export_hf", "vllm", "nas", "algorithms", "autonas", "config", "conversion", "hparams", "concat", "container", "mode", "modules", "container", "conv", "linear", "norm", "utils", "plugins", "registry", "search_space", "traced_hp", "utils", "opt", "config", "conversion", "dynamic", "hparam", "mode", "plugins", "huggingface", "searcher", "utils", "prune", "config", "fastnas", "gradnas", "mcore_gpt_minitron", "mode", "plugins", "pruning", "quantization", "algorithms", "calib", "calibrator", "histogram", "max", "config", "conversion", "extensions", "mode", "model_calib", "model_quant", "nn", "functional", "modules", "clip", "quant_activations", "quant_batchnorm", "quant_conv", "quant_instancenorm", "quant_linear", "quant_module", "quant_pooling", "quant_rnn", "tensor_quantizer", "optim", "plugins", "qtensor", "base_qtensor", "int4_tensor", "nf4_tensor", "quant_modules", "tensor_quant", "utils", "sparsity", "config", "magnitude", "mode", "module", "plugins", "searcher", "sparsegpt", "sparsification", "speculative", "config", "medusa", "conversion", "medusa_model", "mode", "plugins", "speculative_decoding", "trace", "analyzer", "modules", "concat", "nn", "plugins", "symbols", "tracer", "utils", "cpp_extension", "dataset_utils", "distributed", "graph", "list", "logging", "network", "perf", "random", "tensor", "Contact us", "FAQs"], "terms": {"pleas": [0, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18, 19, 20, 22, 26, 70, 73, 89, 91, 106, 113, 118, 133, 149, 156, 178], "read": [0, 12, 31, 56], "workflow": [0, 2, 4, 11, 15, 94, 97, 99], "first": [0, 2, 3, 5, 8, 11, 14, 18, 34, 36, 45, 56, 58, 88, 118, 167, 173], "befor": [0, 3, 5, 11, 12, 15, 17, 34, 52, 70, 71, 72, 77, 92, 96, 97, 101, 103, 104, 106, 113, 116, 128, 130, 173, 175], "go": [0, 3, 11, 12], "through": [0, 3, 4, 8, 9, 12, 17, 20, 58, 87, 117, 118, 139, 164], "thi": [0, 2, 3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 27, 29, 33, 34, 36, 38, 39, 40, 41, 43, 44, 45, 48, 50, 51, 52, 53, 56, 58, 59, 61, 62, 65, 70, 72, 73, 77, 87, 88, 90, 91, 92, 93, 96, 97, 99, 102, 104, 106, 108, 111, 113, 114, 116, 117, 118, 120, 130, 131, 133, 135, 137, 138, 139, 140, 143, 144, 145, 149, 154, 155, 156, 161, 164, 165, 168, 173, 175, 178], "section": [0, 11, 12, 13, 14], "modelopt": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 34, 40, 49, 57, 59, 86, 88, 89, 90, 91, 94, 96, 99, 109, 113, 114, 118, 157, 168, 175, 178], "toolkit": [0, 10], "automat": [0, 3, 4, 12, 14, 15, 20, 22, 70, 73, 92, 96, 106, 143, 149], "convers": [0, 13, 18, 29, 33, 44, 49, 86, 92, 96, 157, 175, 178], "engin": [0, 19, 22, 26, 59, 60], "acceler": [0, 3, 4, 6, 9, 14, 16], "inferenc": 0, "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 26, 27, 29, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 65, 70, 71, 72, 73, 77, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 106, 108, 111, 112, 113, 114, 116, 117, 118, 120, 128, 130, 131, 135, 138, 139, 140, 142, 143, 144, 145, 149, 157, 161, 162, 164, 165, 168, 169, 173, 175, 178], "achiev": [0, 2, 3, 8, 10, 12, 14, 16, 20, 22, 92], "huggingfac": [0, 3, 5, 6, 8, 20, 22, 26, 27, 55, 59, 133], "nemo": [0, 2, 4, 6, 11, 12, 20, 22, 27, 55, 59, 103, 106, 133], "build": [0, 3, 5, 11, 12, 19, 22, 27, 34, 58, 59, 60, 101, 106, 149, 165], "from": [0, 1, 2, 3, 4, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 22, 26, 27, 31, 34, 39, 40, 41, 42, 44, 45, 48, 50, 58, 59, 61, 63, 64, 70, 71, 86, 87, 89, 90, 91, 92, 93, 96, 97, 102, 106, 111, 113, 114, 118, 131, 139, 140, 143, 148, 149, 161, 164, 165, 168, 171, 173, 175, 176], "after": [0, 2, 3, 7, 9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 34, 40, 51, 56, 71, 72, 73, 89, 91, 92, 94, 97, 101, 102, 113, 114, 117, 149, 154, 164, 173], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 29, 34, 43, 44, 53, 59, 60, 70, 72, 73, 75, 77, 86, 88, 89, 90, 91, 92, 94, 97, 100, 101, 102, 103, 104, 106, 108, 113, 114, 116, 118, 131, 133, 139, 142, 144, 155, 156, 161, 164, 168, 173, 174, 175, 178], "format": [0, 3, 4, 6, 10, 14, 18, 19, 20, 22, 31, 44, 48, 56, 59, 60, 61, 63, 70, 73, 97, 106, 108, 118, 131, 136, 137, 168, 173], "store": [0, 3, 7, 12, 14, 22, 34, 44, 48, 60, 70, 91, 92, 93, 97, 101, 102, 106, 136, 137, 139, 161, 165], "A": [0, 2, 3, 11, 12, 13, 14, 16, 17, 18, 20, 26, 41, 42, 44, 48, 49, 50, 52, 54, 56, 58, 60, 61, 70, 71, 73, 85, 86, 87, 88, 90, 91, 92, 93, 94, 97, 99, 101, 106, 108, 111, 112, 113, 114, 117, 118, 122, 130, 131, 135, 139, 140, 147, 149, 154, 157, 162, 164, 165, 168, 173, 174], "singl": [0, 2, 3, 12, 13, 17, 19, 34, 43, 48, 50, 61, 62, 63, 70, 88, 93, 94, 106, 118, 130, 131, 164, 173], "json": [0, 3, 48, 56, 60, 61, 72, 90, 100, 113, 142, 151], "file": [0, 2, 3, 19, 22, 33, 34, 36, 37, 43, 44, 45, 56, 58, 60, 65, 90, 91, 167], "record": [0, 12, 91, 94, 165], "structur": 0, "metadata": [0, 14, 71, 91, 101, 113, 144, 153], "config": [0, 2, 3, 6, 7, 9, 12, 13, 14, 15, 16, 22, 26, 27, 49, 53, 56, 57, 58, 59, 60, 61, 62, 65, 70, 71, 73, 77, 86, 88, 91, 92, 97, 101, 102, 103, 104, 106, 108, 116, 118, 136, 137, 144, 147, 148, 149, 153, 155, 157, 175], "group": [0, 2, 3, 11, 12, 18, 22, 56, 63, 113, 118, 131, 169], "safetensor": [0, 60], "each": [0, 3, 12, 14, 16, 17, 20, 22, 34, 36, 44, 48, 50, 51, 56, 60, 63, 65, 71, 72, 87, 89, 91, 92, 93, 94, 100, 108, 113, 114, 136, 137, 140, 142, 149, 165, 175], "local": [0, 3, 56, 88], "calibr": [0, 2, 3, 6, 7, 9, 11, 12, 14, 18, 20, 22, 31, 33, 36, 42, 44, 60, 70, 72, 73, 106, 108, 109, 111, 112, 113, 114, 117, 118, 125, 127, 128, 130, 131, 149, 168], "gpu": [0, 2, 3, 4, 14, 18, 22, 60, 111, 174, 175], "rank": [0, 2, 7, 11, 12, 56, 59, 60, 62, 63, 102, 113, 118, 131, 140, 169, 174], "weight": [0, 2, 3, 4, 7, 9, 11, 12, 14, 17, 18, 20, 22, 27, 34, 36, 42, 44, 45, 50, 51, 56, 58, 59, 60, 61, 62, 63, 65, 67, 73, 91, 92, 108, 111, 113, 114, 117, 118, 128, 130, 139, 140, 143, 145, 149], "scale": [0, 19, 22, 31, 36, 42, 58, 59, 60, 61, 63, 113, 117, 131, 135, 136, 137, 139], "factor": [0, 18, 36, 42, 58, 59, 60, 61, 63, 108, 113, 117, 139], "per": [0, 3, 13, 17, 18, 20, 22, 43, 49, 60, 73, 106, 108, 113, 118, 131, 135, 139, 149, 153, 157, 164], "The": [0, 2, 3, 4, 6, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 26, 27, 34, 36, 42, 43, 48, 49, 50, 51, 53, 56, 58, 59, 60, 61, 62, 63, 65, 67, 70, 71, 73, 77, 78, 86, 87, 88, 90, 91, 92, 97, 102, 104, 106, 108, 113, 114, 116, 117, 118, 120, 131, 135, 136, 137, 139, 140, 143, 144, 149, 151, 154, 155, 157, 159, 164, 165, 168, 170, 173, 175], "api": [0, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 19, 20, 21, 22, 26, 27, 47, 49, 60, 73, 96, 99, 106, 117, 118, 138, 141, 149, 157], "export_tensorrt_llm_checkpoint": [0, 60], "us": [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 22, 29, 34, 36, 37, 43, 44, 48, 49, 50, 52, 53, 56, 60, 63, 68, 70, 71, 72, 73, 77, 86, 87, 88, 89, 90, 91, 92, 96, 97, 100, 101, 102, 103, 104, 106, 108, 111, 112, 113, 114, 116, 117, 118, 120, 122, 130, 131, 138, 139, 142, 143, 145, 149, 151, 157, 161, 164, 165, 167, 168, 169, 173, 174, 175, 178], "follow": [0, 2, 3, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 34, 49, 53, 58, 70, 73, 77, 86, 91, 97, 104, 106, 113, 116, 118, 139, 149, 154, 157, 164, 165], "torch": [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 20, 22, 40, 47, 49, 51, 56, 58, 60, 61, 67, 68, 70, 78, 79, 80, 81, 82, 86, 88, 89, 91, 92, 96, 97, 99, 106, 109, 111, 113, 114, 118, 130, 131, 135, 136, 137, 139, 154, 157, 161, 162, 164, 165, 167, 168, 169, 173, 175, 176], "import": [0, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 90, 91, 93, 96, 103, 108, 113, 114, 118, 168, 173, 175], "inference_mod": 0, "decoder_typ": [0, 58, 59, 60], "type": [0, 3, 13, 14, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 67, 70, 71, 73, 74, 77, 83, 86, 87, 88, 90, 91, 92, 93, 94, 97, 98, 101, 102, 103, 104, 106, 108, 111, 113, 114, 116, 117, 118, 125, 127, 128, 130, 131, 135, 136, 137, 139, 140, 143, 144, 147, 148, 149, 153, 154, 155, 157, 159, 161, 162, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178], "str": [0, 3, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 44, 45, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 65, 67, 68, 70, 71, 72, 73, 77, 83, 86, 88, 90, 91, 92, 97, 98, 100, 101, 102, 103, 104, 106, 108, 111, 113, 114, 116, 117, 118, 130, 131, 142, 143, 144, 147, 148, 149, 153, 155, 157, 159, 164, 165, 167, 168, 169, 171, 172, 173], "e": [0, 2, 3, 8, 9, 11, 12, 13, 14, 15, 17, 18, 20, 22, 36, 44, 52, 60, 70, 73, 86, 92, 94, 97, 106, 113, 118, 130, 139, 161, 164, 165, 167, 173], "g": [0, 2, 3, 9, 11, 12, 14, 17, 20, 22, 60, 70, 73, 86, 92, 94, 106, 113, 139, 161, 164, 167, 173], "gptj": [0, 12, 60], "llama": [0, 11, 22, 60], "gptnext": [0, 60], "dtype": [0, 3, 35, 42, 44, 58, 59, 60, 67, 131, 135, 136, 137, 139, 173], "data": [0, 2, 3, 6, 7, 8, 9, 11, 12, 14, 18, 19, 20, 22, 31, 43, 44, 45, 58, 60, 67, 70, 102, 106, 109, 111, 113, 117, 118, 131, 135, 136, 137, 149, 168, 173, 176], "unquant": [0, 17, 60, 67], "layer": [0, 2, 4, 7, 11, 13, 14, 20, 22, 34, 41, 44, 48, 50, 56, 58, 59, 60, 63, 65, 67, 70, 72, 73, 86, 93, 100, 102, 106, 108, 113, 118, 130, 142, 149, 154, 158, 159, 160, 162, 164, 165, 173], "export_dir": [0, 60, 65, 67, 68], "directori": [0, 3, 16, 19, 26, 44, 45, 56, 60, 65], "where": [0, 3, 12, 14, 16, 17, 20, 36, 44, 50, 70, 97, 101, 106, 108, 113, 118, 128, 161, 164, 173], "inference_tensor_parallel": [0, 22, 60, 62], "number": [0, 2, 3, 11, 12, 36, 52, 63, 70, 88, 92, 93, 106, 111, 112, 113, 118, 122, 139, 151, 168, 169, 172, 173, 175], "infer": [0, 2, 4, 6, 9, 12, 14, 15, 16, 18, 22, 40, 59, 60, 62, 70, 88, 91, 97, 106, 168], "time": [0, 2, 3, 5, 12, 16, 18, 22, 60, 70, 106, 118, 149, 167, 171], "tensor": [0, 3, 8, 12, 13, 14, 17, 18, 20, 22, 26, 31, 34, 36, 42, 44, 45, 50, 51, 52, 56, 58, 59, 60, 61, 62, 63, 83, 88, 92, 93, 102, 108, 111, 112, 113, 118, 120, 122, 130, 131, 134, 135, 136, 137, 139, 140, 143, 148, 154, 164, 165, 173], "parallel": [0, 2, 3, 11, 12, 14, 16, 22, 58, 60, 62, 140, 173], "inference_pipeline_parallel": [0, 60, 62], "pipelin": [0, 2, 4, 8, 11, 12, 13, 14, 20, 22, 60, 118], "If": [0, 2, 3, 5, 11, 12, 13, 14, 15, 16, 18, 19, 20, 31, 34, 44, 45, 48, 49, 50, 51, 56, 58, 59, 62, 63, 70, 72, 73, 86, 88, 91, 92, 93, 100, 102, 106, 108, 111, 112, 113, 114, 117, 118, 122, 131, 140, 142, 149, 157, 164, 168, 173, 178], "call": [0, 3, 5, 7, 12, 13, 14, 15, 16, 20, 22, 40, 43, 50, 90, 92, 96, 114, 128, 130, 131, 145, 149, 164, 168], "success": [0, 5], "save": [0, 2, 3, 7, 9, 10, 11, 13, 19, 20, 21, 22, 44, 45, 50, 56, 59, 60, 67, 68, 70, 77, 89, 91, 96, 97, 104, 106, 112, 116, 131, 139], "otherwis": [0, 3, 12, 56, 58, 77, 114, 139, 161, 170], "state_dict": [0, 2, 7, 11, 12, 14, 15, 48, 50, 56, 70, 91, 97, 106, 118], "instead": [0, 11, 12, 15, 16, 22, 43, 56, 70, 72, 86, 88, 92, 93, 94, 100, 108, 111, 138, 139, 142, 164, 165], "fp16": [0, 18, 19, 20, 33, 34, 42, 44, 118, 131], "bf16": [0, 3, 18, 20, 118], "fp8": [0, 4, 17, 18, 19, 20, 22, 34, 42, 44, 58, 59, 60, 113, 131, 139], "int8_sq": [0, 59], "int4_awq": [0, 22], "gpt2": [0, 60], "ye": [0, 2], "No": [0, 3, 12], "2": [0, 2, 3, 4, 5, 9, 11, 12, 14, 22, 31, 34, 36, 43, 64, 75, 86, 100, 102, 108, 118, 139, 143, 151, 164], "3": [0, 2, 5, 7, 11, 12, 22, 58, 113, 118, 139, 164], "mistral": [0, 12], "mixtral": [0, 22], "8x7b": 0, "falcon": 0, "40b": 0, "180b": 0, "7b": 0, "mpt": 0, "30b": 0, "baichuan": 0, "1": [0, 2, 3, 7, 11, 12, 16, 20, 22, 26, 31, 36, 51, 52, 58, 59, 60, 61, 62, 64, 70, 72, 73, 75, 86, 100, 102, 106, 108, 111, 113, 118, 139, 140, 151, 161, 164, 168, 171, 173, 175], "chatglm2": 0, "6b": [0, 11, 14], "bloom": 0, "phi": [0, 65], "nemotron": 0, "8": [0, 2, 3, 4, 5, 18, 19, 36, 58, 65, 100, 111, 112, 113, 125, 127, 128, 130, 139, 167, 173], "gemma": [0, 22], "2b": 0, "recurr": [0, 29, 58, 59], "starcod": [0, 22], "qwen": [0, 22], "5": [0, 2, 3, 12, 20, 36, 41, 51, 70, 72, 73, 75, 86, 100, 106, 113], "onc": [0, 3, 11, 12, 15, 40, 96, 111], "avail": [0, 2, 3, 4, 5, 6, 11, 12, 13, 14, 17, 22, 31, 49, 54, 73, 85, 93, 106, 149, 157, 169], "deploi": [0, 5, 18, 22], "relat": [1, 12, 13, 14, 34, 41, 45, 54, 86, 88, 101, 164], "optim": [1, 3, 6, 10, 11, 12, 13, 14, 15, 24, 28, 30, 43, 46, 49, 60, 64, 66, 68, 69, 70, 71, 73, 89, 91, 94, 97, 98, 101, 102, 106, 108, 113, 130, 149, 150, 152, 157], "techniqu": [1, 6, 9, 14, 17, 20, 22], "like": [1, 2, 4, 6, 7, 10, 11, 12, 14, 16, 17, 19, 20, 22, 31, 41, 44, 51, 70, 73, 86, 91, 92, 97, 106, 112, 131, 173], "quantiz": [1, 5, 7, 11, 15, 21, 22, 29, 33, 34, 36, 37, 38, 40, 41, 42, 43, 58, 59, 60, 61, 62, 63, 66, 67, 68, 94, 108, 109, 111, 112, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 155, 168], "ptq": [1, 3, 4, 17, 22, 34], "qat": [1, 3, 4, 6, 22], "sparsiti": [1, 15, 21, 22, 142, 143, 144, 145, 146, 147, 149], "distil": [1, 7, 11, 15, 21, 22, 48, 50, 51, 52, 53, 54, 157], "prune": [1, 13, 15, 21, 22, 69, 73, 88, 94, 100, 101, 102, 103, 104, 105, 164], "tensorrt": [1, 3, 5, 6, 10, 11, 18, 19, 20, 21, 22, 26, 31, 34, 44, 58, 59, 60, 64, 65, 67, 118], "llm": [1, 4, 5, 6, 10, 11, 18, 20, 21, 22, 26, 55, 58, 59, 60, 62, 64, 65, 67, 113, 118], "deploy": [1, 2, 3, 4, 8, 10, 11, 12, 18, 20, 22, 24, 25, 46, 60, 67, 70, 97, 118], "more": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 53, 70, 77, 86, 88, 89, 90, 92, 102, 103, 104, 106, 113, 114, 118, 120, 131, 136, 137, 139, 149, 173], "access": [1, 14, 29, 56, 88, 90, 92, 113], "repositori": [1, 2, 4, 10], "com": [1, 2, 3, 5, 26, 27, 29, 60, 139, 173], "nvidia": [1, 2, 3, 5, 9, 10, 11, 14, 20, 22, 26, 27, 60, 103, 106, 113, 143], "model": [1, 3, 10, 13, 17, 18, 24, 26, 27, 28, 30, 31, 33, 34, 36, 37, 41, 42, 44, 45, 46, 48, 49, 50, 53, 56, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 77, 86, 88, 89, 91, 92, 94, 96, 97, 98, 101, 102, 103, 104, 106, 108, 111, 113, 114, 116, 117, 118, 131, 138, 140, 144, 149, 151, 153, 154, 155, 157, 159, 164, 165, 168, 173, 175, 178], "tutori": 2, "jupyt": 2, "notebook": [2, 7, 11], "download": [2, 3, 5, 19], "here": [2, 3, 6, 7, 9, 11, 12, 15, 20, 41, 43, 51, 92, 93, 96, 101, 103, 113, 114, 118, 130, 173], "It": [2, 3, 4, 11, 12, 13, 20, 56, 70, 87, 88, 94, 106, 113, 116, 118, 130, 131, 135, 139, 143, 149, 164, 173], "would": [2, 11, 12, 50, 51, 73, 106, 111, 113, 149, 161], "take": [2, 3, 5, 7, 11, 12, 14, 16, 20, 70, 86, 88, 90, 93, 106, 111, 113, 114, 117, 118, 131, 139, 149, 167, 173], "about": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 53, 54, 77, 85, 89, 102, 104, 113, 118, 131, 164], "hour": [2, 3], "googl": [2, 36, 42, 139], "colab": 2, "run": [2, 3, 5, 7, 12, 13, 16, 19, 20, 27, 34, 70, 71, 97, 103, 106, 111, 118, 149, 173], "fast": [2, 5, 102, 118], "you": [2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 70, 72, 88, 90, 91, 100, 106, 113, 118, 133, 138, 142, 149, 156, 173, 178], "better": [2, 3, 11, 12, 14, 19, 20, 102], "expect": [2, 3, 13, 41, 65], "slightli": 2, "differ": [2, 3, 4, 7, 10, 11, 12, 13, 17, 18, 29, 49, 51, 52, 73, 87, 92, 106, 113, 130, 149, 157, 164, 168], "accuraci": [2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 17, 18, 20, 70, 106], "than": [2, 3, 8, 11, 12, 13, 14, 20, 27, 45, 92, 113], "report": [2, 19, 70, 174], "below": [2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 92, 113, 118, 164, 173], "depend": [2, 3, 5, 11, 12, 22, 34, 87, 92, 93, 158, 159, 161, 164, 165], "system": [2, 92], "purpos": [2, 3, 13, 54, 89, 139], "demonstr": 2, "best": [2, 3, 10, 11, 12, 19, 20, 22, 26, 70, 71, 97, 101, 106, 108, 118, 143], "In": [2, 3, 11, 12, 13, 18, 70, 92, 102, 106, 108, 113, 114, 118, 164, 173], "we": [2, 3, 5, 6, 11, 12, 13, 14, 16, 17, 18, 20, 34, 36, 58, 59, 60, 62, 70, 71, 86, 87, 90, 91, 92, 93, 94, 97, 101, 102, 106, 108, 111, 116, 118, 130, 133, 139, 145, 146, 149, 156, 161, 164, 168, 173, 175, 178], "make": [2, 3, 11, 12, 13, 27, 43, 62, 73, 88, 92, 135, 140, 161, 164, 178], "faster": [2, 5, 8, 11, 13, 16, 43, 93], "our": [2, 3, 11, 90], "target": [2, 3, 4, 11, 12, 16, 56, 60, 61, 62, 67, 88, 91, 92, 136, 137, 161, 165, 168, 173], "constraint": [2, 3, 7, 12, 20, 70, 71, 97, 106, 108, 113, 118], "without": [2, 3, 5, 8, 11, 12, 14, 50, 60, 73, 88, 92, 161, 173], "sacrif": 2, "much": [2, 3, 5, 11, 13, 20, 113], "By": [2, 5, 19, 22, 38, 70, 113], "end": [2, 3, 4, 6, 7, 9, 11, 12, 13, 22, 34, 70, 106, 113, 118, 161, 173, 174], "understand": [2, 11, 12], "how": [2, 3, 6, 8, 11, 12, 13, 15, 18, 20, 22, 27, 52, 89, 93, 113, 133, 139, 156, 173], "user": [2, 4, 6, 7, 8, 11, 12, 13, 14, 16, 18, 19, 20, 22, 29, 34, 40, 56, 89, 91, 92, 93, 113, 118, 157], "provid": [2, 3, 4, 7, 9, 11, 12, 13, 14, 16, 17, 19, 20, 31, 34, 40, 43, 44, 51, 56, 63, 70, 72, 73, 86, 87, 88, 89, 90, 91, 92, 97, 99, 100, 106, 109, 118, 135, 142, 149, 164, 168, 173], "perform": [2, 3, 4, 6, 8, 9, 13, 18, 20, 22, 26, 33, 36, 37, 56, 61, 73, 88, 106, 111, 113, 117, 118, 131, 137, 139, 154, 174], "architectur": [2, 5, 11, 13, 14, 15, 60, 88, 91, 92, 106, 175], "fit": [2, 3, 22, 59], "your": [2, 3, 5, 11, 13, 14, 15, 16, 18, 20, 22, 52, 70, 106, 113, 118, 133, 149, 156, 178], "downstream": [2, 4, 11, 12, 15], "task": [2, 3, 11, 12, 13, 15, 47, 51, 70, 88, 91, 97, 106, 118], "all": [2, 3, 4, 5, 11, 12, 14, 20, 21, 22, 34, 39, 41, 42, 44, 45, 56, 58, 59, 60, 62, 70, 72, 73, 75, 88, 90, 91, 92, 98, 100, 102, 111, 112, 114, 118, 130, 131, 140, 142, 143, 145, 161, 164, 165, 169, 173, 175], "just": [2, 3, 6, 12, 59, 86, 116, 173], "few": [2, 5, 11, 12, 13, 16, 118, 164, 167], "line": [2, 13, 19], "code": [2, 13, 20, 43, 53, 60, 64, 67, 77, 104, 116, 133, 144, 155, 156, 175], "": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 24, 34, 36, 40, 42, 44, 48, 49, 50, 52, 53, 56, 58, 70, 73, 77, 86, 88, 90, 91, 92, 94, 104, 106, 112, 113, 116, 120, 130, 144, 149, 155, 157, 164, 165, 168, 171, 173], "simpl": [2, 12, 13, 14, 19, 20, 87, 122, 164, 174], "let": [2, 3, 20, 92], "instal": [2, 3, 21, 22, 140], "step": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 71, 86, 91, 94, 97, 103, 113, 131], "pip": [2, 3, 5, 22], "extra": [2, 3, 5, 22, 27, 131, 165, 173], "index": [2, 3, 5, 131, 164], "url": [2, 3, 5], "http": [2, 3, 5, 26, 27, 29, 52, 60, 102, 103, 120, 139, 173], "pypi": [2, 3, 4, 5], "math": [2, 3, 14, 17], "o": [2, 3, 5, 16], "random": [2, 3, 19, 22, 31, 45, 71, 86, 88], "numpi": [2, 3, 19, 31, 42, 44, 45, 112, 131, 176], "np": [2, 3, 19, 61, 111], "nn": [2, 3, 8, 11, 12, 20, 48, 51, 58, 70, 72, 73, 78, 79, 80, 81, 82, 86, 91, 92, 97, 100, 106, 111, 113, 114, 127, 129, 131, 135, 142, 164, 173, 178], "function": [2, 3, 6, 7, 8, 11, 12, 13, 16, 20, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51, 52, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 83, 86, 87, 88, 90, 91, 93, 94, 96, 97, 98, 101, 102, 106, 108, 111, 113, 114, 115, 117, 118, 122, 130, 131, 132, 137, 138, 139, 140, 143, 144, 145, 148, 149, 153, 154, 157, 159, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176], "f": [2, 3, 15, 20, 91, 114], "torchvis": [2, 7, 8, 11, 12, 13], "transform": [2, 3, 4, 5, 12, 14, 15, 16, 19, 22, 58, 59, 61, 96, 118, 154, 156], "basicblock": 2, "tqdm": [2, 3], "auto": [2, 3, 16, 90, 168], "seed": [2, 3, 45, 175], "123": [2, 3], "manual_se": 2, "devic": [2, 3, 12, 16, 128, 168, 173, 174], "cuda": [2, 3, 5, 96, 113, 115, 130, 139, 167, 174], "For": [2, 3, 4, 5, 14, 15, 17, 18, 19, 20, 26, 44, 51, 60, 62, 72, 73, 88, 90, 91, 92, 93, 94, 100, 102, 106, 113, 117, 118, 131, 139, 142, 165, 173], "work": [2, 5, 12, 13, 17, 19, 33, 34, 56, 133, 156, 173], "well": [2, 3, 11, 12, 13, 14, 16, 18, 20, 72, 73, 92, 100, 142, 165, 173, 174], "known": [2, 13, 44], "consist": [2, 12, 17, 27, 86, 90, 92, 130], "60k": 2, "32x32": 2, "class": [2, 3, 8, 13, 20, 22, 26, 27, 31, 36, 38, 48, 50, 51, 52, 53, 56, 59, 64, 71, 73, 75, 76, 77, 86, 87, 88, 90, 91, 92, 93, 94, 97, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 116, 120, 122, 125, 126, 127, 128, 129, 130, 131, 134, 135, 136, 137, 139, 143, 144, 145, 147, 148, 154, 155, 161, 162, 164, 165, 173, 174], "split": [2, 3, 60, 61, 62, 111], "50k": 2, "10k": 2, "test": [2, 3, 10, 12], "further": [2, 4, 8, 11, 12, 15, 16, 102, 137], "5k": 2, "randomli": [2, 14, 70, 71], "out": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 43, 49, 51, 53, 77, 88, 104, 113, 133, 156], "valid": [2, 3, 7, 11, 12, 26, 45, 62, 90, 92, 118, 159, 161], "def": [2, 3, 6, 7, 8, 11, 12, 20, 88, 114, 118, 164], "get_cifar10_dataload": 2, "train_batch_s": 2, "int": [2, 3, 26, 36, 42, 45, 52, 56, 58, 59, 60, 62, 63, 65, 71, 75, 92, 93, 98, 101, 108, 111, 113, 118, 130, 131, 135, 136, 137, 139, 140, 143, 151, 154, 161, 162, 164, 168, 169, 171, 173], "return": [2, 3, 7, 8, 11, 12, 13, 14, 20, 22, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 65, 67, 70, 71, 73, 75, 77, 83, 86, 87, 88, 90, 91, 92, 93, 97, 98, 101, 102, 103, 104, 106, 108, 111, 112, 113, 114, 115, 116, 117, 118, 131, 135, 136, 137, 139, 140, 143, 144, 147, 148, 149, 153, 154, 155, 157, 159, 161, 162, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176], "val": [2, 162, 171], "loader": [2, 6, 7, 8, 9, 11, 20, 70, 106, 118, 149, 173], "normal": [2, 12, 20, 29, 38, 70, 93, 106, 124, 126, 149, 173], "mean": [2, 12, 16, 20, 44, 60, 102, 149, 171], "0": [2, 3, 5, 11, 12, 16, 19, 20, 26, 36, 45, 51, 52, 59, 60, 64, 65, 71, 72, 73, 75, 86, 88, 100, 102, 111, 113, 118, 125, 127, 130, 131, 139, 154, 168, 173, 174, 175], "4914": 2, "4822": 2, "4465": 2, "std": [2, 171], "2470": 2, "2435": 2, "2616": 2, "train_dataset": 2, "cifar10": 2, "root": [2, 34, 58, 91, 165], "true": [2, 3, 11, 12, 16, 20, 26, 33, 34, 36, 37, 44, 45, 48, 50, 59, 60, 62, 65, 70, 72, 73, 77, 88, 91, 92, 97, 108, 111, 113, 114, 118, 122, 125, 127, 128, 130, 131, 139, 140, 159, 164, 170, 173], "compos": [2, 58], "totensor": 2, "randomhorizontalflip": 2, "randomcrop": 2, "32": [2, 11, 12, 72, 93, 100, 113], "4": [2, 3, 4, 9, 11, 12, 14, 16, 17, 18, 20, 31, 43, 58, 70, 75, 100, 106, 113, 139, 143], "n_trainval": 2, "len": [2, 3], "n_train": 2, "9": [2, 11, 12, 36, 65, 100], "id": [2, 3, 27, 61, 161], "arang": 2, "shuffl": [2, 3, 175], "train_id": 2, "val_id": 2, "arrai": [2, 3, 19, 42, 43, 44, 112, 131, 176], "val_dataset": 2, "test_dataset": 2, "fals": [2, 3, 12, 33, 34, 36, 37, 42, 44, 45, 48, 50, 59, 60, 70, 72, 73, 77, 88, 90, 91, 92, 97, 111, 112, 113, 114, 118, 122, 125, 127, 128, 130, 131, 139, 164, 168, 170, 173, 178], "num_work": 2, "min": [2, 3, 11, 12, 18, 70, 93, 120, 122, 162, 167, 171], "cpu_count": 2, "train_load": [2, 7, 8, 11, 12, 20], "util": [2, 3, 8, 11, 12, 13, 14, 22, 25, 27, 29, 31, 34, 40, 41, 42, 43, 56, 58, 61, 62, 63, 65, 68, 86, 91, 94, 114, 117, 148, 153, 164, 167, 168, 169, 170, 171, 172, 173, 174, 176], "dataload": [2, 3, 11, 12, 14, 20, 168], "pin_memori": 2, "val_load": [2, 7, 11, 12], "batch_siz": [2, 3, 19, 45, 130, 168], "1024": [2, 31, 113], "test_load": 2, "print": [2, 5, 11, 12, 20, 33, 34, 44, 70, 86, 88, 106, 118, 149, 172], "variant": [2, 18, 27, 43], "name": [2, 3, 5, 19, 22, 34, 41, 42, 44, 45, 50, 51, 53, 58, 67, 70, 72, 73, 77, 86, 90, 92, 97, 98, 100, 104, 106, 108, 113, 114, 116, 118, 140, 142, 144, 155, 164, 167, 168, 173, 174], "20": [2, 3], "sinc": [2, 3, 16, 20, 70, 90, 106, 111, 116], "ar": [2, 3, 4, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 27, 34, 36, 37, 41, 44, 45, 48, 49, 51, 58, 59, 60, 61, 62, 65, 70, 72, 73, 75, 86, 88, 90, 91, 92, 97, 100, 102, 106, 113, 114, 117, 118, 128, 130, 131, 139, 140, 142, 149, 157, 161, 164, 165, 167, 173], "veri": [2, 3, 18], "small": [2, 18, 20, 101, 161], "find": [2, 3, 10, 11, 12, 13, 14, 20, 34, 36, 41, 45, 101, 108, 143], "detail": [2, 3, 5, 6, 7, 8, 10, 11, 12, 17, 18, 19, 20, 44, 48, 70, 72, 97, 100, 103, 106, 113, 114, 118, 131, 139, 142, 149, 151, 154], "paper": [2, 11, 36, 52, 102, 113, 120, 149], "an": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 33, 34, 36, 37, 40, 43, 45, 48, 49, 53, 56, 58, 60, 62, 70, 71, 72, 73, 77, 86, 87, 88, 91, 92, 93, 94, 96, 100, 101, 102, 106, 108, 111, 112, 113, 114, 116, 117, 118, 120, 131, 139, 142, 144, 149, 157, 161, 164, 173, 175], "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 26, 27, 44, 51, 72, 73, 75, 86, 88, 90, 91, 93, 94, 96, 100, 102, 114, 117, 118, 133, 142, 156, 164, 168, 175], "regular": [2, 6, 12, 14, 17, 20, 44, 70, 71, 73, 89, 92, 93, 144, 149, 161], "pytorch": [2, 3, 5, 10, 11, 12, 14, 15, 18, 22, 52, 73, 88, 89, 92, 113, 114, 117, 118, 120, 122, 139, 140, 168, 173, 176], "anyth": [2, 118], "new": [2, 15, 19, 22, 42, 53, 71, 77, 87, 88, 90, 92, 101, 104, 116, 135, 140], "add": [2, 3, 13, 16, 22, 34, 37, 41, 44, 70, 91, 106, 118, 154, 164, 165, 173], "some": [2, 3, 7, 11, 12, 20, 34, 41, 43, 48, 50, 58, 65, 94, 112, 120, 164], "helper": [2, 36, 43], "_weights_init": 2, "m": [2, 3, 19, 113, 139, 143, 165], "isinst": [2, 3, 13], "linear": [2, 3, 4, 11, 12, 20, 22, 29, 34, 58, 59, 61, 72, 86, 100, 108, 113, 118, 127, 128, 140, 142, 154, 164], "conv2d": [2, 11, 12, 72, 73, 86, 93, 100, 113, 125, 139, 142, 164], "init": [2, 38, 130, 154, 161], "kaiming_normal_": 2, "lambdalay": 2, "modul": [2, 3, 5, 8, 13, 14, 16, 22, 24, 25, 27, 28, 30, 32, 35, 36, 38, 39, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 117, 118, 119, 122, 123, 124, 126, 128, 129, 130, 131, 132, 133, 134, 138, 140, 141, 142, 144, 146, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 170, 173, 178], "__init__": [2, 20, 26, 27, 31, 36, 38, 51, 52, 56, 59, 86, 88, 91, 92, 93, 97, 102, 108, 111, 112, 114, 122, 130, 131, 135, 154, 161, 162, 164, 165, 174], "self": [2, 3, 20, 87, 88, 91, 92, 93, 114, 128, 130, 161, 164], "lambd": 2, "super": [2, 3, 12, 20, 114], "forward": [2, 3, 6, 7, 8, 9, 11, 12, 17, 20, 34, 50, 51, 52, 65, 70, 73, 88, 97, 106, 114, 117, 118, 120, 122, 128, 130, 131, 139, 148, 149, 154, 159, 165, 168, 173, 178], "x": [2, 3, 9, 14, 20, 36, 70, 106, 111, 112, 143, 154, 171, 173], "num_block": 2, "num_class": 2, "in_plan": 2, "16": [2, 3, 11, 18, 31, 34, 86, 93, 106], "sequenti": [2, 12, 72, 73, 79, 86, 100, 113, 131, 142], "kernel_s": [2, 72, 86, 88, 100, 164, 173], "stride": [2, 3, 111], "pad": [2, 3, 59, 61, 62, 173], "bia": [2, 3, 20, 59, 114, 139], "batchnorm2d": [2, 72, 86, 100], "relu": [2, 34], "_make_lay": 2, "64": [2, 3, 11, 12, 31, 62, 113], "adaptiveavgpool2d": [2, 129], "flatten": 2, "appli": [2, 3, 4, 9, 13, 14, 15, 18, 22, 33, 36, 37, 50, 51, 91, 113, 118, 126, 131, 139, 143, 168], "plane": 2, "downsampl": 2, "none": [2, 3, 5, 20, 26, 27, 33, 34, 36, 37, 40, 42, 44, 45, 48, 50, 51, 52, 53, 56, 58, 59, 60, 62, 63, 65, 70, 71, 72, 77, 83, 86, 87, 88, 90, 91, 92, 93, 97, 98, 100, 101, 102, 103, 104, 106, 108, 111, 112, 113, 114, 116, 117, 118, 125, 127, 128, 130, 131, 139, 140, 142, 144, 145, 147, 149, 159, 161, 162, 164, 165, 167, 168, 169, 173, 174, 175], "lambda": [2, 3, 9, 13, 14, 88, 102], "constant": [2, 3, 34, 42, 45, 58, 61, 65, 113, 161, 164], "append": [2, 3, 16, 92, 118], "ckpt": 2, "load_state_dict": [2, 7, 8, 11, 50, 91], "load": [2, 3, 7, 12, 13, 14, 15, 16, 18, 19, 27, 32, 45, 50, 56, 61, 62, 91, 96, 97, 101, 115, 131, 167, 168], "resnet32": 2, "cosinelrwithwarmup": 2, "lr_schedul": [2, 3], "_lrschedul": 2, "warmup_step": 2, "decay_step": 2, "warmup_lr": 2, "float": [2, 3, 17, 26, 36, 42, 43, 51, 52, 58, 59, 63, 70, 88, 93, 97, 101, 102, 106, 108, 111, 113, 118, 125, 127, 128, 130, 137, 139, 148, 171, 172, 173, 174, 175], "last_epoch": 2, "get_lr": 2, "base_lr": 2, "els": [2, 3, 34, 45, 58], "current_step": 2, "co": [2, 3], "pi": 2, "get_optimizer_schedul": 2, "lr": [2, 3], "weight_decai": [2, 3], "sgd": 2, "filter": [2, 20, 113, 114, 118], "p": [2, 3], "requires_grad": [2, 3], "paramet": [2, 11, 12, 20, 22, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 56, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 73, 83, 86, 87, 88, 90, 91, 92, 93, 97, 98, 101, 102, 103, 106, 108, 109, 111, 112, 113, 114, 117, 118, 122, 130, 131, 135, 136, 137, 139, 140, 143, 144, 145, 147, 148, 149, 153, 154, 157, 159, 161, 162, 164, 165, 167, 168, 170, 171, 172, 173, 175, 176], "momentum": 2, "train_one_epoch": 2, "loss_fn": [2, 8], "given": [2, 3, 4, 7, 8, 9, 11, 12, 15, 22, 29, 34, 42, 45, 63, 70, 71, 88, 90, 92, 97, 98, 106, 113, 114, 118, 131, 140, 143, 148, 149, 164, 165, 168, 173, 175], "epoch": [2, 3, 11, 12, 20], "epoch_loss": 2, "img": 2, "label": [2, 3, 8, 52, 168, 173], "output": [2, 3, 8, 13, 16, 19, 20, 26, 34, 41, 42, 44, 45, 48, 50, 52, 58, 70, 88, 92, 106, 108, 113, 118, 131, 139, 154, 164, 173], "loss": [2, 3, 4, 7, 8, 11, 17, 20, 36, 48, 50, 51, 70, 102, 106, 108, 118, 149], "item": [2, 3, 44, 62, 90, 164], "zero_grad": [2, 3, 8, 173], "backward": [2, 3, 7, 8, 11, 17, 22, 34, 60, 65, 70, 102, 106, 118, 120, 139, 165, 173], "no_grad": [2, 3], "percentag": [2, 3, 11, 70, 106, 118], "eval": [2, 3, 70, 71, 73, 106, 178], "correct": [2, 5, 71, 101, 108, 114, 118, 128], "total": [2, 3, 11, 12, 20, 50, 51, 102, 113, 118], "predict": [2, 3, 4, 16, 52, 168], "argmax": 2, "dim": [2, 3, 22, 113, 161], "detach": [2, 3, 176], "cpu": [2, 3, 11, 62, 111], "sum": [2, 3, 34, 51, 75, 102, 108, 143], "100": [2, 3, 111], "loss_fn_default": 2, "cross_entropi": 2, "train_model": 2, "num_epoch": 2, "print_freq": 2, "25": [2, 11, 12, 18, 100], "ckpt_path": 2, "temp_saved_model": 2, "pth": [2, 3, 7, 11, 12, 14, 15, 96], "allow": [2, 3, 4, 13, 14, 19, 20, 22, 50, 92, 97], "u": [2, 3, 21, 161], "obtain": [2, 3, 8, 11, 12, 13, 14, 16, 51, 86], "need": [2, 3, 5, 8, 11, 12, 13, 15, 16, 17, 20, 22, 51, 56, 58, 59, 65, 70, 91, 92, 93, 96, 106, 113, 118, 138, 139, 173], "best_val_acc": 2, "best_ep": 2, "ep": [2, 20, 59, 114], "rang": [2, 3, 12, 17, 44, 93, 113, 120, 131, 139, 140], "train_loss": [2, 3], "val_acc": 2, "3d": [2, 26, 125, 126], "t": [2, 3, 5, 34, 41, 44, 86, 88, 97, 111, 116, 120, 130, 140, 165, 175], "4f": 2, "2f": 2, "gave": 2, "uncom": 2, "statement": [2, 20], "see": [2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 18, 19, 20, 27, 70, 92, 102, 106, 111, 112, 113, 114, 118, 139, 149, 173], "6": [2, 3, 11, 19, 36, 75], "should": [2, 3, 6, 11, 12, 13, 15, 19, 20, 22, 31, 34, 40, 41, 43, 44, 49, 51, 58, 59, 70, 71, 73, 87, 88, 90, 91, 92, 93, 96, 101, 106, 113, 114, 117, 118, 135, 149, 154, 157, 164, 173], "30": [2, 3, 20, 118], "hyperparamet": [2, 11, 74, 86, 87, 88, 92, 93, 97, 106], "compar": [2, 3, 11, 12, 17, 113, 130, 173], "origin": [2, 3, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 44, 49, 50, 51, 61, 67, 70, 73, 88, 91, 92, 93, 106, 108, 113, 114, 118, 128, 130, 135, 154, 161, 173, 175], "setup": [2, 3, 6, 8, 9, 20, 102, 114], "describ": [2, 11, 12, 13, 14, 15, 16, 20, 36, 49, 53, 70, 73, 76, 77, 86, 87, 91, 92, 104, 106, 116, 118, 131, 144, 149, 155, 157, 164, 165], "also": [2, 3, 4, 6, 7, 8, 11, 12, 13, 14, 20, 22, 42, 44, 61, 70, 73, 86, 88, 92, 94, 101, 108, 111, 113, 114, 118, 120, 164, 173, 175], "reduc": [2, 4, 6, 9, 12, 13, 14, 16, 17, 48, 50, 51, 52, 70, 106, 113, 118, 130, 137, 140, 149, 175], "whole": [2, 3, 13, 17, 94, 164, 165], "cost": [2, 4, 11, 17, 101], "7": [2, 3, 36, 75], "512": [2, 11, 12, 20, 31, 113, 118, 168], "120": 2, "learning_r": [2, 3], "128": [2, 3, 11, 20, 106, 111, 113, 118, 139], "1e": [2, 3, 59], "batch_per_epoch": 2, "alreadi": [2, 3, 5, 13, 41, 48, 91], "verifi": [2, 20], "45000": 2, "5000": 2, "10000": 2, "resnet20_model": 2, "0049": 2, "22": 2, "82": 2, "0006": 2, "78": 2, "84": 2, "50": [2, 3, 18, 20], "0004": 2, "85": [2, 36, 71], "06": 2, "75": [2, 36, 100], "0002": 2, "88": 2, "12": [2, 3, 5, 12, 22, 167], "0001": 2, "90": 2, "34": 2, "0000": 2, "80": 2, "92": 2, "119": 2, "97": 2, "have": [2, 3, 5, 11, 12, 14, 16, 17, 18, 20, 22, 31, 42, 44, 51, 56, 73, 90, 92, 102, 113, 114, 118, 161, 164, 173], "now": [2, 3, 11, 12, 22, 41, 116], "establish": 2, "so": [2, 3, 11, 20, 44, 55, 59, 90, 92, 111, 112, 130, 161], "far": [2, 55, 112], "seen": [2, 173], "advanc": [2, 4, 6, 9, 17, 108], "state": [2, 3, 4, 7, 11, 12, 13, 20, 50, 53, 56, 63, 70, 71, 77, 91, 94, 96, 97, 103, 104, 106, 108, 116, 128, 131, 140, 147, 161, 164, 173], "art": [2, 4], "algorithm": [2, 3, 4, 6, 7, 11, 12, 18, 19, 20, 22, 36, 49, 71, 73, 77, 86, 89, 90, 91, 94, 97, 99, 101, 102, 103, 104, 106, 113, 117, 118, 141, 144, 147, 148, 149, 157], "enabl": [2, 3, 4, 6, 13, 14, 15, 16, 20, 22, 34, 50, 88, 93, 96, 108, 113, 118, 125, 127, 128, 130, 131, 140, 161, 164, 167], "one": [2, 3, 5, 8, 11, 12, 13, 16, 17, 58, 59, 62, 86, 88, 91, 92, 111, 114, 133, 140, 143, 156, 161, 164], "complementari": 2, "mode": [2, 3, 7, 8, 9, 11, 12, 13, 22, 44, 48, 49, 70, 71, 72, 73, 90, 91, 97, 100, 101, 106, 113, 130, 131, 140, 142, 149, 151, 157], "creat": [2, 3, 5, 13, 14, 19, 20, 34, 40, 42, 56, 60, 91, 111, 113, 131, 135, 143, 148, 154, 168, 173], "space": [2, 3, 7, 44, 70, 71, 73, 86, 88, 92, 97, 98, 101, 106, 108, 175], "method": [2, 4, 7, 8, 9, 10, 11, 12, 14, 15, 20, 27, 34, 43, 44, 70, 73, 87, 88, 90, 91, 92, 97, 106, 111, 113, 114, 117, 118, 128, 130, 131, 135, 137, 139, 152, 165, 169, 173, 178], "recommend": [2, 3, 4, 5, 7, 11, 12, 18, 20, 70, 106, 113, 139, 149], "comput": [2, 3, 8, 11, 12, 13, 17, 18, 20, 22, 36, 48, 50, 51, 52, 70, 93, 106, 111, 113, 131, 136, 137, 140, 143, 149, 170, 171, 176], "vision": [2, 11, 12, 19, 22, 106], "pretrain": [2, 3, 4, 7, 8, 11], "which": [2, 3, 7, 8, 11, 12, 13, 15, 16, 17, 20, 22, 34, 41, 43, 50, 70, 72, 86, 87, 89, 90, 91, 93, 97, 100, 101, 102, 106, 108, 111, 113, 114, 117, 118, 120, 128, 130, 131, 140, 142, 143, 164, 173, 175], "maxim": [2, 11, 17, 70, 97, 106, 143, 165], "score": [2, 3, 7, 11, 12, 16, 70, 93, 97, 102, 106, 108, 118, 149], "while": [2, 3, 4, 8, 11, 12, 17, 20, 22, 70, 92, 97, 102, 108, 138], "meet": [2, 11, 12, 13, 18, 20, 108, 140], "mcore_gpt_minitron": [2, 11, 100, 104, 106], "develop": [2, 4, 11], "research": [2, 11, 173], "gpt": [2, 11, 12, 14, 22, 106, 108], "style": [2, 11, 12, 22, 86, 106, 139], "megatron": [2, 4, 11, 12, 22, 103, 106, 133, 146], "lm": [2, 4, 11], "framework": [2, 4, 10, 11, 20, 22], "activ": [2, 5, 11, 12, 13, 17, 18, 20, 36, 42, 44, 58, 59, 73, 75, 83, 86, 88, 92, 93, 103, 108, 113, 118, 123, 139, 145, 154, 173], "magnitud": [2, 11, 14, 103, 144, 149], "mlp": [2, 4, 11, 12, 58, 59, 64, 118], "attent": [2, 4, 11, 12, 16, 20, 22, 58, 59, 63, 102, 103], "head": [2, 4, 11, 12, 16, 22, 34, 58, 102, 103, 151, 157], "gqa": [2, 11, 12], "queri": [2, 11], "gradna": [2, 3, 7, 11, 12, 70, 100, 104, 106], "light": [2, 7, 11], "languag": [2, 3, 11, 16, 102, 106], "hug": [2, 3, 11, 12, 20, 22, 67, 106], "face": [2, 3, 11, 12, 20, 22, 67, 106, 118, 157], "bert": [2, 7, 11, 12, 21, 22, 106, 108], "j": [2, 11, 14, 22, 106], "gradient": [2, 3, 7, 11, 70, 102, 106, 108, 118, 120, 139, 140, 149, 173], "inform": [2, 3, 7, 8, 11, 12, 13, 54, 59, 70, 85, 91, 106, 108, 113, 130, 131, 143, 149, 160, 162, 164], "checkout": [2, 6, 7, 9, 11], "github": [2, 3, 4, 6, 9, 10, 21, 26, 27, 29, 60, 139, 173, 177], "convert": [2, 3, 4, 8, 11, 14, 20, 22, 33, 42, 43, 44, 49, 51, 53, 58, 59, 60, 61, 63, 65, 66, 67, 68, 70, 71, 72, 73, 77, 88, 91, 92, 97, 100, 101, 104, 106, 116, 135, 136, 137, 142, 144, 149, 153, 155, 157, 161, 165, 172, 173, 175, 176, 178], "its": [2, 3, 5, 8, 11, 12, 13, 14, 16, 22, 42, 49, 58, 65, 70, 73, 86, 91, 92, 97, 106, 108, 113, 114, 118, 131, 149, 157, 164, 165, 173], "flop": [2, 3, 7, 11, 12, 70, 88, 97, 106], "latenc": [2, 11, 12, 16, 19, 70, 97], "opt": [2, 3, 7, 11, 12, 14, 15, 16, 18, 20, 22, 86, 91, 96], "mtp": [2, 3, 4, 7, 11, 12, 104], "gener": [2, 3, 4, 7, 11, 16, 17, 19, 29, 34, 44, 45, 52, 59, 61, 70, 86, 87, 88, 89, 90, 91, 92, 93, 98, 113, 143, 147, 164, 175], "sai": 2, "look": [2, 3, 11, 12, 20, 41, 51, 90, 92, 159], "most": [2, 3, 7, 11, 12, 14, 17, 18, 20, 70], "30m": 2, "param": [2, 3, 11, 12, 19, 70, 106, 173], "upper": [2, 11, 12, 70, 71, 97, 106, 122], "bound": [2, 3, 11, 12, 18, 51, 63, 70, 71, 88, 97, 106, 122, 164], "valu": [2, 3, 12, 13, 17, 19, 20, 22, 34, 42, 43, 45, 48, 49, 50, 51, 52, 53, 59, 63, 64, 70, 73, 75, 77, 90, 92, 93, 101, 102, 104, 106, 108, 112, 113, 116, 117, 118, 128, 131, 139, 140, 144, 145, 149, 155, 157, 164, 173], "either": [2, 3, 8, 11, 13, 14, 16, 40, 44, 88, 92, 164, 173], "absolut": [2, 11, 70, 112, 139, 140], "30e6": 2, "string": [2, 26, 49, 58, 65, 73, 86, 88, 91, 106, 111, 113, 114, 117, 118, 143, 149, 157, 172, 173], "addit": [2, 8, 11, 12, 13, 16, 38, 58, 70, 71, 87, 90, 91, 92, 97, 106, 108, 113, 114, 118, 149, 164], "final": [2, 7, 11, 12, 16, 20, 52, 58, 92, 97], "specifi": [2, 3, 4, 7, 11, 12, 13, 14, 20, 44, 45, 48, 49, 51, 53, 72, 73, 77, 86, 87, 88, 91, 92, 94, 100, 104, 106, 108, 111, 113, 114, 116, 117, 118, 140, 142, 143, 144, 149, 155, 157, 167, 168, 174, 176], "custom": [2, 3, 12, 13, 15, 19, 27, 42, 44, 73, 90, 92, 113, 114, 135], "configur": [2, 3, 6, 9, 11, 12, 13, 14, 16, 20, 22, 40, 48, 49, 70, 71, 72, 73, 86, 88, 90, 92, 93, 94, 97, 98, 100, 101, 106, 108, 114, 118, 135, 142, 149, 151, 157, 168, 175], "get": [2, 3, 7, 11, 20, 26, 36, 42, 58, 63, 71, 83, 87, 88, 90, 92, 94, 97, 98, 102, 103, 108, 113, 131, 140, 143, 147, 148, 161, 164, 165, 168, 173, 174], "grain": [2, 14, 17], "select": [2, 3, 20, 29, 36, 44, 55, 71, 88, 92, 117, 143, 175], "rel": 2, "smaller": [2, 4, 8, 11, 13, 14], "finer": 2, "could": [2, 3, 8, 13, 18, 20, 26, 92, 93, 113, 114, 118, 164], "effect": [2, 4, 6, 9, 13, 17, 20, 139], "case": [2, 3, 6, 9, 12, 13, 14, 18, 20, 51, 62, 70, 92, 106, 113], "why": 2, "howev": [2, 12, 20, 92, 108, 118, 161], "default": [2, 3, 5, 8, 11, 12, 19, 20, 22, 29, 38, 40, 44, 48, 52, 58, 60, 70, 71, 72, 73, 77, 86, 88, 90, 92, 93, 97, 100, 102, 103, 106, 108, 111, 113, 114, 122, 131, 139, 140, 142, 143, 147, 148, 149, 151, 164, 165, 173, 175], "itself": [2, 13, 16, 131], "channel": [2, 11, 12, 17, 18, 19, 52, 92, 111, 113, 131, 140, 173], "choic": [2, 3, 12, 18, 20, 44, 86, 88, 92, 93, 102, 108, 118, 175], "fastnasconfig": [2, 11, 100, 106], "channel_divisor": [2, 11, 72, 86, 100], "feature_divisor": [2, 72, 100], "dummy_input": [2, 3, 7, 11, 12, 70, 88, 97, 106, 173], "randn": [2, 7, 11, 12, 19], "wrap": [2, 6, 7, 8, 11, 12, 13, 20, 48, 73, 90, 91, 135, 165, 173], "onli": [2, 3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 29, 33, 34, 36, 38, 41, 42, 44, 48, 49, 55, 58, 59, 61, 65, 70, 73, 90, 92, 96, 101, 102, 106, 111, 113, 117, 118, 120, 122, 130, 131, 139, 145, 159, 164, 165, 172, 173], "input": [2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 19, 20, 22, 26, 31, 34, 36, 38, 41, 42, 43, 44, 45, 50, 63, 70, 75, 88, 92, 106, 111, 113, 114, 118, 120, 122, 126, 128, 130, 131, 135, 136, 137, 139, 140, 149, 154, 161, 164, 168, 173, 176], "act": [2, 7, 8, 11, 12], "score_func": [2, 7, 11, 12, 70, 97, 106, 178], "pruned_model": [2, 3, 7, 11], "_": [2, 3, 51, 88], "data_load": [2, 3, 6, 7, 9, 11, 12, 14, 20, 70, 106, 118, 149, 173], "checkpoint": [2, 3, 4, 7, 9, 11, 12, 13, 14, 16, 22, 48, 50, 59, 60, 64, 65, 67, 68, 70, 89, 91, 96, 97, 106, 108, 131], "modelopt_seaarch_checkpoint_fastna": 2, "futur": [2, 11, 12, 14, 16, 20, 22, 149], "modelopt_pruned_model_fastna": 2, "profil": [2, 26, 70, 106, 173], "39": 2, "centroid": [2, 11, 12, 70, 175], "max": [2, 3, 11, 12, 17, 18, 20, 26, 33, 36, 44, 59, 70, 75, 93, 113, 117, 118, 120, 122, 125, 127, 128, 130, 139, 162, 171], "result": [2, 3, 12, 70, 86, 88, 92, 106, 118, 154, 165, 175], "ratio": [2, 11, 12, 20, 52, 70, 113, 118, 143], "24": 2, "33m": [2, 12], "27": [2, 12], "57m": 2, "40": [2, 12], "55m": 2, "67": [2, 72], "94k": 2, "141": 2, "63k": 2, "268": 2, "35k": 2, "95": [2, 36], "satisfi": [2, 11, 12, 70, 97, 106, 167], "00m": 2, "summari": [2, 11, 12, 20, 86, 88, 118], "depth": [2, 4, 12, 76, 79, 162], "out_channel": [2, 11, 12, 92], "in_channel": [2, 11, 12, 93], "conv1": [2, 11, 12], "bn1": [2, 11, 12], "num_featur": [2, 11, 12], "conv2": [2, 11, 12], "48": 2, "hparam": [2, 11, 12, 70, 75, 76, 86, 87, 88, 92, 98, 101, 102, 108], "size": [2, 3, 4, 11, 12, 13, 17, 18, 20, 22, 43, 45, 48, 56, 58, 59, 63, 70, 92, 98, 106, 113, 118, 131, 136, 137, 143, 154, 168, 169, 173], "12e": 2, "02": 2, "note": [2, 3, 5, 8, 11, 12, 20, 27, 29, 33, 34, 38, 40, 41, 45, 48, 50, 56, 70, 72, 73, 91, 92, 93, 100, 106, 116, 130, 142, 145, 161, 164, 165], "within": [2, 4, 11, 12, 13, 19, 94, 106, 113, 139, 140, 161, 165, 172], "begin": [2, 97], "pre": [2, 5, 7, 11, 12, 13, 14, 20, 41, 42, 44, 63, 88, 97, 103, 130], "estim": [2, 17, 22, 93, 102, 103, 108, 113, 118, 139], "runtim": [2, 11, 12, 70, 106, 149], "longer": [2, 3, 11, 12, 14, 20, 22, 62, 92, 113, 138, 149], "minut": [2, 5, 11, 12, 18], "consid": [2, 3, 11, 12, 18, 29], "subsampl": [2, 11, 12, 118], "subset": [2, 11, 12, 71], "org": [2, 3, 5, 52, 102, 103, 120], "doc": [2, 3, 7, 26, 60, 90, 139], "stabl": [2, 4], "html": 2, "subset_dataset": [2, 11, 12], "indic": [2, 3, 11, 12, 44, 49, 70, 71, 73, 75, 86, 91, 93, 97, 101, 102, 106, 113, 116, 139, 149, 157, 161, 164, 173, 175], "collect": [2, 3, 12, 20, 27, 34, 41, 56, 108, 109, 111, 112, 113, 131, 148, 165], "statist": [2, 3, 11, 20, 70, 109, 113, 118, 131, 140], "18": [2, 12, 13], "00": 2, "lt": [2, 113], "76it": 2, "cur": 2, "num_satisfi": [2, 71], "11": [2, 5, 167], "17": 2, "43": [2, 11], "39it": 2, "best_subnet_constraint": 2, "173": 2, "88k": 2, "29": 2, "64m": 2, "60": [2, 7, 11, 70, 106], "37": 2, "As": [2, 8, 13, 139], "6m": 2, "ha": [2, 3, 5, 8, 11, 13, 18, 20, 31, 34, 45, 56, 70, 91, 92, 93, 97, 118, 122, 140, 164], "drop": [2, 3, 12, 22], "common": [2, 7, 11, 17, 20, 27, 41, 43, 45, 61, 164], "necessari": [2, 3, 8, 13, 73, 88, 130, 131, 135, 145], "To": [2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 20, 22, 72, 100, 113, 118, 142], "simpli": [2, 7, 8, 11, 12, 20, 70, 92, 161], "repeat": [2, 11, 12, 20, 165, 171], "1x": [2, 3, 11, 12], "5x": [2, 11, 12], "learn": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 17, 20, 50, 53, 77, 89, 104, 113, 118, 122, 131, 140], "rate": [2, 3, 11, 12, 20], "constitut": [2, 12, 94], "trade": [2, 10, 12, 20], "off": [2, 10, 12, 20, 88], "between": [2, 3, 8, 10, 11, 12, 13, 48, 50, 57, 86, 111, 165], "15": [2, 3], "modelopt_pruned_model_fastnas_finetun": 2, "0011": 2, "79": 2, "0003": 2, "87": 2, "62": 2, "58": 2, "70": 2, "101": 2, "13": [2, 5], "vanilla": [2, 87, 92], "optimized_model": 2, "28": [2, 11], "conclus": 2, "comparison": [2, 11], "summar": [2, 12, 18], "268k": 2, "174k": 2, "improv": [2, 12, 18], "littl": [2, 11, 12, 18], "good": [2, 11, 12], "job": 2, "next": [2, 6, 7, 8, 9, 11, 12, 16, 22, 31, 34, 144], "show": [3, 6, 8, 11, 15, 20, 48, 72, 90, 100, 113, 142, 151], "compress": [3, 4, 13, 14, 18, 20, 108, 118], "larg": [3, 4, 16, 18, 43], "question": 3, "answer": 3, "combin": [3, 8, 13, 15, 16], "specif": [3, 5, 11, 12, 13, 14, 18, 34, 53, 70, 72, 73, 92, 94, 100, 106, 108, 113, 114, 135, 142, 160, 161, 162, 164, 168], "fine": [3, 7, 9, 13, 14, 17, 20, 70, 97, 106, 149, 161], "tune": [3, 7, 9, 13, 14, 17, 20, 70, 97, 106, 149], "int8": [3, 4, 6, 18, 19, 22, 33, 42, 44, 58, 113, 131, 137], "precis": [3, 10, 18, 19, 20, 44, 113, 131], "post": [3, 4, 6, 17, 22, 88, 97, 173], "train": [3, 4, 6, 7, 13, 15, 16, 22, 49, 62, 70, 71, 73, 88, 101, 106, 130, 149, 178], "awar": [3, 4, 6, 11, 12, 22, 36], "export": [3, 6, 10, 13, 14, 20, 22, 49, 53, 58, 60, 62, 64, 65, 67, 68, 70, 71, 72, 73, 77, 86, 89, 92, 94, 97, 104, 106, 113, 116, 131, 138, 140, 144, 149, 173], "onnx": [3, 4, 5, 6, 10, 18, 20, 22, 29, 30, 31, 33, 34, 36, 37, 40, 41, 42, 43, 45, 70, 97, 106, 113, 138, 139, 173], "option": [3, 5, 7, 11, 12, 14, 15, 16, 22, 34, 41, 44, 58, 63, 70, 86, 91, 92, 93, 97, 103, 106, 114, 149, 175], "been": [3, 16, 22, 91, 118, 164], "24gb": 3, "a5000": 3, "complet": 3, "stage": [3, 73, 86, 131], "spent": 3, "view": [3, 17], "integr": [3, 4, 8], "point": [3, 11, 17, 18, 42, 113], "highlight": 3, "sourc": [3, 26, 53, 60, 77, 104, 116, 133, 144, 155, 156, 167], "script": [3, 4, 13, 27], "bert_prune_distill_quant": 3, "py": [3, 27, 29, 60, 173], "adapt": [3, 11], "run_qa_no_train": 3, "utils_qa": 3, "blob": [3, 26, 27, 29, 60, 139, 173], "c52b515e948fc12ff58ad773a0385860d0162f61": 3, "copyright": 3, "2021": 3, "inc": 3, "team": 3, "right": [3, 10, 113, 116], "reserv": 3, "licens": [3, 5], "under": [3, 20, 60], "apach": 3, "version": [3, 5, 20, 29, 43, 52, 59, 65, 92, 127, 129, 139, 140, 161, 167], "mai": [3, 5, 8, 12, 13, 14, 17, 20, 70, 91, 92, 106, 118, 139, 149, 167], "except": [3, 58, 65, 72, 100, 101, 131, 142, 161, 165, 172], "complianc": 3, "copi": [3, 20, 22, 29, 113], "www": 3, "unless": [3, 140], "requir": [3, 6, 7, 9, 11, 12, 13, 14, 18, 20, 22, 44, 59, 70, 73, 87, 88, 106, 113, 116, 117, 118, 131, 167], "applic": [3, 12, 16], "law": 3, "agre": 3, "write": [3, 13, 44, 56, 133, 156], "softwar": [3, 4, 10], "distribut": [3, 11, 12, 14, 16, 22], "AS": 3, "basi": [3, 118], "warranti": 3, "OR": 3, "condit": 3, "OF": 3, "ani": [3, 5, 7, 8, 12, 13, 15, 22, 34, 42, 48, 49, 50, 51, 53, 56, 60, 61, 65, 67, 70, 71, 72, 73, 77, 86, 88, 90, 91, 92, 93, 96, 97, 100, 101, 102, 103, 104, 106, 108, 113, 116, 118, 131, 140, 142, 144, 145, 147, 148, 149, 153, 155, 157, 159, 161, 164, 165, 167, 170, 171, 173, 175], "kind": 3, "express": [3, 44, 72, 73, 100, 142], "impli": [3, 118], "govern": [3, 90], "permiss": 3, "limit": [3, 18], "spdx": 3, "filecopyrighttext": 3, "c": [3, 5, 13, 32, 43, 115, 164, 167], "2024": 3, "corpor": 3, "affili": 3, "identifi": [3, 5, 12, 41, 86, 159], "mit": 3, "herebi": 3, "grant": 3, "free": [3, 4, 164], "charg": 3, "person": 3, "associ": [3, 86, 87, 93, 102, 164], "document": [3, 7, 8, 10, 11, 12, 70, 106, 113, 149], "deal": 3, "restrict": [3, 11, 86, 92, 108, 118], "includ": [3, 4, 5, 11, 12, 13, 17, 22, 26, 59, 86, 92, 113, 131, 161, 164, 168], "modifi": [3, 11, 12, 14, 15, 20, 29, 34, 38, 42, 45, 50, 70, 86, 90, 91, 92, 106, 118, 145, 154, 161], "merg": [3, 59, 60, 61, 62, 63, 108], "publish": 3, "sublicens": 3, "sell": 3, "permit": 3, "whom": 3, "furnish": 3, "do": [3, 11, 14, 15, 41, 51, 56, 92, 102, 113, 116, 139, 178], "subject": [3, 18, 29, 118], "abov": [3, 11, 12, 15, 73], "notic": 3, "shall": 3, "substanti": 3, "portion": 3, "THE": 3, "BUT": 3, "NOT": [3, 111, 139], "TO": 3, "merchant": 3, "FOR": [3, 159], "particular": [3, 12, 102, 108], "AND": 3, "noninfring": 3, "IN": 3, "NO": 3, "event": 3, "author": 3, "holder": 3, "BE": 3, "liabl": 3, "claim": 3, "damag": 3, "other": [3, 11, 12, 14, 15, 17, 22, 27, 56, 62, 73, 86, 92, 108, 113, 114, 117, 161, 164, 178], "liabil": 3, "whether": [3, 12, 29, 33, 34, 42, 43, 50, 53, 56, 58, 60, 70, 71, 72, 73, 77, 88, 91, 92, 93, 97, 101, 106, 116, 139, 149, 159, 161, 162, 164, 168, 169, 173], "action": 3, "contract": 3, "tort": 3, "aris": [3, 161], "connect": [3, 12, 34, 154, 159], "WITH": 3, "showcas": [3, 22], "squad": 3, "argpars": 3, "log": [3, 33, 108], "dict": [3, 7, 11, 12, 13, 19, 26, 31, 34, 41, 42, 44, 45, 48, 49, 50, 51, 53, 56, 59, 60, 61, 63, 65, 67, 70, 71, 72, 73, 77, 86, 87, 88, 90, 91, 92, 94, 97, 100, 101, 102, 103, 104, 106, 108, 113, 114, 116, 118, 131, 142, 144, 147, 148, 149, 153, 155, 157, 159, 164, 165, 171, 173], "list": [3, 4, 5, 17, 20, 26, 33, 34, 37, 40, 41, 44, 45, 49, 50, 51, 56, 58, 59, 60, 62, 63, 65, 71, 73, 83, 86, 88, 91, 106, 108, 112, 113, 114, 118, 130, 131, 149, 157, 161, 162, 164, 167, 176], "tupl": [3, 8, 12, 13, 34, 41, 45, 48, 49, 50, 53, 56, 58, 60, 67, 70, 71, 73, 77, 88, 91, 92, 93, 97, 98, 101, 102, 104, 106, 108, 111, 112, 113, 116, 118, 130, 131, 136, 137, 140, 143, 144, 148, 149, 153, 155, 157, 164, 171, 173], "dataset": [3, 9, 11, 12, 118, 168], "evalu": [3, 6, 11, 12, 27, 70, 73, 97, 106, 118, 178], "get_logg": 3, "set_se": 3, "automodelforquestionansw": 3, "autotoken": [3, 16], "datacollatorwithpad": 3, "evalpredict": 3, "pretrainedtoken": [3, 27, 168], "schedulertyp": 3, "default_data_col": 3, "get_schedul": 3, "mtd": [3, 4, 8, 13, 51], "mto": [3, 7, 11, 12, 13, 14, 15, 16, 20, 22, 91, 96], "mtq": [3, 6, 15, 20, 22, 113, 114, 138, 168], "_deploi": [3, 5, 22], "get_onnx_byt": 3, "logger": 3, "__name__": 3, "parse_arg": 3, "input_arg": 3, "parser": 3, "argumentpars": 3, "descript": [3, 173], "finetun": [3, 11], "argument": [3, 13, 14, 29, 49, 50, 51, 70, 73, 86, 88, 91, 92, 93, 97, 101, 106, 111, 113, 117, 118, 139, 149, 157, 159, 165, 167, 168, 173], "add_argu": 3, "model_name_or_path": 3, "uncas": 3, "word": [3, 16, 26], "mask": [3, 14, 50, 52, 102, 143, 145, 147, 148, 149], "help": [3, 11, 12, 17, 38, 70, 173], "path": [3, 16, 19, 22, 26, 27, 31, 33, 34, 44, 45, 56, 60, 62, 65, 67, 68, 70, 106, 131, 167], "do_train": 3, "store_tru": 3, "per_device_train_batch_s": 3, "batch": [3, 6, 18, 20, 26, 36, 45, 70, 92, 106, 113, 118, 124, 149, 168, 173], "per_device_eval_batch_s": 3, "5e": 3, "initi": [3, 7, 8, 11, 12, 14, 15, 16, 20, 26, 31, 34, 36, 42, 48, 73, 86, 87, 91, 92, 93, 102, 108, 111, 112, 114, 122, 128, 131, 135, 138, 145, 161, 164, 165, 168, 169, 173, 174], "potenti": [3, 8, 11, 12, 13, 17, 50, 88], "warmup": 3, "period": 3, "decai": [3, 12], "lr_scheduler_typ": 3, "schedul": [3, 11, 12, 20], "cosin": [3, 12], "cosine_with_restart": 3, "polynomi": 3, "constant_with_warmup": 3, "num_warmup_step": 3, "num_train_epoch": 3, "max_train_step": 3, "overrid": [3, 50, 97], "gradient_accumulation_step": 3, "updat": [3, 16, 17, 20, 36, 42, 45, 53, 58, 62, 63, 65, 71, 77, 90, 91, 92, 101, 104, 114, 116, 131, 144, 149], "accumul": [3, 34, 44, 173], "pass": [3, 7, 11, 13, 17, 20, 50, 51, 52, 56, 70, 88, 92, 106, 113, 117, 118, 120, 131, 139, 140, 154, 159, 165, 173, 178], "preprocessing_num_work": 3, "process": [3, 8, 11, 13, 14, 16, 17, 19, 44, 49, 53, 56, 60, 62, 72, 73, 77, 88, 91, 92, 97, 100, 102, 103, 104, 106, 142, 149, 157, 159, 161, 168, 169, 172, 173, 175, 178], "preprocess": [3, 168], "output_dir": 3, "with_track": 3, "experi": 3, "tracker": 3, "checkpointing_step": 3, "variou": [3, 4, 9, 15, 16, 42, 74, 89, 91, 102, 106, 114, 131, 149], "everi": [3, 43], "n": [3, 5, 102, 143], "resume_from_last_ckpt": 3, "continu": [3, 4, 11, 12, 14, 149], "latest": [3, 5], "misc": [3, 22], "max_seq_length": 3, "384": 3, "maximum": [3, 12, 17, 63, 70, 106, 112, 140, 168], "sequenc": [3, 29, 42, 43, 86, 88, 93, 94, 108, 130, 170, 175], "length": [3, 16, 26, 93, 130, 140, 168], "token": [3, 16, 22, 26, 27, 68, 113, 168], "truncat": 3, "shorter": 3, "pad_to_max_lengh": 3, "pad_to_max_length": 3, "sampl": [3, 7, 11, 12, 16, 20, 26, 31, 70, 71, 86, 88, 92, 101, 168, 173, 175], "dynam": [3, 12, 13, 22, 35, 38, 54, 72, 73, 78, 79, 80, 81, 82, 85, 86, 90, 98, 100, 113, 145, 149, 164, 173], "doc_strid": 3, "when": [3, 5, 7, 12, 13, 14, 15, 18, 22, 34, 48, 50, 56, 73, 86, 88, 90, 91, 92, 93, 96, 111, 113, 130, 131, 145, 164, 165, 168, 178], "up": [3, 4, 5, 6, 11, 12, 14, 16, 18, 49, 56, 73, 89, 92, 97, 106, 131, 149, 157], "long": [3, 173], "chunk": 3, "n_best_siz": 3, "max_answer_length": 3, "becaus": [3, 11, 34, 36, 65, 88, 118, 167, 173], "start": [3, 11, 13, 34, 61, 174], "anoth": [3, 34, 91, 92, 161, 162], "debug": [3, 61, 113, 159], "max_train_sampl": 3, "quicker": 3, "max_eval_sampl": 3, "do_modelopt_prun": 3, "modelopt_prune_flops_perc": 3, "retain": [3, 14, 140], "modelopt_quantize_cfg": 3, "do_modelopt_distil": 3, "teacher": [3, 4, 8, 48, 49, 50, 52], "must": [3, 13, 17, 20, 36, 53, 72, 73, 77, 88, 91, 92, 93, 104, 106, 113, 116, 130, 140, 164, 173], "temperatur": [3, 26, 52], "restor": [3, 11, 13, 16, 21, 22, 48, 53, 61, 70, 71, 77, 89, 91, 96, 101, 104, 106, 114, 116, 131, 144, 153, 155], "modelopt_save_fil": 3, "insid": [3, 6, 58, 70, 106, 149], "modelopt_restore_path": 3, "onnx_export_fil": 3, "arg": [3, 8, 12, 13, 16, 22, 27, 48, 50, 70, 73, 88, 91, 92, 97, 106, 128, 130, 131, 132, 138, 145, 154, 161, 162, 164, 165, 172, 173, 175, 176], "saniti": 3, "check": [3, 7, 9, 12, 19, 27, 34, 45, 53, 62, 71, 77, 88, 90, 91, 92, 97, 98, 101, 104, 130, 133, 140, 156, 165, 170, 173], "rais": [3, 11, 51, 70, 73, 88, 91, 112, 122, 139, 140], "valueerror": [3, 51, 122, 139, 140], "get_datasets_and_dataload": 3, "answer_column_nam": 3, "own": [3, 8, 12, 13, 15, 20, 52, 62, 92, 113, 133, 156], "csv": 3, "txt": 3, "public": 3, "hub": 3, "column": [3, 58, 59, 140], "text": [3, 16, 26, 27, 168], "found": [3, 17, 34, 52, 70, 90, 92, 103, 106, 164], "easili": [3, 4, 8], "tweak": [3, 19], "behavior": [3, 19, 88, 91, 92, 114, 120, 164], "prepare_train_featur": 3, "lot": 3, "whitespac": 3, "left": 3, "context": [3, 16, 18, 26, 50, 59, 88, 92, 108, 114, 128, 130, 138, 139, 140, 172], "fail": [3, 45, 165], "remov": [3, 4, 11, 12, 14, 22, 34, 42, 45, 56, 92, 143, 148, 164, 173], "question_column_nam": 3, "q": [3, 34, 36, 42, 44, 58, 59, 118], "lstrip": 3, "mayb": 3, "keep": [3, 44, 87, 101, 108, 130, 135], "overflow": 3, "possibl": [3, 11, 12, 13, 70, 71, 86, 90, 92, 106, 118, 143], "give": [3, 18, 102, 173], "sever": [3, 13, 92], "featur": [3, 4, 8, 9, 12, 13, 14, 15, 16, 22, 52, 93, 97], "those": [3, 34, 41, 42, 72, 73, 88, 100, 142, 178], "overlap": 3, "bit": [3, 4, 17, 18, 43, 111, 112, 113, 139], "previou": [3, 11, 19, 20], "tokenized_exampl": 3, "pad_on_right": 3, "context_column_nam": 3, "only_second": 3, "only_first": 3, "max_length": [3, 27], "return_overflowing_token": 3, "return_offsets_map": 3, "might": [3, 18, 20, 91, 92, 118, 139, 173], "map": [3, 4, 13, 17, 34, 41, 42, 50, 52, 57, 60, 65, 86, 87, 101, 106, 108, 113, 114, 118, 159, 164], "correspond": [3, 5, 11, 16, 42, 48, 51, 53, 70, 75, 77, 86, 91, 92, 93, 101, 104, 106, 113, 116, 118, 144, 173, 175], "kei": [3, 13, 19, 20, 22, 34, 49, 51, 61, 63, 72, 73, 86, 88, 90, 91, 92, 100, 106, 113, 114, 117, 118, 142, 149, 157, 164, 173], "sample_map": 3, "pop": [3, 164], "overflow_to_sample_map": 3, "offset": 3, "charact": 3, "posit": [3, 16, 50, 58, 70, 106, 113], "start_posit": 3, "end_posit": 3, "offset_map": 3, "enumer": [3, 70, 106], "imposs": 3, "cl": [3, 90, 96, 135], "input_id": 3, "cls_index": 3, "cls_token_id": 3, "grab": 3, "know": 3, "what": [3, 7, 90, 101], "sequence_id": 3, "One": [3, 13, 44, 111], "span": 3, "contain": [3, 7, 11, 12, 39, 49, 58, 70, 71, 73, 74, 86, 88, 89, 90, 91, 92, 97, 106, 116, 118, 131, 136, 137, 149, 155, 157, 160, 162, 164, 165, 173], "sample_index": 3, "set": [3, 5, 6, 11, 12, 14, 15, 16, 20, 22, 26, 34, 35, 40, 41, 42, 48, 49, 50, 51, 53, 58, 60, 65, 70, 71, 73, 77, 88, 89, 90, 91, 92, 93, 97, 101, 102, 104, 106, 108, 111, 113, 114, 116, 118, 131, 144, 145, 149, 157, 161, 162, 164, 165, 173], "answer_start": 3, "start_char": 3, "end_char": 3, "current": [3, 5, 10, 11, 12, 14, 19, 20, 22, 33, 36, 70, 71, 73, 75, 87, 90, 91, 92, 93, 106, 108, 118, 130, 133, 144, 146, 149, 156, 167, 169], "token_start_index": 3, "token_end_index": 3, "detect": [3, 91], "move": [3, 43, 111, 176], "two": [3, 8, 13, 14, 34, 43, 45, 58, 60, 114, 173], "last": [3, 16, 52, 70, 91, 106, 113, 173], "edg": 3, "prepare_validation_featur": 3, "substr": 3, "example_id": 3, "context_index": 3, "part": [3, 34], "easi": [3, 4, 9, 14, 19], "determin": [3, 8, 12, 13, 101, 109, 161, 164, 168, 175], "k": [3, 16, 36, 58, 59, 118], "load_dataset": 3, "guarante": [3, 16], "concurr": 3, "raw_dataset": 3, "standard": [3, 11, 16, 91, 92, 93, 97, 106, 135, 149, 165, 173], "python": [3, 4, 5, 19, 22, 29, 61, 130, 175], "panda": 3, "datafram": 3, "etc": [3, 4, 11, 12, 15, 19, 20, 34, 36, 44, 108, 113, 118, 131], "loading_dataset": 3, "slighlti": 3, "column_nam": 3, "side": 3, "padding_sid": 3, "model_max_length": 3, "warn": [3, 12, 22, 90, 173], "larger": [3, 13, 16, 45, 113], "agument": 3, "main_process_first": 3, "num_proc": 3, "remove_column": 3, "load_from_cache_fil": 3, "desc": 3, "increas": [3, 4, 11, 12, 118], "dure": [3, 11, 12, 14, 16, 17, 20, 44, 50, 53, 70, 71, 72, 73, 77, 86, 91, 101, 104, 106, 113, 131, 137, 149, 164, 165, 178], "creation": 3, "again": [3, 48, 92], "info": [3, 8, 11, 12, 34, 70, 90, 106, 173], "wa": [3, 20, 22, 97, 173], "done": [3, 12, 15, 19, 20, 43, 149], "ot": 3, "collat": 3, "everyth": [3, 111], "data_col": 3, "mix": [3, 73, 118], "pad_to_multiple_of": 3, "multipl": [3, 8, 11, 12, 13, 16, 22, 34, 44, 50, 62, 63, 91, 92, 113, 131, 161, 173], "core": [3, 12, 14, 22, 103, 106, 130], "hardwar": [3, 10, 14], "capabl": [3, 87, 90], "volta": 3, "collate_fn": 3, "evaluate_model": 3, "eval_exampl": 3, "eval_dataset": 3, "eval_dataload": 3, "prefix": [3, 16, 61, 131], "create_and_fill_np_arrai": 3, "start_or_end_logit": 3, "max_len": 3, "fill": [3, 13, 143], "len_of_validation_data": 3, "max_length_of_output_tensor": 3, "enter": 3, "logit": [3, 4, 8, 13, 26, 52], "logits_concat": 3, "float64": 3, "popul": [3, 71, 175], "gather_for_metr": 3, "output_logit": 3, "replac": [3, 5, 13, 19, 20, 40, 42, 88, 92, 113, 114, 118, 130, 131, 140], "newli": 3, "And": [3, 51, 58, 59], "iter": [3, 9, 11, 12, 26, 31, 50, 58, 60, 65, 70, 71, 87, 88, 91, 92, 101, 106, 118, 130, 131, 149, 164, 168, 173], "chang": [3, 12, 19, 22, 29, 50, 88, 91, 108, 112, 114, 118, 164], "shape": [3, 7, 11, 12, 19, 26, 29, 31, 42, 45, 52, 59, 62, 88, 102, 112, 130, 131, 139, 164], "col": 3, "postprocess_qa_predict": 3, "ndarrai": [3, 31, 36, 42, 43, 44, 45, 61, 65, 176], "version_2_with_neg": 3, "bool": [3, 26, 33, 34, 36, 37, 42, 43, 44, 45, 48, 50, 53, 58, 59, 60, 62, 70, 71, 72, 73, 77, 88, 90, 91, 92, 97, 98, 101, 111, 113, 116, 118, 130, 131, 139, 143, 144, 159, 161, 162, 164, 165, 168, 169, 170, 173], "null_score_diff_threshold": 3, "them": [3, 12, 20, 22, 43, 44, 52, 59, 62, 73, 89, 92, 118, 131, 135, 161, 173], "base": [3, 9, 10, 11, 14, 16, 18, 22, 26, 27, 31, 36, 38, 48, 49, 50, 51, 52, 53, 56, 59, 64, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 101, 102, 103, 104, 106, 108, 110, 111, 112, 113, 114, 116, 117, 118, 120, 122, 125, 126, 127, 128, 129, 130, 131, 135, 136, 137, 139, 142, 143, 144, 145, 147, 148, 151, 154, 155, 157, 161, 162, 164, 165, 172, 173, 174], "postprocess": [3, 56, 60, 117], "non": [3, 13, 19, 27, 29, 34, 41, 48, 50, 58, 70, 91, 92, 106, 143, 173], "respect": [3, 4, 13, 14, 17, 90, 106, 113, 118], "Its": 3, "dimens": [3, 12, 17, 36, 43, 45, 52, 113, 140, 164], "match": [3, 19, 20, 34, 41, 70, 72, 73, 86, 90, 100, 106, 113, 114, 118, 142, 170], "element": [3, 14, 34, 43, 70, 106, 143, 171, 173, 175], "underli": [3, 88, 92], "threshold": [3, 14], "null": [3, 48, 113, 142], "less": [3, 11, 12, 20, 130], "minu": 3, "minimum": [3, 12], "align": [3, 22], "fact": 3, "thei": [3, 20, 22, 45, 48, 72, 92, 100, 113, 118, 131, 142, 149, 173], "want": [3, 5, 11, 12, 14, 15, 20, 56, 72, 86, 87, 88, 91, 92, 97, 100, 101, 113, 116, 139, 142, 149, 175], "dictionari": [3, 13, 14, 19, 20, 22, 31, 34, 36, 42, 45, 48, 49, 50, 63, 70, 72, 73, 90, 91, 92, 97, 100, 106, 113, 114, 117, 118, 142, 149, 157, 164, 173], "n_best": 3, "mention": [3, 12], "ad": [3, 22, 34, 44, 53, 70, 91, 92, 106, 131, 139, 149, 151, 157, 161, 164], "start_logit": 3, "end_logit": 3, "all_start_logit": 3, "all_end_logit": 3, "got": 3, "example_id_to_index": 3, "features_per_exampl": 3, "defaultdict": 3, "all_predict": 3, "ordereddict": 3, "all_nbest_json": 3, "scores_diff_json": 3, "loop": [3, 4, 6, 8, 9, 12, 20, 43, 70, 71, 97, 106, 149, 168], "over": [3, 4, 11, 12, 13, 26, 36, 45, 86, 90, 92, 97, 101, 102, 118, 126, 164, 168], "example_index": 3, "feature_indic": 3, "min_null_predict": 3, "prelim_predict": 3, "feature_index": 3, "token_is_max_context": 3, "feature_null_scor": 3, "greater": 3, "start_index": 3, "argsort": 3, "tolist": 3, "end_index": 3, "don": [3, 5, 34, 44, 97, 116], "scope": 3, "null_scor": 3, "n_best_pr": 3, "sort": [3, 13, 70, 75, 86, 93, 102, 106, 162], "revers": [3, 130], "back": [3, 12, 34, 89, 92, 135, 161], "low": [3, 10, 17, 18, 20, 22, 113], "gather": [3, 56, 70, 106, 118], "pred": 3, "rare": 3, "fake": [3, 20, 91, 113, 131, 135, 139, 161], "avoid": [3, 13, 20, 48, 50, 113, 178], "failur": [3, 165], "insert": [3, 19, 20, 34, 42, 91, 108], "empti": [3, 56, 62, 70, 106, 139, 142, 164, 173], "softmax": [3, 34, 41], "stai": [3, 17], "independ": [3, 161], "tf": [3, 173], "logsumexp": 3, "trick": 3, "exp_scor": 3, "exp": 3, "prob": 3, "probabl": 3, "zip": 3, "pick": [3, 16], "best_non_null_pr": 3, "Then": [3, 16, 75], "score_diff": 3, "serializ": 3, "cast": [3, 34, 44], "v": [3, 34, 58, 59, 118, 173], "float16": [3, 59, 60, 67, 131], "float32": [3, 43, 131, 139], "isdir": 3, "environmenterror": 3, "prediction_fil": 3, "join": 3, "_predict": 3, "nbest_fil": 3, "nbest_predict": 3, "_nbest_predict": 3, "null_odds_fil": 3, "null_odd": 3, "_null_odd": 3, "open": 3, "w": [3, 19, 36, 92, 143], "writer": 3, "dump": [3, 48, 90], "indent": 3, "nbest_pr": 3, "metric": [3, 12, 70, 97, 106], "formatted_predict": 3, "prediction_text": 3, "refer": [3, 4, 6, 7, 10, 11, 12, 13, 14, 19, 20, 22, 26, 27, 29, 34, 70, 89, 93, 106, 130, 131, 149, 164, 173], "ex": [3, 31, 34], "label_id": 3, "num": [3, 172], "being": [3, 22, 92, 102], "pad_across_process": 3, "pad_index": 3, "clear": [3, 161, 173, 174], "intermedi": [3, 13, 34, 44, 70, 106, 118], "compute_kd_loss": [3, 8, 13, 50, 51], "concaten": [3, 75], "start_logits_concat": 3, "end_logits_concat": 3, "outputs_numpi": 3, "eval_metr": 3, "defin": [3, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 20, 41, 57, 59, 88, 89, 94, 97, 113, 114, 118, 120, 131, 144, 164, 175], "factori": [3, 59], "teacher_factori": [3, 8], "from_pretrain": [3, 14, 15, 16, 22, 96], "startendlogitsdistillationloss": 3, "logitsdistillationloss": [3, 8, 13, 52], "outputs_": 3, "outputs_t": 3, "loss_start": 3, "loss_end": 3, "train_and_evaluate_model": 3, "no_decai": 3, "layernorm": [3, 20, 58, 59, 64, 72, 100, 114], "optimizer_grouped_paramet": 3, "named_paramet": 3, "nd": 3, "adamw": 3, "around": [3, 20], "overrode_max_train_step": 3, "num_update_steps_per_epoch": 3, "ceil": [3, 43], "num_training_step": 3, "prepar": [3, 65, 94, 108, 148, 168], "recalcul": 3, "afterward": [3, 52, 92], "figur": 3, "mani": [3, 7, 11, 14, 16, 139], "isdigit": 3, "main": [3, 11, 26, 27, 29, 38, 49, 60, 69, 71, 73, 157], "experiment_config": 3, "var": 3, "tensorboard": 3, "cannot": [3, 12, 48, 70, 106, 149, 161, 164, 173], "enum": [3, 164], "raw": [3, 45], "init_track": 3, "total_batch_s": 3, "num_process": 3, "instantan": [3, 167], "progress": [3, 118, 173], "bar": [3, 173], "machin": 3, "progress_bar": [3, 173], "disabl": [3, 20, 22, 88, 108, 118, 130, 131, 140, 161, 162, 164], "is_local_main_process": 3, "completed_step": 3, "starting_epoch": 3, "resume_step": 3, "recent": 3, "dir": [3, 22, 27, 56], "scandir": 3, "is_dir": 3, "startswith": 3, "epoch_": 3, "step_": 3, "scratch": [3, 7, 11, 13], "latest_dir": 3, "getctim": 3, "load_stat": 3, "extract": 3, "basenam": 3, "multipli": [3, 14, 52], "reflect": [3, 11], "real": [3, 19, 20, 113, 117, 131, 134, 135], "total_loss": 3, "skip": [3, 11, 12, 20, 34, 86, 92, 111, 113, 118, 164], "resum": [3, 7, 11, 12, 20, 89], "active_dataload": 3, "skip_first_batch": 3, "unwrap": [3, 73, 90, 91, 173], "to_tupl": 3, "track": [3, 87, 108, 112], "behind": [3, 11, 13, 17], "scene": 3, "sync_gradi": 3, "save_st": [3, 16], "break": [3, 8, 22, 70, 106], "ignor": [3, 12, 27, 118], "attr": 3, "wait_for_everyon": 3, "is_main_process": 3, "eval_": 3, "accelerator_log_kwarg": 3, "log_with": 3, "project_dir": 3, "basicconfig": 3, "asctim": 3, "levelnam": 3, "messag": [3, 165], "datefmt": 3, "d": [3, 61, 108], "y": [3, 36, 70, 106, 173], "h": [3, 19, 143], "level": [3, 26, 34, 70, 92, 106, 118, 149], "main_process_onli": 3, "set_verbosity_warn": 3, "set_verbosity_info": 3, "set_verbosity_error": 3, "handl": [3, 13, 20, 22, 71, 84, 86, 87, 91, 92, 95, 105, 133, 135, 146, 156, 161, 163], "makedir": 3, "exist_ok": 3, "use_fast": 3, "save_modelopt_model": 3, "save_path": 3, "assert": [3, 45, 91], "exist": [3, 4, 11, 12, 13, 14, 56, 58, 70, 87, 91, 92, 96, 106, 130], "doe": [3, 9, 11, 14, 18, 22, 38, 44, 73, 88, 91, 92, 93, 113, 116, 118], "synchron": [3, 56, 131, 169, 175], "across": [3, 14, 17, 56, 59, 62, 92, 131, 175], "same": [3, 8, 11, 13, 15, 16, 17, 22, 44, 45, 56, 59, 70, 72, 91, 92, 100, 101, 102, 106, 118, 130, 131, 139, 142, 149, 164, 173, 175], "search": [3, 20, 22, 70, 71, 72, 73, 77, 86, 88, 89, 91, 92, 97, 98, 101, 102, 103, 104, 106, 108, 113, 118, 144, 147, 148, 149, 164, 175], "na": [3, 7, 11, 21, 53, 72, 77, 84, 85, 88, 99, 104, 175], "mtn": [3, 12, 53, 77, 88, 173, 175, 178], "collect_func": [3, 9, 14, 70, 106, 118, 149, 173], "loss_func": [3, 11, 20, 70, 106, 118], "forward_loop": [3, 6, 9, 15, 20, 70, 97, 106, 113, 117, 118, 149, 168], "num_sampl": [3, 6, 9, 20, 168], "256": [3, 12], "num_batch": 3, "idx": [3, 51, 162], "getattr": [3, 92], "empty_cach": 3, "distillationmodel": [3, 13, 49, 50, 51], "kd_config": 3, "teacher_model": [3, 8, 13, 48, 50], "criterion": [3, 8, 13, 48, 50, 51], "kd_loss": [3, 8, 13, 49], "wb": 3, "onnx_opset": 3, "14": 3, "__main__": 3, "unprun": 3, "recov": [3, 7, 11, 12, 16, 20], "99": [3, 111], "f1": 3, "93": 3, "converg": [3, 4], "1_prune": 3, "sh": [3, 27], "bin": [3, 19, 111], "bash": 3, "flops_perc": 3, "base_dir": 3, "bert_large_pruned_": 3, "_percent": 3, "modelopt_arg": 3, "fi": 3, "launch": 3, "multi_gpu": 3, "mixed_precis": 3, "slight": 3, "abl": [3, 12], "2_int8_quant": 3, "int8_quant": 3, "quantized_model": [3, 20], "int8_default_cfg": [3, 20, 113], "3_onnx_export": 3, "python3": 3, "pruned_model_int8": 3, "minim": [4, 13, 17, 22, 97, 108, 113], "present": [4, 8, 13, 45], "signific": [4, 12, 164], "challeng": 4, "ai": 4, "grow": 4, "complex": 4, "librari": [4, 7, 15, 22, 44], "compris": [4, 18], "accept": [4, 13, 16, 22, 130, 139], "stack": [4, 10, 116], "produc": [4, 16, 34, 45], "seamlessli": [4, 12, 13], "ecosystem": 4, "readi": [4, 6, 11, 49, 71], "plan": 4, "enterpris": 4, "diffus": [4, 15, 22, 133], "nim": 4, "visit": 4, "recip": [4, 108], "2x": [4, 14], "4x": 4, "speed": [4, 6, 9, 14, 16], "preserv": [4, 17, 73, 91, 164], "qualiti": [4, 13, 20], "highli": [4, 11, 14, 20], "int4": [4, 18, 19, 20, 44, 113, 131, 136], "support": [4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 27, 33, 35, 36, 37, 40, 42, 44, 50, 55, 58, 59, 70, 73, 91, 92, 97, 106, 111, 113, 114, 116, 117, 118, 119, 120, 121, 133, 138, 140, 146, 149, 154, 156, 161, 173, 178], "smoothquant": [4, 6, 17, 18, 20, 113, 117, 131], "awq": [4, 6, 17, 18, 20, 36, 59, 62, 113, 136], "doubl": [4, 113, 137], "both": [4, 6, 8, 12, 13, 14, 17, 18, 20, 22, 36, 49, 92, 128, 161, 164], "page": 4, "memori": [4, 6, 9, 10, 14, 18, 20, 22, 45, 60, 62, 113, 137, 173, 174], "footprint": [4, 6, 9, 14], "deep": [4, 6, 9, 17], "mt": [4, 9, 14], "sparsifi": [4, 9, 14, 22, 149], "pattern": [4, 9, 14, 34, 41, 44, 72, 86, 100, 113, 118, 142, 143, 149, 170], "sparsif": [4, 22, 141, 144], "asp": [4, 9, 14, 143], "sparsegpt": [4, 9, 14, 144, 149], "pt": [4, 20, 91], "sat": [4, 22], "latter": 4, "degrad": [4, 11, 12, 18, 20, 102], "knowledg": [4, 8, 22, 48, 50, 51, 53], "effici": [4, 13, 14, 130, 136, 137], "student": [4, 8, 48, 49, 50, 51, 52], "tradit": 4, "becom": [4, 13, 18], "invas": 4, "unnecessari": 4, "conv": [4, 20, 22, 33, 37, 41, 58, 59, 164], "linux": 5, "x86_64": 5, "via": [5, 11, 12, 13, 14, 16, 18, 36, 53, 70, 77, 86, 87, 88, 91, 92, 97, 104, 106, 116, 144, 145, 155, 164, 173, 175], "review": 5, "term": [5, 11, 13, 14], "quick": [5, 21], "instruct": 5, "virtual": 5, "environ": 5, "command": [5, 19], "conda": 5, "desir": [5, 6, 7, 12, 13, 42, 49, 73, 91, 106, 149, 157, 164], "whl": 5, "cu118": 5, "partial": [5, 34, 161, 165], "barebon": 5, "appropri": [5, 6, 9, 87, 93, 113, 131], "correctli": [5, 12, 14, 15, 20, 88, 90, 131, 133], "addition": [5, 34, 91, 118], "3rd": 5, "parti": [5, 84, 95, 105, 133, 146, 156, 163], "plugin": [5, 16, 22, 44, 96], "third": [5, 34, 84, 95, 105, 133, 146, 156, 163], "packag": [5, 22, 24, 55, 107, 130, 140, 169], "hf": [5, 7, 11, 21, 22, 27, 57, 67], "compil": [5, 19, 29, 34, 37, 41, 44, 167], "kernel": [5, 12, 18, 34, 41, 173], "subsequ": [5, 12, 14, 70, 97, 106, 167], "invok": [5, 13, 44, 172], "docker": 5, "extens": [5, 27, 86, 139, 167], "ext": 5, "cuda_ext": 5, "cuda_ext_fp8": 5, "get_model": [6, 9, 20], "rough": 6, "calib_s": [6, 9, 20], "get_dataload": [6, 20], "int8_smoothquant_cfg": [6, 20, 113], "guid": [6, 8, 9, 12, 15, 20, 22], "usag": [6, 7, 8, 9, 12, 13, 14, 16, 20, 70, 73, 87, 90, 96, 106, 118, 137, 168, 174], "resnet20": [7, 11, 21], "cifar": [7, 11, 21], "10": [7, 11, 18, 19, 20, 21], "minitron": [7, 11, 103, 106], "fastna": [7, 11, 12, 70, 88, 100, 102, 104, 106], "involv": [7, 8, 13, 56, 71], "three": [7, 11, 18, 34, 118], "altern": [7, 13, 15, 19], "sub": [7, 11, 41, 70, 71, 88, 89, 97, 165], "net": [7, 11, 70, 71, 88, 97, 173], "serach": [7, 11], "resnet50": [7, 8, 11, 12, 13], "pretrained_weight": [7, 8, 11], "dummi": [7, 11, 12, 88, 128], "similar": [7, 11, 12, 122, 131], "224": [7, 11, 12], "244": [7, 11], "prune_constraint": [7, 11], "prune_r": [7, 11], "stat": [7, 11, 12, 34, 70, 97, 106, 118, 149, 171], "pruner": [7, 11], "searcher": [7, 11, 12, 71, 101, 102, 103, 108, 143, 148], "bn": [7, 11, 12, 34], "subnet": [7, 70, 71, 72, 73, 86, 88, 92, 97, 101, 106, 144, 175], "re": [7, 11, 12, 13, 14, 16, 48, 92], "modelopt_fastnas_search_checkpoint": [7, 11], "modelopt_pruned_model": [7, 11], "wrapper": [8, 26, 50, 73, 91, 135, 173], "among": [8, 13, 93], "higher": [8, 11, 12, 14, 118], "usuali": 8, "serv": [8, 13, 18], "resnet18": 8, "student_model": [8, 13], "callabl": [8, 13, 20, 48, 50, 51, 53, 70, 73, 77, 86, 87, 88, 91, 93, 97, 102, 104, 106, 108, 113, 114, 116, 117, 118, 130, 144, 149, 155, 161, 164, 165, 168, 173], "least": [8, 41, 90], "simplifi": [8, 99, 161], "assum": [8, 34, 52, 58, 70, 106, 118, 161, 173], "distillation_config": [8, 13], "receiv": 8, "order": [8, 12, 13, 20, 27, 51, 70, 72, 91, 92, 93, 100, 106, 113, 142, 161, 173], "loss_balanc": [8, 13, 48, 50], "staticlossbalanc": [8, 13, 51], "omit": [8, 13], "distillation_model": [8, 13], "model_cl": [8, 73, 91], "kwarg": [8, 13, 27, 37, 48, 50, 70, 73, 90, 91, 92, 106, 117, 128, 130, 131, 132, 135, 136, 137, 138, 145, 161, 162, 164, 172, 173, 175, 176], "usual": [8, 11, 12, 13, 14, 91, 92, 97], "get_train_load": 8, "get_user_loss_fn": 8, "train_dataload": 8, "loss_tot": 8, "student_loss": [8, 50, 51], "dataparallel": [8, 73], "trainer": [8, 16], "revert": [8, 92, 161], "modif": [8, 11, 12, 13, 15, 22, 89, 91], "attach": 8, "get_train_dataload": 9, "sparsity_config": [9, 14], "driven": [9, 14], "sparse_magnitud": [9, 14, 142, 149], "pure": [9, 13, 90], "substitut": [9, 108], "simul": [10, 20, 131], "actual": [10, 13, 18, 34, 71, 91, 92, 93, 97, 103, 164, 173], "speedup": [10, 19, 20], "basic": [10, 12, 13, 14, 16, 31, 40, 43, 51, 87, 92, 97, 118, 139, 164], "concept": [10, 89, 113], "practic": [10, 26], "choos": [10, 70, 106, 113, 149, 175], "beta": 10, "aka": [11, 12], "unifi": [11, 22, 67, 111], "aggress": [11, 12], "These": [11, 16, 22, 113], "convolut": [11, 12, 34, 125], "network": [11, 12, 17, 56, 88, 148], "measur": [11, 12, 18, 61, 102, 174], "3e": 11, "equal": [11, 45, 93], "place": [11, 12, 13, 20, 41, 58, 70, 90, 91, 92, 106, 118, 149, 159, 161, 175], "distributeddataparallel": [11, 73, 91, 178], "fulli": [11, 20, 22, 73, 92, 131], "shard": [11, 22, 173], "fsdp": [11, 22, 48, 50], "henc": [11, 12, 15, 92, 118, 145], "feasibl": 11, "shown": [11, 12, 15, 72, 73, 100, 142, 164], "ss_config": 11, "candid": [11, 12, 16, 71, 92], "overal": [11, 99], "274": 11, "34m": 11, "28g": 11, "59g": [11, 12], "73": 11, "70m": 11, "75m": 11, "50m": [11, 12], "75g": 11, "layer1": [11, 12], "layer4": [11, 12], "96": 11, "416": 11, "448": 11, "480": 11, "2048": [11, 12, 111, 113], "bn2": [11, 12], "conv3": [11, 12], "36": 11, "48e": 11, "come": [11, 12, 139], "pruneabl": 11, "slower": [11, 13], "adjust": [11, 12, 17, 20, 63, 114, 117], "accordingli": [11, 63, 86, 92, 114, 164], "unabl": 11, "perhap": 11, "too": 11, "try": [11, 12, 18, 176], "cannnot": 11, "interrupt": 11, "errror": 11, "wai": [11, 14, 15, 16, 17, 20, 92, 161, 173], "ensur": [11, 12, 71, 86, 88, 92, 118, 173], "explain": 11, "reus": 11, "ahead": 11, "forget": [11, 15], "modelopt_pruned_finetuned_model": 11, "hand": [11, 14], "neural": 11, "redund": [11, 12], "compon": [11, 12, 18, 51], "conceptu": 11, "overhead": [11, 130], "simpler": [11, 99], "approxim": [11, 101, 108, 149, 175], "therefor": [11, 16, 91, 92], "expens": [11, 16], "directli": [11, 20, 49, 86, 88, 92, 102, 131, 139], "autona": [12, 70, 72, 73, 77, 88, 101], "suitabl": [12, 168], "layerwis": 12, "uniqu": [12, 51, 60, 92, 102, 143, 173], "nativ": [12, 20, 22, 41, 162], "conveni": [12, 90], "even": [12, 13, 20, 36, 102, 165], "modelopt_model": [12, 15, 88], "autonasconfig": [12, 72, 73], "out_channels_ratio": [12, 73], "model_or_model_factori": 12, "accord": [12, 86, 88, 90, 92, 120, 139, 149, 161, 173], "togeth": [12, 16, 19, 20, 59, 75, 91, 92, 161, 164], "gflop": [12, 106], "0e9": 12, "against": [12, 113, 114, 118], "is_sat": 12, "search_space_stat": 12, "487": 12, "92m": 12, "84g": 12, "84m": 12, "00g": 12, "352": 12, "90e": 12, "infrastructur": [12, 89, 99], "3x": 12, "sure": [12, 88, 92], "anneal": 12, "rest": [12, 14, 101, 102], "proce": 12, "calcul": [12, 13, 17, 44, 63, 70, 97, 102, 106, 139, 140, 143], "search_constraint": 12, "search_r": 12, "searched_model": 12, "modelopt_search_checkpoint": 12, "modelopt_searched_model": 12, "still": [12, 13, 73, 92, 108], "At": 12, "compat": [12, 22, 58, 60, 65, 68, 73, 91, 92, 118, 135, 165, 173], "implement": [12, 13, 14, 17, 34, 41, 43, 50, 52, 53, 56, 58, 74, 77, 79, 80, 81, 82, 89, 92, 97, 101, 102, 103, 104, 120, 122, 130, 135, 136, 137, 139, 154, 160, 161, 162], "quickli": 12, "encount": [12, 165], "problem": 12, "deriv": 12, "searchabl": [12, 86, 88, 92, 161, 164], "unit": [12, 86, 88, 92, 94, 173], "conv1d": [12, 59, 72, 100, 125], "conv3d": [12, 72, 100, 125], "convtranspose1d": [12, 72, 100, 125], "convtranspose2d": [12, 72, 100, 125], "convtranspose3d": [12, 72, 100, 125], "residu": [12, 34, 41, 154], "block": [12, 14, 18, 20, 34, 36, 58, 63, 92, 106, 113, 131, 136, 137, 149, 154, 175], "llama3": 12, "hidden": [12, 59, 130, 154], "megatronmodul": 12, "nlp": [12, 27], "language_model": 12, "megatron_gpt_model": 12, "megatrongptmodel": 12, "use_cach": [12, 59], "modeling_bert": 12, "bertattent": 12, "modeling_gptj": 12, "gptjattent": 12, "suffic": 12, "repres": [12, 42, 75, 92, 93, 139, 161, 162, 173], "behav": 12, "roughli": 12, "broken": [12, 36], "down": 12, "trace": [12, 86, 87, 159, 161, 163, 164, 165], "resolv": [12, 87], "implicitli": 12, "fx": [12, 165], "tracer": [12, 159], "error": [12, 70, 73, 88, 91, 113, 116, 132, 138, 172], "affect": [12, 92, 164, 173], "certain": [12, 41, 91, 92, 101, 102, 114, 118], "definit": [12, 113, 118], "occur": [12, 34, 58, 65, 113], "find_unused_paramet": 12, "branch": 12, "full": [12, 22, 56, 58, 59, 90, 91, 113], "faq": [12, 21], "terminologi": [12, 13, 14, 16], "isol": 12, "discret": 12, "parameter": 12, "individu": [12, 58, 70, 73, 89, 92, 106, 131, 149], "distinct": 12, "oper": [12, 14, 17, 18, 22, 29, 44, 73, 88, 106, 161, 165, 171, 173], "character": 12, "smallest": 12, "closest": [12, 171, 175], "largest": [12, 14, 86], "relev": [12, 70, 90, 164], "sapc": 12, "simultan": [12, 16, 92], "entir": [12, 118], "vari": 12, "procedur": [12, 70, 89, 90, 97, 106, 118], "account": 12, "accur": 12, "boost": [12, 13], "flexibl": [12, 14, 164], "constrain": [12, 17], "fewer": [12, 70, 106, 149], "due": [12, 14, 20, 102, 108], "exhibit": [12, 87, 164], "wors": 12, "direct": [13, 20, 130], "transfer": [13, 91, 111], "power": [13, 16], "meta": [13, 49, 50, 131, 135, 144], "abstract": [13, 51, 71, 97, 110, 139], "awai": 13, "interact": [13, 161], "orign": 13, "form": [13, 70, 73, 91, 173], "model_cls_or_cal": [13, 173], "model_export": 13, "upon": [13, 20, 86, 92], "thu": [13, 70, 106, 149], "namespac": 13, "anymor": [13, 92], "though": [13, 139], "subclass": [13, 20, 92, 108, 113, 135, 157], "learnabl": 13, "fix": [13, 17, 22, 41, 94, 131, 149], "separ": [13, 17, 44, 91, 111, 165], "scalar": [13, 50, 52, 70, 106, 118, 120, 131], "broader": 13, "auxilliari": 13, "hope": 13, "master": [13, 139, 169, 172, 173], "reduct": [13, 29, 51, 52], "reach": 13, "exceed": 13, "lotteri": 13, "ticket": 13, "hypothesi": 13, "reason": [13, 139], "b": [13, 70, 106], "often": [13, 18, 20, 41], "wish": 13, "ideal": [13, 111], "untrain": 13, "possess": 13, "satisfactori": 13, "object": [13, 34, 36, 42, 56, 59, 73, 86, 87, 91, 92, 93, 102, 130, 131, 135, 139, 164, 165, 173], "enact": 13, "mse": [13, 111], "assumpt": 13, "high": [13, 17, 18, 26, 44, 70, 106, 149], "imit": 13, "pair": [13, 22, 48, 50, 117], "pairwis": 13, "Will": 13, "classifi": 13, "atd": 13, "captur": [13, 15, 118], "especi": [13, 16], "backpropag": [13, 50], "whose": [13, 88], "interfac": [13, 51, 86, 91, 94, 97, 147], "distillationlossbalanc": [13, 50, 51], "aforement": 13, "ones": [13, 86, 143], "scenario": [13, 17, 18], "classif": 13, "altogeth": 13, "prefer": [13, 19], "whatev": 13, "ground": 13, "truth": 13, "dens": [14, 59], "retrain": 14, "simplest": [14, 17, 20], "automodelforcausallm": [14, 15, 16, 96], "eleutherai": 14, "calib_dataload": 14, "sparse_model": 14, "modelopt_sparse_model": 14, "along": [14, 17, 22, 113, 135, 140], "later": [14, 15, 18, 20, 72, 86, 100, 131, 142], "unmodifi": [14, 16, 91, 92], "plain": 14, "enforc": [14, 72, 90, 91, 92, 93, 149, 159], "overview": [14, 16, 17, 21], "fraction": 14, "zero": [14, 42, 111, 139, 143], "broadli": 14, "categor": [14, 29], "matrix": [14, 143, 148], "lead": [14, 114], "poor": 14, "exploit": 14, "throughput": [14, 18, 19], "special": [14, 20, 34, 51, 92, 113, 114, 161], "contigu": [14, 61, 62], "nonzero": 14, "benefit": 14, "bandwidth": [14, 17, 18], "deliv": 14, "On": 14, "amper": [14, 18], "four": 14, "There": [14, 16, 139, 161], "commonli": [14, 17], "approach": [14, 16], "brain": 14, "surgeon": 14, "modelopt_st": [15, 22, 91, 96, 131], "custom_method_to_save_model_weight": 15, "although": [15, 92, 93, 164], "thereof": 15, "were": [15, 173], "restore_modelopt_st": 15, "custom_method_to_load_model_weight": 15, "save_pretrain": [15, 22, 96], "enable_huggingface_checkpoint": [15, 16, 22, 96], "program": [15, 96, 108], "model_path": [15, 96], "modelopt_": 15, "mtsp": 16, "compute_loss": 16, "frozen": [16, 20, 145], "medua": 16, "tinyllama": 16, "1b": 16, "chat": 16, "v1": 16, "pad_token_id": [16, 27], "eos_token_id": [16, 27], "medusa_config": 16, "medusa_num_head": [16, 151, 154], "medusa_num_lay": [16, 151, 154], "medusa_model": 16, "training_arg": 16, "data_modul": 16, "_move_model_to_devic": 16, "replace_medusa_compute_loss": 16, "medusa_only_head": 16, "resume_from_checkpoint": 16, "save_model": 16, "autoregress": 16, "serial": [16, 48, 56, 173], "slow": 16, "propos": [16, 91], "critic": 16, "typic": [16, 17, 18, 19, 20], "short": [16, 72, 100, 142], "draft": 16, "regress": 16, "attain": 16, "scheme": [16, 48, 50, 113], "decid": [16, 111, 139], "popular": [16, 18], "introduc": [16, 27], "tree": [16, 164], "mechan": [16, 92], "emploi": 16, "longest": 16, "plausibl": 16, "topic": 17, "width": [17, 26], "integ": [17, 18, 36, 111, 112, 113, 131, 139], "sign": [17, 43, 131, 139], "mantissa": [17, 113], "expon": [17, 113], "explan": 17, "unscal": 17, "share": [17, 44, 45, 56, 60, 118], "divid": 17, "global": [17, 42, 88, 112, 118], "gptq": 17, "unchang": [17, 92], "round": [17, 36, 59], "nearest": [17, 36], "entropi": [17, 37, 44, 111], "straight": [17, 139], "ste": 17, "clip": [17, 37, 113, 120, 131, 139], "explicit": [17, 19, 164], "graph": [17, 22, 34, 41, 42, 45, 86, 165, 176], "represent": [17, 53, 60, 77, 104, 113, 116, 144, 155, 161, 164], "qdq": [17, 19, 34, 38, 41, 42, 113], "node": [17, 19, 20, 22, 34, 41, 42, 44, 45, 60, 161, 165], "primari": 18, "cach": [18, 20, 22, 26, 31, 42, 44, 174], "regim": 18, "superior": 18, "densiti": 18, "crucial": 18, "consequ": [18, 92], "lower": [18, 71, 73, 90, 122], "suggest": [18, 118], "priorit": [18, 90], "caus": [18, 41, 86], "strong": 18, "earlier": [18, 72, 73, 86, 100, 142], "sq": 18, "toler": 18, "tabl": [18, 113], "tradeoff": 18, "medium": 18, "ada": 18, "hopper": 18, "w4a16": [18, 113], "wise": [18, 20, 34, 50, 113, 158, 159], "ten": 18, "w4a8": [18, 59, 113], "impact": 18, "ll": 18, "eq": 19, "advantag": [19, 20], "offer": [19, 20], "expert": [19, 20, 58, 59], "white": 19, "box": 19, "design": [19, 69, 70, 73, 106], "rule": [19, 20, 34, 86, 90, 92, 108, 118, 145], "link": [19, 22, 61, 108, 161, 162], "npz": [19, 60, 65], "npy": 19, "calib_data": 19, "multi": [19, 56, 102], "input_nam": [19, 34, 45], "input_name2": 19, "shape2": 19, "savez": 19, "moq": 19, "calibration_data": [19, 31, 44], "calibration_data_path": 19, "onnx_path": [19, 31, 33, 34, 36, 37, 44, 45], "output_path": [19, 44], "quant": [19, 42, 44, 116], "quantize_mod": [19, 34, 44], "calibraton": 19, "tool": [19, 27, 29, 89], "friendli": [19, 22, 37], "op_types_to_quant": [19, 29, 33, 37, 40, 44], "op_types_to_exclud": [19, 33, 34, 37, 44], "trtexec": 19, "usr": 19, "src": [19, 34], "saveengin": 19, "field": [19, 48, 59, 61, 72, 90, 100, 113, 142, 151], "flag": [19, 44, 91, 161], "implicit": 19, "cover": 20, "successfulli": 20, "print_quant_summari": [20, 118], "flow": [20, 29], "sample_input": 20, "onnx_fil": 20, "resourc": 20, "calib_set": 20, "durat": 20, "suffici": [20, 38], "weight_compress": [20, 118], "un": [20, 114, 118], "fp8_default_cfg": [20, 113, 118], "55": [20, 36, 100], "sensit": [20, 101, 102, 118], "quantrecip": [20, 108], "search_state_dict": 20, "quantization_format": [20, 118], "auto_quantize_model": 20, "hood": 20, "patch": [20, 35, 39, 40, 71, 73, 86, 88, 92, 101, 161], "quantizerattributeconfig": [20, 22, 111, 112, 113, 114, 118, 125, 127, 128, 130, 131], "set_from_attribute_config": [20, 22, 114, 131], "explicitli": [20, 35, 90, 92], "quant_x": 20, "quantizer_custom": 20, "num_bit": [20, 58, 111, 112, 113, 125, 127, 128, 130, 131, 139], "block_siz": [20, 36, 113, 125, 127, 128, 130, 131, 135, 136, 137], "who": 20, "wildcard": [20, 73, 86, 113, 114, 118], "quant_cfg": [20, 113, 114, 118, 168], "bmm": 20, "output_quant": [20, 58, 128], "regist": [20, 22, 87, 90, 92, 93, 108, 114, 139, 148, 164, 165], "unsupport": [20, 165], "kv": [20, 26], "quantlayernorm": [20, 114], "normalized_shap": [20, 114], "_setup": [20, 92, 114], "input_quant": [20, 113, 114, 118, 128, 130], "weight_quant": [20, 108, 111, 113, 114, 118, 128, 130], "anywher": 20, "layer_norm": [20, 114], "instanti": [20, 27, 88, 96], "attribut": [20, 22, 42, 58, 92, 113, 114, 118, 131, 135, 173], "original_cl": [20, 92, 114], "quantized_cl": [20, 114], "fold": [20, 92, 108, 118], "inferec": 20, "fold_weight": [20, 118], "user_evaluate_func": 20, "refactor": 20, "extend": [20, 90, 92], "specul": [21, 22, 151, 156, 157], "decod": [21, 22, 27, 58, 59, 60, 65, 150, 151, 154, 157], "changelog": 21, "contact": 21, "deprec": [22, 111, 132, 138, 169, 172], "dataset_util": 22, "get_dataset_dataload": [22, 168], "chain": [22, 116], "dq": [22, 34, 42, 44], "medusa": [22, 58, 151, 153, 154, 155, 157], "amax": [22, 63, 111, 112, 113, 117, 131, 139, 140], "upgrad": 22, "export_hf_checkpoint": [22, 67], "pack": [22, 43, 61, 67, 130, 135, 136, 137], "vllm": 22, "flux": 22, "dev": 22, "set_data_parallel_group": [22, 169], "set_tensor_parallel_group": [22, 169], "releas": 22, "quantdescriptor": 22, "tensorquant": [22, 58, 113, 114, 118, 128, 130, 131], "backend": [22, 169], "rnn": [22, 130], "lstm": 22, "gru": 22, "dbrx": 22, "experiment": [22, 117, 118, 139, 165], "auto_quant": [22, 108, 118], "qlora": 22, "nf4": [22, 137], "offici": 22, "medusamodel": [22, 154, 157], "gptmodel": 22, "recurrentgemma": [22, 59], "spars": [22, 142, 143, 144, 145, 147, 148, 149], "renam": 22, "ammo": 22, "product": 22, "inference_gpu": 22, "model_config_export": 22, "torch_to_tensorrt_llm_checkpoint": [22, 60], "float8": 22, "window": [22, 29], "win_amd64": 22, "wheel": 22, "submodul": [22, 58, 72, 73, 92, 100, 140, 142, 165], "bug": 22, "issu": [22, 48, 173, 177], "opset": 22, "neg": 22, "pb": 22, "tmp": [22, 60, 67, 68], "folder": 22, "tensorrt_llm": [25, 26, 27, 59, 60, 64, 65], "runner": 26, "hlapi": 26, "engine_dir": 26, "kv_cache_config": 26, "tokenizerbas": 26, "perf": 26, "md": [26, 60, 139], "generate_context_logit": 26, "prompt": 26, "top_p": 26, "nucleu": 26, "keep_input_prompt": 26, "prommpt": 26, "context_logit": 26, "generate_text": 26, "max_new_token": 26, "stop_word": 26, "stop": [26, 71, 101, 174], "max_beam_width": 26, "2d": [26, 125], "beam": 26, "generate_token": 26, "sequence_len": 26, "properti": [26, 27, 50, 53, 56, 59, 71, 75, 77, 90, 91, 92, 93, 97, 101, 102, 103, 104, 108, 112, 116, 130, 131, 144, 147, 148, 155, 161, 162, 164], "instanc": [26, 48, 49, 50, 61, 70, 88, 91, 92, 98, 106, 113, 114, 118, 126, 131, 135, 149, 157, 164, 168], "max_input_len": 26, "customsentencepiecetoken": 27, "sentencepiecetoken": 27, "nemo_exampl": 27, "constructor": [27, 50, 51, 52, 88, 113, 161, 162, 173], "legaci": 27, "batch_decod": 27, "batch_encode_plu": 27, "mmethod": 27, "encod": [27, 65], "return_tensor": 27, "eos_token": 27, "pad_token": 27, "get_nemo_token": 27, "tokenizer_cfg_path": 27, "logic": [27, 43, 58, 65, 97, 161], "get_nmt_token": 27, "tokenizer_util": 27, "get_tokenzi": 27, "tokenizer_dir_or_path": 27, "subpackag": [28, 30, 46, 47], "op": [29, 34, 37, 38, 40, 41, 44, 91, 165], "is_binary_op": 29, "binari": [29, 101, 102], "is_control_flow_op": 29, "control": [29, 113], "categori": 29, "is_conversion_op": 29, "is_copy_op": 29, "is_default_quantizable_op_by_ort": 29, "ort": [29, 38, 39, 40], "nodes_to_quant": [29, 33, 37, 41, 44], "microsoft": 29, "onnxruntim": 29, "registri": [29, 86, 87, 90, 91, 92], "is_fusible_reduction_op": 29, "fusibl": [29, 41], "is_generator_op": 29, "is_irregular_mem_access_op": 29, "irreggular": 29, "mem": 29, "is_linear_op": 29, "is_modifier_op": 29, "is_multiclass_op": 29, "multiclass": 29, "is_non_reshape_copy_op": 29, "reshap": [29, 143], "is_normalization_op": 29, "is_pointwise_or_elementwise_op": 29, "pointwis": [29, 41, 52], "elementwis": 29, "is_pooling_or_window_op": 29, "pool": [29, 129], "is_recurrent_op": 29, "is_selection_op": 29, "is_sequence_op": 29, "is_shape_op": 29, "is_unary_op": 29, "unari": 29, "calibrationdataprovid": 31, "calibrationdataread": [31, 33, 36, 37], "intial": [31, 56], "timestep": 31, "encoder_hidden_st": 31, "768": 31, "get_next": 31, "reader": 31, "randomdataprovid": 31, "import_scales_from_calib_cach": 31, "cache_path": 31, "float_scal": 31, "tensor_nam": 31, "gemm": [33, 36, 37], "modelproto": [33, 36, 37, 42, 45], "int8_to_fp8": 33, "verbos": [33, 34, 37, 42, 44, 70, 106, 118, 149], "calibration_method": [33, 36, 37, 44], "calibration_data_read": [33, 36, 37], "calibration_cache_path": [33, 37, 44], "nodes_to_exclud": [33, 34, 37, 44], "use_external_data_format": [33, 34, 36, 37, 44], "intermediate_generated_fil": [33, 34, 37], "trt_extra_plugin_lib_path": [33, 37, 39, 40], "high_precision_dtyp": [33, 34, 37, 44], "mha_accumulation_dtyp": [33, 44], "fp32": [33, 34, 37, 42, 44], "matmul": [33, 34, 37, 41, 44], "placement": 34, "add_fp16_fp32_cast": 34, "custom_ops_to_cast_to_fp16": 34, "cast_to_fp16": 34, "cast_to_fp32": 34, "build_non_residual_input_map": 34, "subgraph": [34, 41], "modern": 34, "convnet": 34, "classify_partition_nod": 34, "partit": [34, 44], "outsid": 34, "algo": 34, "dst": 34, "expand_node_names_from_pattern": 34, "name_pattern": 34, "expand": 34, "filter_quantizable_kgen_head": 34, "cask_fusible_partit": 34, "kgen_partit": 34, "quantizable_op_typ": [34, 41], "kgen": [34, 41], "cask": [34, 41], "find_fp8_mha_partit": 34, "mha": [34, 41, 44], "bmm1": [34, 44], "mul": [34, 37, 41, 42], "div": [34, 41], "bmm2": [34, 44], "find_mha_partit": [34, 41], "find_nodes_from_mha_to_exclud": 34, "disable_mha_qdq": [34, 44], "is_fp8fp16": 34, "exclud": [34, 44], "head_siz": 34, "maskadd": 34, "delet": 34, "find_nodes_to_exclud": 34, "exclus": [34, 164], "get_fusible_backbon": 34, "backbon": [34, 41, 73, 86], "fuse": [34, 41, 42, 118], "tri": 34, "biasadd": 34, "constmul": 34, "get_tensor_consumer_nod": 34, "consum": [34, 42, 45, 67], "graphproto": [34, 42, 45], "nodeproto": 34, "get_tensor_producer_nod": 34, "extern": [34, 45], "eas": 34, "has_const_input": 34, "has_path_typ": 34, "path_typ": 34, "is_forward": 34, "wild_card_typ": 34, "path_nod": 34, "wrt": [34, 102, 108], "travers": [34, 41], "wild": 34, "card": 34, "insert_fp8_mha_cast": 34, "onnx_model": [34, 36, 42, 45], "input0": 34, "second": [34, 45], "input1": 34, "forbid": 34, "insert_matmul_cast": 34, "matmul_nod": 34, "is_const_input": 34, "const": 34, "foldabl": 34, "print_stat": 34, "remove_partial_input_qdq": 34, "no_quantize_input": 34, "mark": [34, 164], "onnx_graphsurgeon": 35, "patch_gs_modul": 35, "graphsurgeon": [35, 42], "woq": 36, "awqcliphelp": 36, "alpha_step": [36, 113], "05": [36, 59, 100, 113], "alpha": [36, 113], "65": [36, 52, 100], "min_alpha": 36, "update_best_param": 36, "awqlitehelp": 36, "lite": [36, 113], "dq_tensor": 36, "dequant": [36, 42, 131, 135, 136, 137, 139], "find_scal": 36, "get_act_scal": 36, "get_scal": 36, "x_max": 36, "w_max": 36, "reduce_across_tp": 36, "get_weight_scal": 36, "quant_tensor": 36, "awq_clip": [36, 44, 113, 117], "quantize_awq_clip": 36, "data_read": 36, "force_fp16": 36, "quantize_awq_lit": 36, "enable_fast_path_using_high_sysram": 36, "quantize_rtn": 36, "gemm_io_typ": 36, "dq_onli": [36, 42, 44], "rtn": 36, "ab": [36, 52, 120], "round_to_even": 36, "denot": 36, "ti": 36, "alwai": 36, "cin": 36, "plug": 36, "rh": 36, "protobuf": [36, 42], "intern": [36, 42, 83, 92, 164, 175, 178], "enum_type_wrapp": [36, 42], "enumtypewrapp": [36, 42], "0x7f1c4f143170": [36, 42], "heurist": 37, "averagepool": 37, "batchnorm": 37, "convtranspos": [37, 38], "globalaveragepool": 37, "maxpool": 37, "top": [38, 91, 92], "qdqconvtranspos": 38, "qdqoperatorbas": 38, "onnx_quant": 38, "onnx_nod": 38, "qdqnormal": 38, "intend": [38, 92], "patch_ort_modul": 39, "shoul": 40, "ort_client": 40, "configure_ort": 40, "op_typ": [40, 44, 45], "create_inference_sess": 40, "onnx_path_or_model": 40, "inferencesess": 40, "byte": [40, 43, 45, 174], "get_quantizable_op_typ": 40, "_configure_ort": 40, "suppli": [40, 44], "find_fusible_partit": 41, "partitioned_nod": 41, "non_residual_input": 41, "find_hardcoded_pattern": 41, "tail": 41, "mtl_v1": 41, "reducesum": 41, "pow": 41, "sqrt": 41, "find_layer_norm_partit": 41, "norm": [41, 102], "find_non_quantizable_partitions_from_pattern": 41, "counterpart": [41, 92, 118], "find_quantizable_nod": 41, "yet": [41, 118], "get_skiped_output_lay": 41, "paritially_quantizable_nod": 41, "insert_dq_nod": 42, "quantized_weight": 42, "insert_pre_quant_scale_nod": 42, "input_tensor": [42, 113, 140], "pre_quant_scal": [42, 63, 108, 131], "insert_qdq_nod": 42, "weight_map": 42, "make_gs_awq_scal": 42, "_basename_": 42, "make_gs_dequantize_nod": 42, "make_gs_dequantize_output": 42, "variabl": [42, 45, 70, 79, 106, 113, 130, 131, 173], "make_gs_pre_quant_scale_nod": 42, "make_gs_pre_quant_scale_output": 42, "make_gs_quantize_nod": 42, "make_gs_quantize_output": 42, "make_gs_quantized_weight": 42, "wq": 42, "make_gs_scal": 42, "make_gs_zp": 42, "qdq_to_dq": 42, "dangl": [42, 164], "replace_scale_valu": 42, "act_scales_dict": 42, "use_trt_qdq_op": 42, "trt": [42, 62, 64, 65], "pack_float32_to_4bit_cpp_bas": 43, "4bit": 43, "concecut": 43, "pack_float32_to_4bit": 43, "round_and_pack": 43, "suppos": 43, "unsign": [43, 111, 112, 113, 125, 127, 128, 130, 131, 139], "pack_float32_to_4bit_optim": 43, "mainli": 43, "reli": [43, 73], "therebi": 43, "remain": [43, 92], "keep_intermediate_fil": 44, "trt_plugin": 44, "trt_plugins_precis": 44, "rtn_dq": 44, "filenam": 44, "suffix": [44, 51, 172], "throughout": 44, "semicolon": 44, "lib_1": 44, "lib_2": 44, "tensorrtexecutionprovid": 44, "op_type_1": 44, "op_type_2": 44, "model_nam": [44, 59], "duplicate_shared_const": 45, "duplic": [45, 88, 92, 143], "find_lowest_common_ancestor": 45, "node1": 45, "node2": 45, "lowest": 45, "ancestor": 45, "lca": 45, "distanc": 45, "gen_random_input": 45, "get_all_input_nam": 45, "get_batch_s": 45, "get_batch_size_from_byt": 45, "onnx_byt": 45, "get_child_nod": 45, "get_input_nam": 45, "external_inputs_onli": 45, "external_input_nam": 45, "initializer_nam": 45, "get_input_names_from_byt": 45, "model_byt": 45, "get_input_shap": 45, "get_input_shapes_from_byt": 45, "get_node_nam": 45, "get_node_names_from_byt": 45, "get_output_nam": 45, "get_output_names_from_byt": 45, "get_output_shap": 45, "get_parent_nod": 45, "get_variable_input": 45, "is_valid_onnx_model": 45, "file_path": 45, "name_onnx_nod": 45, "assign": [45, 87, 92, 113], "statu": 45, "randomize_weight": 45, "randomize_weights_onnx_byt": 45, "remove_weights_data": 45, "save_onnx": 45, "save_as_external_data": 45, "2gb": 45, "save_onnx_bytes_to_dir": 45, "onnx_dir": 45, "onnx_nam": 45, "udpate_domain": 45, "domain": 45, "validate_batch_s": 45, "validate_onnx": 45, "modeloptconfig": [48, 72, 90, 100, 113, 142, 151], "kdlossconfig": [48, 49], "modeloptbaseconfig": [48, 53, 71, 72, 77, 90, 91, 101, 104, 113, 116, 142, 144, 151, 155], "expose_minimal_state_dict": [48, 50], "_loss": [48, 50, 52], "student_layer_nam": 48, "teacher_layer_nam": 48, "loss_modul": [48, 50], "hide": [48, 50], "unnecessarili": [48, 50], "balanc": [48, 50, 51, 113], "weigh": [48, 50], "init_model_from_model_lik": [48, 173], "model_dump": [48, 90], "dataclass": 48, "turn": [49, 157], "_modedescriptor": [49, 53, 73, 77, 91, 104, 106, 116, 144, 149, 155, 157], "encapsul": [49, 50], "inner": 49, "dynamicmodul": [50, 54, 83, 85, 86, 88, 92, 93, 98, 102, 128, 130, 145, 154, 173], "loss_reduction_fn": 50, "skip_balanc": 50, "prior": [50, 51], "situat": 50, "hide_loss_modul": 50, "manag": [50, 71, 88, 89, 91, 92, 101, 102, 114, 131, 138, 140], "temporarili": [50, 88, 92], "hide_teacher_model": 50, "fetch": 50, "modulelist": [50, 58], "aggreg": 51, "student_loss_kei": 51, "mod1_": 51, "mod1_t": 51, "mseloss": 51, "mod2_": 51, "mod2_t": 51, "mseloss_0": 51, "mseloss_1": 51, "kd": [51, 52], "set_student_loss_reduction_fn": 51, "student_loss_reduction_fn": 51, "static": [51, 91, 102, 108, 113, 120, 125, 127, 128, 130, 131, 135, 139, 161], "kd_loss_weight": 51, "kl": 52, "diverg": 52, "arxiv": [52, 102, 103, 120], "1503": 52, "02531": 52, "batchmean": 52, "soften": 52, "logits_t": 52, "logits_": 52, "treat": [52, 164], "mgdloss": 52, "2205": 52, "01529": 52, "num_student_channel": 52, "num_teacher_channel": 52, "alpha_mgd": 52, "lambda_mgd": 52, "out_": 52, "out_t": 52, "bxcxhxw": 52, "exportstudentmodedescriptor": 53, "inspect": [53, 58, 77, 104, 116, 144, 155], "config_class": [53, 77, 104, 116, 144, 155], "entrypoint": [53, 71, 73, 77, 97, 104, 116, 144, 155], "is_export_mod": [53, 77, 116, 144], "knowledgedistillationmodedescriptor": 53, "export_mod": [53, 77, 104, 116, 144], "next_mod": [53, 77, 104, 116, 144], "immedi": [53, 77, 104, 116], "update_for_new_mod": [53, 77, 104, 116, 144], "hold": [54, 85, 164], "nfsworkspac": 56, "workspac": [56, 60], "storag": [56, 135, 136, 137], "nf": [56, 60], "modifit": 56, "commun": [56, 60], "nor": 56, "barrier": [56, 169], "respons": 56, "workspace_path": [56, 60, 62], "cross": [56, 60, 164], "sharedmemori": 56, "clean": [56, 131, 173], "is_initi": [56, 169], "read_configs_and_weights_from_rank": 56, "target_rank": 56, "write_configs_and_weight": 56, "config_json": 56, "get_configs_parallel": 56, "shm": 56, "nullabl": 56, "sync": 56, "yield": [56, 60, 70, 91, 92, 98, 106, 113, 118, 131, 149, 164], "destroi": [56, 149], "consumpt": 56, "get_tensors_parallel": 56, "model_config": [58, 60, 61, 62, 65], "empir": [58, 65], "build_attention_config": 58, "model_metadata_config": 58, "ext_config": 58, "decoderlayerconfig": [58, 59, 65], "attentionconfig": [58, 59], "build_conv_config": 58, "convconfig": [58, 59], "build_decoder_config": 58, "build_embedding_config": 58, "normalization_const": 58, "embed": [58, 59, 62, 111], "embeddingconfig": [58, 59], "build_layernorm_config": 58, "layernormconfig": [58, 59], "build_linear_config": 58, "linear_typ": [58, 59], "linearconfig": [58, 59, 61], "build_medusa_heads_config": 58, "medusaheadconfig": [58, 59], "num_medusa_head": [58, 59], "medsua_head": 58, "lm_head": [58, 59, 61, 62, 65, 72, 100, 113, 118, 142], "vocab_s": [58, 59], "hidden_s": [58, 59, 154], "num_medusa_lay": [58, 59], "linearactconfig": [58, 59], "hidden_act": [58, 59], "silu": [58, 154], "build_mlp_config": 58, "mlpconfig": [58, 59], "build_moe_config": 58, "moe": [58, 113], "moeconfig": [58, 59], "build_qkv": 58, "qkv_modul": 58, "qkv": [58, 59, 61], "qkvconfig": [58, 59, 61], "build_recurrent_config": 58, "build_stacked_expert": 58, "linear_nam": 58, "num_expert": 58, "expert_gett": 58, "experts_weight_1": 58, "experts_weight_2": 58, "check_model_compat": 58, "module_list": 58, "assembl": 58, "get_activation_scaling_factor": 58, "get_kv_cache_dtyp": 58, "kv_cach": 58, "union": [58, 93], "get_kv_cache_scaling_factor": 58, "get_prequant_scaling_factor": 58, "prequant": [58, 59], "get_qkv_and_avg_prequant_scal": 58, "averag": [58, 63], "get_quantization_format": 58, "children": 58, "get_scaling_factor": 58, "get_transformer_lay": 58, "get_weight_block_s": 58, "get_weight_scaling_factor": 58, "get_weight_scaling_factor_2": 58, "secondari": 58, "is_attent": 58, "is_decoder_list": 58, "is_embed": 58, "is_layernorm": 58, "is_linear": 58, "is_mlp": 58, "is_mo": 58, "is_quantlinear": 58, "is_recurr": 58, "kv_cache_scaling_factor": 59, "kv_cache_dtyp": 59, "rotary_dim": 59, "inf": 59, "clip_qkv": 59, "rel_attn_t": 59, "input_layernorm": 59, "mlp_layernorm": 59, "post_layernorm": [59, 64], "pre_feedforward_layernorm": 59, "post_feedforward_layernorm": 59, "num_attention_head": [59, 103, 106], "attention_head_s": 59, "num_kv_head": 59, "max_position_embed": 59, "rotary_pct": 59, "use_alibi": 59, "new_decoder_architectur": 59, "parallel_attent": 59, "apply_residual_connection_post_layernorm": 59, "rope_ratio": 59, "seq_length": 59, "qwen_typ": 59, "rotary_bas": 59, "partial_rotary_factor": 59, "original_max_position_embed": 59, "longrope_scaling_short_factor": 59, "longrope_scaling_long_factor": 59, "mup_attn_multipli": 59, "mup_embedding_multipli": 59, "mup_use_sc": 59, "mup_width_multipli": 59, "blocksparse_block_s": 59, "blocksparse_homo_head_pattern": 59, "blocksparse_num_local_block": 59, "blocksparse_vertical_strid": 59, "dense_attention_every_n_lay": 59, "gegelu_limit": 59, "longrope_short_mscal": 59, "longrope_long_mscal": 59, "moe_num_expert": 59, "moe_top_k": 59, "moe_tp_mod": 59, "moe_renorm_mod": 59, "alibi_bias_max": 59, "residual_layernorm": 59, "residual_mlp": 59, "rnn_hidden_s": 59, "logits_soft_cap": 59, "emb_scale_by_sqrt_dim": 59, "layer_typ": 59, "final_logit_softcap": 59, "attn_logit_softcap": 59, "query_pre_attn_scalar": 59, "cross_attent": 59, "cross_attention_layernorm": 59, "self_attent": 59, "self_attention_layernorm": 59, "attention_layernorm": 59, "rel_attn_max_dist": 59, "rel_attn_num_bucket": 59, "rope_sc": 59, "recurrentconfig": 59, "ffn_hidden_size_loc": 59, "ffn": 59, "local_vocab_s": 59, "expertconfig": 59, "fc": 59, "proj": 59, "layernorm_typ": 59, "activation_scaling_factor": 59, "weights_scaling_factor": [59, 61], "weights_scaling_factor_2": 59, "prequant_scaling_factor": 59, "awq_block_s": 59, "gate": [59, 113], "merged_fc1_g": 59, "mixtur": 59, "router": [59, 113], "medusa_lay": 59, "modelconfig": [59, 61, 62, 65], "pipeline_parallel": 59, "tensor_parallel": 59, "vocab_embed": 59, "position_embed": 59, "block_embed": 59, "ln_emb": 59, "ln_f": 59, "share_embedding_t": 59, "medusa_head": 59, "enc_dec": [59, 65], "encoder_hidden_s": 59, "encoder_num_head": 59, "encoder_head_s": 59, "num_key_value_head": 59, "vocab_size_pad": 59, "concat": 59, "quanitz": 59, "weight_scaling_factor_2": 59, "recurrentblock": 59, "linear_i": 59, "y_bia": 59, "linear_x": 59, "linear_out": 59, "rg_lru": 59, "rglruconfig": 59, "rg": 59, "lru": 59, "recurrent_param": 59, "input_g": 59, "recurrent_g": 59, "export_npz": 60, "naive_fp8_quant": 60, "use_nfs_workspac": 60, "manual": [60, 161, 164], "old": 60, "naiv": 60, "nest": [60, 61], "pretrainedconfig": 60, "modeling_util": 60, "tensorrt_llm_config": [60, 65], "from_quantized_weight": 61, "torch_dtyp": 61, "merge_fc1_g": 61, "merge_qkv": 61, "model_config_from_dict": 61, "model_config_to_dict": 61, "naive_quant": 61, "pack_linear_weight": 61, "pad_weight": 61, "tp_size": [61, 65], "restore_model_config": 61, "recurs": [61, 92, 98, 101, 114, 164, 165, 176], "split_config_and_weight": 61, "to_quantized_weight": 61, "check_weight_shape_valid": 62, "training_tensor_parallel": 62, "tp": [62, 65], "recurisv": 62, "pad_embedding_lm_head": 62, "padding_factor": 62, "postprocess_model_config": 62, "training_pipeline_parallel": 62, "pp": 62, "postprocess_tensor": 62, "force_cpu": 62, "force_contigu": 62, "force_non_view": 62, "update_lm_head_quant": 62, "quantlinear": [62, 127], "adjust_attn_amax_valu": 63, "convert_state_dict_amax_to_scal": 63, "quantized_state_dict": 63, "maxbound": [63, 131], "_amax": 63, "get_weights_scaling_factor_and_amax": 63, "group_siz": 63, "facotr": 63, "resmooth_and_get_scale_and_amax": 63, "merged_weight": 63, "avg_pre_quant_scal": 63, "resmooth": 63, "weight_scaling_factor": 63, "layernormpositiontyp": 64, "intenum": 64, "__new__": [64, 135], "pre_layernorm": 64, "layernormtyp": 64, "groupnorm": [64, 72, 100], "rmsnorm": 64, "mlptype": 64, "fusedgatedmlp": 64, "gatedmlp": 64, "convert_to_tensorrt_llm_config": 65, "weight_kei": 65, "tp_size_overwrit": 65, "overwrit": [65, 72, 92, 100, 142], "builder": 65, "unshard": 65, "is_tensorrt_llm_0_8_or_9": 65, "prepare_enc_dec_decoder_lay": 65, "layer_config": 65, "t5config": 65, "prepare_enc_dec_export_dir": 65, "export_root": 65, "weights_to_npz": 65, "convert_to_transformer_engin": 66, "transformers_engin": 66, "export_hf": 67, "export_to_vllm": 68, "export_path": 68, "strict": [70, 72, 73, 88, 92, 131, 159], "use_centroid": 70, "convent": [70, 97, 106, 139], "keyword": [70, 92, 106, 111, 167, 173], "kw_only_arg": [70, 106, 173], "z": [70, 106, 173], "interpret": [70, 106, 139, 173], "arg_nam": [70, 106], "constraintsfunc": [70, 71], "0e6": 70, "5e8": 70, "median": [70, 175], "determinist": [70, 175], "is_all_sat": 70, "prunabl": [70, 97, 102], "carefulli": [70, 106, 149], "significantli": [70, 106, 149], "run_forward_loop": [70, 106, 118, 149, 173], "max_iter_data_load": [70, 97, 106], "histori": [70, 71, 91, 97, 106, 118], "autonaspatchmanag": [71, 101], "patchmanag": 71, "monkei": [71, 73, 161], "automod": 71, "sample_during_train": [71, 101], "evolvesearch": 71, "iterativesearch": [71, 101], "evolutionari": 71, "after_step": [71, 101], "before_search": [71, 97, 101, 102, 103, 108, 148], "before_step": [71, 101], "default_search_config": [71, 97, 102, 103, 108, 147, 148], "default_state_dict": [71, 97, 101, 103, 108, 147], "mutat": 71, "crossov": 71, "basesearch": [71, 77, 97, 103, 104, 108, 144, 147], "abc": [71, 97], "after_search": [71, 97, 148], "best_histori": 71, "constraints_func": 71, "early_stop": [71, 101], "earli": [71, 101], "iter_num": 71, "run_search": [71, 97, 103, 108, 147], "run_step": 71, "routin": 71, "sanitize_search_config": [71, 97, 102, 103, 108, 147], "sanit": [71, 97, 102, 103, 108, 147], "randomsearch": 71, "steo": 71, "convert_autonas_searchspac": 71, "convert_searchspac": 71, "patch_manager_typ": 71, "export_searchspac": 71, "exportconfig": [71, 72], "restore_autonas_searchspac": 71, "restore_export": 71, "restore_searchspac": 71, "patch_manag": 71, "update_autonas_metadata": 71, "modeloptbaseruleconfig": [72, 90, 100, 142], "channels_ratio": [72, 86, 100], "features_ratio": [72, 100], "batchnorm1d": [72, 100], "batchnorm3d": [72, 100], "syncbatchnorm": [72, 86, 100], "instancenorm1d": [72, 100, 126], "instancenorm2d": [72, 100, 126], "instancenorm3d": [72, 100, 126], "min_depth": [72, 86, 162], "dynamicbatchnorm1dconfig": [72, 100], "deactiv": [72, 100, 138, 142, 173], "glob": [72, 73, 100, 142], "unnest": [72, 100, 142], "dynamicbatchnorm2dconfig": [72, 100], "dynamicbatchnorm3dconfig": [72, 100], "dynamicconv1dconfig": [72, 100], "dynamicconv2dconfig": [72, 100], "dynamicconv3dconfig": [72, 100], "dynamicconvtranspose1dconfig": [72, 100], "dynamicconvtranspose2dconfig": [72, 100], "dynamicconvtranspose3dconfig": [72, 100], "dynamicgroupnormconfig": [72, 100], "dynamicinstancenorm1dconfig": [72, 100], "dynamicinstancenorm2dconfig": [72, 100], "dynamicinstancenorm3dconfig": [72, 100], "dynamiclayernormconfig": [72, 100], "dynamiclinearconfig": [72, 100], "dynamicsequentialconfig": 72, "dynamicsyncbatchnormconfig": [72, 100], "calib": [72, 73], "exactli": [72, 102, 173], "augment": [73, 161, 178], "render": [73, 178], "incompat": [73, 178], "inherit": [73, 92], "qualifi": 73, "appear": [73, 173], "prioriti": 73, "spatial_conv": [73, 86], "334": [73, 86], "667": [73, 86], "entri": [73, 113, 114, 140], "concattracedhp": 75, "tracedhp": [75, 76, 87], "stitch": 75, "active_slic": [75, 93], "slice": [75, 83, 93], "longtensor": [75, 83, 93], "hp1": 75, "hp2": 75, "hp": [75, 87, 88, 92], "depthhparam": 76, "autonasmodedescriptor": 77, "search_algorithm": [77, 104, 144], "update_for_sav": [77, 104, 116, 144], "exportmodedescriptor": 77, "equival": [78, 93, 113, 114, 118], "get_sliced_tensor": 83, "mod": [83, 164], "hp_name": 83, "get_sliced_tensor_by_slic": 83, "dynamicspac": [86, 92], "searchspac": [86, 88], "stub": 86, "sym_map": 86, "symbol": [86, 87, 92, 93, 139, 159, 160, 161, 162], "symmap": [86, 159, 164], "dm_registri": [86, 92], "_dmregistrycl": [86, 92], "print_summari": 86, "skipped_hparam": [86, 88], "sample_func": [86, 88], "unix": 86, "shell": 86, "preced": 86, "wilcard": 86, "parameter_nam": [86, 88, 92], "sort_paramet": 86, "propag": 86, "generate_search_spac": 86, "det_block": 86, "outlin": 86, "analyz": 86, "analysi": [86, 158], "classmethod": [87, 90, 91, 92, 108, 135, 136, 137, 164, 165], "initialize_from": 87, "resolve_depend": 87, "sym": [87, 161], "get_hp": 87, "parent": [87, 92, 114, 164, 165], "tracedhpregistri": 87, "sym_cl": 87, "mysymbol": 87, "myhparam": 87, "unregist": [87, 90, 114, 164, 165], "previous": [87, 91, 144, 153, 164], "throw": [87, 116, 132, 138, 164], "keyerror": [87, 164], "enable_modelopt_patch": 88, "_decoratorcontextmanag": 88, "decor": [88, 164, 174], "parenthesi": 88, "no_modelopt": 88, "enable_modelopt": 88, "get_subnet_config": 88, "inference_flop": 88, "data_shap": 88, "1000000": [88, 173], "return_str": 88, "1e6": [88, 173], "million": [88, 173], "is_modelopt_patches_en": 88, "no_modelopt_patch": 88, "print_search_space_summari": 88, "replace_forward": 88, "new_forward": 88, "forward_origin": 88, "fake_forward": 88, "out_origin": 88, "set_modelopt_patches_en": 88, "thread": 88, "set_modelopt_en": 88, "clone": 88, "ingest": 89, "wihin": 89, "pydant": 90, "basemodel": 90, "easier": [90, 111], "manipul": 90, "alia": [90, 93, 125, 127, 129, 164], "get_field_name_from_kei": 90, "alias": 90, "itemsview": 90, "keysview": 90, "model_dump_json": 90, "valuesview": 90, "modeloptbaserul": 90, "customize_rul": 90, "construct": [90, 92, 130, 131], "get_rule_typ": 90, "wrapped_onli": 90, "typealia": 90, "validate_rul": 90, "made": 90, "register_default": 90, "extra_default": 90, "unregister_default": 90, "modeloptfield": 90, "pydanticundefin": 90, "get_kwargs_for_create_model_with_rul": 90, "default_rul": 90, "create_model": 90, "rule_field": 90, "docstr": 90, "pertain": 90, "myruleconfig": 90, "get_create_model_kwargs_for_rule_model": 90, "sparsemagnitudeconfig": [90, 142, 149], "autodoc": 90, "workaround": 90, "burden": 90, "modeloptstatemanag": 91, "correspondig": 91, "init_st": 91, "add_mod": 91, "_state": 91, "recal": 91, "check_mod": 91, "get_config_class": 91, "has_stat": 91, "trivial": 91, "is_convert": 91, "is_root": 91, "last_mod": 91, "modes_with_st": 91, "transfer_state_dict": 91, "model_from": 91, "model_to": [91, 173], "update_last_state_before_new_mod": 91, "update_last_state_before_sav": 91, "apply_mod": 91, "quantizemodedescriptor": [91, 116], "_moderegistrycl": 91, "retriev": [91, 173], "bias": 91, "model_weight": 91, "pathlik": 91, "binaryio": 91, "locat": [91, 114], "restore_from_modelopt_st": 91, "famili": 92, "dynamicconv2d": 92, "callback": [92, 93], "temporari": [92, 131], "expos": 92, "outermost": 92, "child": [92, 111, 154], "dynamiclinear": 92, "__class__": 92, "inject": 92, "rigoruo": 92, "fashion": 92, "mutual": [92, 164], "exlus": 92, "dyanmic": 92, "kept": [92, 113, 173], "until": [92, 173], "extra_repr": [92, 131], "__dict__": 92, "heavili": 92, "force_assign": 92, "forc": 92, "overwritt": 92, "buffer": [92, 131], "circumst": 92, "freez": 92, "tbe": 92, "orgin": 92, "get_hparam": [92, 98], "get_paramet": 92, "scalabl": 92, "overriden": 92, "out_features_ratio": 92, "fly": [92, 130], "leav": 92, "intact": 92, "some_dynamic_modul": 92, "named_hparam": [92, 98], "reset_dynamic_attribut": 92, "interf": 92, "setattr": 92, "delattr": 92, "exit": [92, 114], "convert_to_dynam": 92, "is_configur": [92, 93, 98], "is_dynam": [92, 98, 164], "named_dynamic_modul": [92, 98], "exact": 92, "ident": 93, "activeslic": 93, "importanceestim": 93, "customhptyp": [93, 108], "enforce_ord": 93, "_order": 93, "todo": 93, "ever": [93, 116], "cycl": 93, "detector": 93, "1d": [93, 125, 143], "notion": 93, "is_sort": [93, 164], "sortabl": [93, 164], "register_import": 93, "importance_estim": 93, "arbitrari": 94, "save_directori": 96, "pretrained_model_name_or_path": 96, "whenev": [97, 161], "conjunct": [97, 178], "construct_forward_loop": 97, "silent": 97, "progress_bar_msg": 97, "post_process_fn": [97, 117], "runnabl": 97, "eval_scor": 97, "has_scor": 97, "load_search_checkpoint": [97, 101], "reset_search": 97, "reset": [97, 111, 112, 114, 131, 161], "save_search_checkpoint": 97, "search_space_s": 98, "accommod": 99, "natur": [99, 139, 164], "15000000000000002": 100, "30000000000000004": 100, "35000000000000003": 100, "45": 100, "6000000000000001": 100, "7000000000000001": 100, "8500000000000001": 100, "9500000000000001": 100, "gradnasconfig": [100, 106], "mcoregptminitronconfig": [100, 106], "fasna": 101, "binarysearch": [101, 102], "boundari": 101, "interv": 101, "middl": 101, "enough": 101, "hparam_names_for_search": [101, 102], "hparam_types_for_search": 101, "original_scor": 101, "max_degrad": 101, "middle_valu": 101, "min_degrad": 101, "sensitivity_map": 101, "fastnaspatchmanag": 101, "convert_fastnas_searchspac": 101, "restore_fastnas_searchspac": 101, "l1": 102, "abstractli": 102, "pdf": [102, 103], "1905": 102, "10650": 102, "gradientbinarysearch": 102, "setup_gradient_func": 102, "gradientdatamanag": 102, "removablehandl": 102, "gradnas_score_func": 102, "neuron": [102, 103, 111], "l": 102, "validation_scor": 102, "reduce_func": 102, "process_gradi": 102, "2407": 103, "14679": 103, "mcoregptminitronsearch": 103, "supported_hparam": 103, "ffn_hidden_s": [103, 106], "num_query_group": [103, 106], "fastnasmodedescriptor": 104, "gradnasmodedescriptor": 104, "mcoregptminitronmodedescriptor": 104, "export_config": 106, "5e6": 106, "autoquantizesearch": [108, 118], "autoquant": [108, 118], "solver": 108, "taylor": 108, "expans": 108, "fisher": 108, "hessian": [108, 148, 149], "mathemat": 108, "likelihood": 108, "proxi": [108, 165], "resnet": 108, "candidate_stat": 108, "gradient_checkpointing_enable_context": 108, "_is_supported_hf_model": 108, "setup_model_for_gradient_checkpoint": 108, "insert_hparams_after_merge_rul": 108, "quant_recip": 108, "register_gradient_checkpointing_enable_context": 108, "is_supported_check": 108, "q_proj": [108, 118], "k_proj": [108, 118], "v_proj": [108, 118], "gate_proj": 108, "up_proj": 108, "w1": 108, "w2": 108, "w3": 108, "w1_linear": 108, "w2_linear": 108, "w3_linear": 108, "quantizeconfig": [108, 113, 118], "disable_folding_pqs_to_weight": 108, "fold_pqs_to_weight": 108, "quantrecipehparam": 108, "nn_modul": 108, "histogramcalibr": 111, "_calibr": [111, 112, 113], "compute_amax": [111, 112, 131], "percentil": 111, "axi": [111, 112, 113, 125, 127, 128, 130, 131, 140], "boolean": [111, 112, 122, 131, 139, 140], "num_bin": 111, "grow_method": 111, "skip_zero": 111, "torch_hist": 111, "histc": 111, "start_bin": 111, "calibrate_weight": 111, "perchannel": 111, "collector": 111, "But": 111, "haven": 111, "decoupl": 111, "maxcalibr": 112, "calib_desc": 112, "maxcalibdescriptor": 112, "readonli": 112, "plot": 112, "track_amax": 112, "runtimeerror": 112, "cnn": 113, "int4_awq_cfg": 113, "w4a8_awq_beta_cfg": 113, "miss": 113, "sequentialquant": [113, 114, 128, 130, 131], "quantmoduleregistri": 113, "class_nam": 113, "get_kei": 113, "my_quant_cfg": 113, "leakyrelu": 113, "block_sparse_mo": 113, "int4_blockwise_weight_only_cfg": 113, "awq_lit": [113, 117], "awq_ful": [113, 117], "max_co_batch_s": [113, 117], "custom_int4_awq_cfg": 113, "deepcopi": [113, 161], "awqclipcalibconfig": [113, 117], "quantizealgorithmconfig": 113, "oom": 113, "out_featur": [113, 164], "max_tokens_per_batch": 113, "min_clip_ratio": 113, "shrink_step": 113, "gt": 113, "le": 113, "awqfullcalibconfig": [113, 117], "awqlitecalibconfig": [113, 117], "maxcalibconfig": [113, 117], "smoothquantcalibconfig": [113, 117], "realquantizeconfig": [113, 117], "fake_qu": [113, 125, 127, 128, 130, 131], "narrow_rang": [113, 125, 127, 128, 130, 131, 139], "learn_amax": [113, 125, 127, 128, 130], "trt_high_precision_dtyp": [113, 125, 127, 128, 130, 131, 139], "ax": 113, "kcr": 113, "quant_axi": 113, "scale_bit": 113, "scale_block_s": [113, 137], "histogram": 113, "standardize_constructor_arg": [113, 173], "narrow": 113, "emul": 113, "fpx": 113, "half": 113, "bfloat16": [113, 131], "additional_algorithm": [113, 117], "smooth": 113, "outlier": 113, "hyper": 113, "migrat": 113, "strength": 113, "difficulti": 113, "ge": 113, "replace_quant_modul": 114, "set_quantizer_attribut": 114, "quant_model": 114, "wildcard_or_filter_func": [114, 118], "parent_class": 114, "finegrain": 114, "set_quantizer_by_cfg": 114, "set_quantizer_by_cfg_context": 114, "caution": 114, "unexpect": 114, "get_cuda_ext": 115, "extent": 115, "tensor_qu": [115, 131], "get_cuda_ext_fp8": 115, "tensor_quant_fp8": 115, "descriptor": [116, 144, 155], "quantizeexportmodedescriptor": 116, "placehold": [116, 132, 138], "properli": 116, "4096": 117, "real_quant": 117, "postprocess_amax": 117, "num_calib_step": 118, "num_score_step": 118, "taken": [118, 173], "belong": 118, "regex": 118, "r": 118, "readili": 118, "disable_quant": 118, "enable_quant": 118, "clipfunct": 120, "univers": [120, 139], "clamp": [120, 122], "doesn": [120, 130, 140, 165], "broadcast": [120, 139], "genar": 120, "ibm": 120, "pact": 120, "1805": 120, "06085": 120, "tensorflow": [120, 139, 173], "clip_by_valu": 120, "ctx": [120, 139], "grad_output": [120, 139], "clip_value_min": [120, 122], "clip_value_max": [120, 122], "learn_min": 122, "learn_max": 122, "quantconv1d": 125, "quantconv2d": 125, "quantconv3d": 125, "quantconvtranspose1d": 125, "quantconvtranspose2d": 125, "quantconvtranspose3d": 125, "_legacyquantlinearconvbasemixin": [125, 127], "default_quant_desc_weight": [125, 127, 128, 130], "transpos": 125, "quantinstancenorm1d": 126, "_legacyquantinputbasemixin": [126, 129], "quantinstancenorm2d": 126, "4d": 126, "quantinstancenorm3d": 126, "5d": 126, "quantinputbas": 128, "default_quant_desc_input": [128, 130], "default_quant_desc_output": 128, "quantlinearconvbas": 128, "initialize_quantizer_with_dummy_st": 128, "quantize_weight": [128, 130], "adaptiveavgpool1d": 129, "quantadaptiveavgpool1d": 129, "quantadaptiveavgpool2d": 129, "adaptiveavgpool3d": 129, "quantadaptiveavgpool3d": 129, "avgpool1d": 129, "quantavgpool1d": 129, "avgpool2d": 129, "quantavgpool2d": 129, "avgpool3d": 129, "quantavgpool3d": 129, "maxpool1d": 129, "quantmaxpool1d": 129, "maxpool2d": 129, "quantmaxpool2d": 129, "maxpool3d": 129, "quantmaxpool3d": 129, "quantrnnbas": 130, "all_input_quantizers_dis": 130, "functionals_to_replac": 130, "quantrnnfullbas": 130, "rnnlayerforward": 130, "cell": 130, "variable_len": 130, "vfrnnforward": 130, "reimplement": 130, "_vf": 130, "oringin": 130, "bidirect": 130, "num_lay": 130, "has_proj": 130, "has_bia": 130, "proj_input_quant": 130, "batch_first": 130, "vf": 130, "layer_forward": 130, "flat_weight": 130, "dropout": 130, "get_quantized_rnn_layer_forward": 130, "signatur": [130, 173], "get_quantized_rnn_layer_variable_len_forward": 130, "get_quantized_rnn_layer_variable_len_reverse_forward": 130, "lstm_cell_with_proj": 130, "lstm_cell": 130, "project": 130, "h_n": 130, "c_n": 130, "quantized_cell_forward": 130, "container": 131, "get_modelopt_st": 131, "replace_sequential_quantizer_with_single_quant": 131, "indx": 131, "attribute_dict": 131, "tensor_quantizer_iter": 131, "quant_attribute_cfg": 131, "if_quant": 131, "if_clip": 131, "_learn_amax": 131, "if_calib": 131, "clean_up_after_set_from_modelopt_st": 131, "set_from_modelopt_st": 131, "qtensor": [131, 135], "de": 131, "basequantizedtensor": [131, 135, 136, 137], "bypass": 131, "neither": 131, "disable_calib": 131, "disable_clip": 131, "disable_qu": 131, "enable_calib": 131, "enable_clip": 131, "enable_qu": 131, "export_amax": 131, "output_dtyp": [131, 139], "properties_onli": 131, "init_learn_amax": 131, "is_en": 131, "load_calib_amax": 131, "symmetr": [131, 139], "reset_amax": 131, "attribute_cfg": 131, "step_siz": 131, "sync_amax_across_distributed_group": 131, "parallel_group": 131, "distributedprocessgroup": 131, "freeze_paramet": 132, "group_paramet": 132, "match_paramet": 132, "quant_weight_inplac": 132, "apex": 133, "original_meta_tensor": 135, "quantized_data": [135, 136, 137], "quantizedtensor": 135, "fake_quant_tensor": 135, "qtensorwrapp": 135, "int4qtensor": 136, "uint8": [136, 137], "dequantz": [136, 137], "nf4qtensor": 137, "double_quant": 137, "num_scale_bit": 137, "unlik": [137, 161, 165], "enable_onnx_export": 138, "fakeaffinetensorquantfunct": 139, "affin": 139, "gemmlowp": 139, "shift": 139, "cancel": 139, "penalti": 139, "grad_input": 139, "min_rang": 139, "max_rang": 139, "granular": [139, 140], "faketensorquantfunct": 139, "tensorquantfunct": 139, "legacyfaketensorquantfunct": 139, "comment": 139, "scalede4m3funct": 139, "e4m3fi": 139, "127": 139, "grad_scal": 139, "int32": 139, "255": 139, "fake_quant_impl": 139, "quantize_op_abstract": 139, "exponent_bit": 139, "scaled_e4m3_impl": 139, "disable_fused_kernel": 139, "export_torch_mod": 140, "get_parallel_st": 140, "parallelst": 140, "is_quant": 140, "is_quantized_column_parallel_linear": 140, "is_quantized_layer_with_weight": 140, "is_quantized_row_parallel_linear": 140, "row": 140, "is_torch_library_support": 140, "exce": 140, "reduce_amax": 140, "keepdim": 140, "never": [140, 161], "meant": 140, "deprect": 140, "sens": 140, "unknown": 140, "replace_funct": 140, "new_func": 140, "exportsparseconfig": [142, 144], "export_spars": [142, 144], "sparsegptconfig": [142, 149], "sparse_gpt": 142, "sparseconv2dconfig": 142, "sparselinearconfig": 142, "inspir": 143, "magnitudesearch": 143, "basesparsesearch": [143, 147, 148], "compute_valid_1d_pattern": 143, "vector": 143, "permut": 143, "create_asp_mask": 143, "m4n2_1d": 143, "booltensor": [143, 145], "get_nmprune_info": 143, "mat": 143, "mn_1d_best": 143, "reshape_1d": 143, "dimension": 143, "hw": 143, "exportsparsemodedescriptor": 144, "sparsegptmodedescriptor": 144, "sparsemagnitudemodedescriptor": 144, "convert_sparse_model": 144, "restore_export_spars": 144, "restore_sparse_model": 144, "update_sparse_metadata": 144, "sparsemodul": 145, "set_mask": 145, "sparsegptsearch": 148, "artifcat": 148, "hook": [148, 173], "create_sgpt_mask": 148, "invert": 148, "hessian_damp": 148, "invers": 148, "finish": 149, "medusaconfig": [151, 153, 157], "resblock": [151, 154], "convert_to_medusa_model": 153, "restore_medusa_model": 153, "medusamodedescriptor": 155, "analyze_symbol": 159, "concrete_arg": [159, 165], "_strict": 159, "happen": 159, "concret": [159, 165], "_only_": 161, "truli": 161, "cat": 161, "x1": 161, "x2": 161, "y1": 161, "y2": 161, "concatnodeprocessor": 161, "nodeprocessor": 161, "is_special_nod": 161, "post_process": [161, 173], "input_nod": 161, "concatsymbol": 161, "concat_sym": 161, "symbl": 161, "orig_sym": 161, "cat_dim": 161, "create_linked_copi": 161, "link_to": [161, 162, 164], "cl_type": [161, 164], "cltype": [161, 164], "elastic_dim": [161, 164], "_memo": [161, 162, 164], "anywai": 161, "input_sym": 161, "is_const": [161, 164], "is_search": [161, 164], "symdepth": 162, "max_depth": 162, "is_skipp": 162, "skippabl": 162, "sp_parent": [162, 164], "set_skipp": 162, "skippable_idx": 162, "syminfo": 164, "symdict": 164, "is_shape_preserv": 164, "symregisterfunc": 164, "add_sym_info": 164, "sym_info": 164, "get_symbol": 164, "named_modul": 164, "_mod_to_nam": 164, "named_sym_dict": 164, "named_symbol": 164, "nn_cl": 164, "is_explicit_leaf": 164, "leaf": [164, 165], "get_linear_sym_info": 164, "in_featur": 164, "incom": 164, "outgo": 164, "set_symbol": 164, "symmodul": 164, "compound": 164, "is_cross_lay": 164, "is_dangl": 164, "cross_lay": 164, "df": 164, "nchw": 164, "elast": 164, "notat": 164, "is_fre": 164, "is_incom": 164, "is_outgo": 164, "graphcollect": 165, "failure_msg": 165, "is_fail": 165, "is_unvisit": 165, "unvisit": 165, "recursive_trac": 165, "coverag": 165, "robusttrac": 165, "robust": 165, "is_leaf_modul": 165, "module_qualified_nam": 165, "is_registered_leaf": 165, "record_call_modul": 165, "call_modul": 165, "register_leaf": 165, "unregister_leaf": 165, "cpp": 167, "load_cpp_extens": 167, "cuda_version_specifi": 167, "fail_msg": 167, "load_kwarg": 167, "create_forward_loop": 168, "dataset_nam": 168, "cnn_dailymail": 168, "max_sample_length": 168, "include_label": 168, "tailor": 168, "feed": [168, 173], "pretrainedtokenizerfast": 168, "tokniz": 168, "instancn": 168, "hugginfac": 168, "get_data_parallel_group": 169, "get_tensor_parallel_group": 169, "is_avail": 169, "is_mast": 169, "list_closest_to_median": 171, "avg": 171, "val2list": 171, "repeat_tim": 171, "val2tupl": 171, "min_len": 171, "idx_repeat": 171, "deprecatederror": 172, "notimplementederror": 172, "no_stdout": 172, "silenc": 172, "stdout": 172, "num2hrb": 172, "big": 172, "human": 172, "readabl": 172, "print_rank_0": 172, "compare_dict": 173, "dict1": 173, "dict2": 173, "unmatch": 173, "create_param_grad_clear_hook": 173, "fire": 173, "accum_grad": 173, "aliv": 173, "get_model_attribut": 173, "get_module_devic": 173, "get_same_pad": 173, "get_unwrapped_nam": 173, "is_channels_last": 173, "is_parallel": 173, "make_divis": 173, "divisor": 173, "min_val": 173, "repo": 173, "divis": 173, "slim": 173, "mobilenet": 173, "target_model": 173, "layout": 173, "param_num": 173, "trainable_onli": 173, "count": 173, "trainabl": 173, "param_num_from_forward": 173, "circumv": 173, "remove_bn": 173, "max_it": 173, "infiinit": 173, "exhaust": 173, "imag": 173, "set_submodul": 173, "target_submodul": 173, "complement": 173, "get_submodul": 173, "constructor_arg": 173, "standardize_model_arg": 173, "model_or_fw_or_sig": 173, "use_kwarg": 173, "matter": 173, "standardize_model_like_tupl": 173, "standardize_named_model_arg": 173, "args_norm": 173, "args_with_default": 173, "unwrap_model": 173, "raise_error": 173, "msg": 173, "force_unwrap": 173, "timer": 174, "contextdecor": 174, "clear_cuda_cach": 174, "get_cuda_memory_stat": 174, "report_memori": 174, "seq": 175, "prod": 175, "aim": 175, "cheapli": 175, "recogn": 175, "mutablesequ": 175, "numpy_to_torch": 176, "np_output": 176, "torch_detach": 176, "torch_to": 176, "torch_to_numpi": 176, "submit": 177, "methodtyp": 178, "nas_forward_func": 178, "nas_train_func": 178}, "objects": {"modelopt": [[24, 0, 0, "-", "deploy"], [28, 0, 0, "-", "onnx"], [46, 0, 0, "-", "torch"]], "modelopt.deploy": [[25, 0, 0, "-", "llm"]], "modelopt.deploy.llm": [[26, 0, 0, "-", "generate"], [27, 0, 0, "-", "nemo_utils"]], "modelopt.deploy.llm.generate": [[26, 1, 1, "", "LLM"]], "modelopt.deploy.llm.generate.LLM": [[26, 2, 1, "", "__init__"], [26, 2, 1, "", "generate_context_logits"], [26, 2, 1, "", "generate_text"], [26, 2, 1, "", "generate_tokens"], [26, 3, 1, "", "max_beam_width"], [26, 3, 1, "", "max_input_len"]], "modelopt.deploy.llm.nemo_utils": [[27, 1, 1, "", "CustomSentencePieceTokenizer"], [27, 4, 1, "", "get_nemo_tokenizer"], [27, 4, 1, "", "get_tokenzier"]], "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer": [[27, 2, 1, "", "__init__"], [27, 2, 1, "", "batch_decode"], [27, 2, 1, "", "batch_encode_plus"], [27, 2, 1, "", "decode"], [27, 2, 1, "", "encode"], [27, 3, 1, "", "eos_token"], [27, 3, 1, "", "eos_token_id"], [27, 3, 1, "", "pad_token"], [27, 3, 1, "", "pad_token_id"]], "modelopt.onnx": [[29, 0, 0, "-", "op_types"], [30, 0, 0, "-", "quantization"], [45, 0, 0, "-", "utils"]], "modelopt.onnx.op_types": [[29, 4, 1, "", "is_binary_op"], [29, 4, 1, "", "is_control_flow_op"], [29, 4, 1, "", "is_conversion_op"], [29, 4, 1, "", "is_copy_op"], [29, 4, 1, "", "is_default_quantizable_op_by_ort"], [29, 4, 1, "", "is_fusible_reduction_op"], [29, 4, 1, "", "is_generator_op"], [29, 4, 1, "", "is_irregular_mem_access_op"], [29, 4, 1, "", "is_linear_op"], [29, 4, 1, "", "is_modifier_op"], [29, 4, 1, "", "is_multiclass_op"], [29, 4, 1, "", "is_non_reshape_copy_op"], [29, 4, 1, "", "is_normalization_op"], [29, 4, 1, "", "is_pointwise_or_elementwise_op"], [29, 4, 1, "", "is_pooling_or_window_op"], [29, 4, 1, "", "is_recurrent_op"], [29, 4, 1, "", "is_selection_op"], [29, 4, 1, "", "is_sequence_op"], [29, 4, 1, "", "is_shape_op"], [29, 4, 1, "", "is_unary_op"]], "modelopt.onnx.quantization": [[31, 0, 0, "-", "calib_utils"], [32, 0, 0, "-", "extensions"], [33, 0, 0, "-", "fp8"], [34, 0, 0, "-", "graph_utils"], [35, 0, 0, "-", "gs_patching"], [36, 0, 0, "-", "int4"], [37, 0, 0, "-", "int8"], [38, 0, 0, "-", "operators"], [39, 0, 0, "-", "ort_patching"], [40, 0, 0, "-", "ort_utils"], [41, 0, 0, "-", "partitioning"], [42, 0, 0, "-", "qdq_utils"], [43, 0, 0, "-", "quant_utils"], [44, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.calib_utils": [[31, 1, 1, "", "CalibrationDataProvider"], [31, 1, 1, "", "RandomDataProvider"], [31, 4, 1, "", "import_scales_from_calib_cache"]], "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.calib_utils.RandomDataProvider": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.fp8": [[33, 4, 1, "", "int8_to_fp8"], [33, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.graph_utils": [[34, 4, 1, "", "add_fp16_fp32_cast"], [34, 4, 1, "", "build_non_residual_input_map"], [34, 4, 1, "", "classify_partition_nodes"], [34, 4, 1, "", "expand_node_names_from_patterns"], [34, 4, 1, "", "filter_quantizable_kgen_heads"], [34, 4, 1, "", "find_fp8_mha_partitions"], [34, 4, 1, "", "find_mha_partitions"], [34, 4, 1, "", "find_nodes_from_mha_to_exclude"], [34, 4, 1, "", "find_nodes_to_exclude"], [34, 4, 1, "", "get_fusible_backbone"], [34, 4, 1, "", "get_tensor_consumer_nodes"], [34, 4, 1, "", "get_tensor_producer_nodes"], [34, 4, 1, "", "has_const_input"], [34, 4, 1, "", "has_path_type"], [34, 4, 1, "", "insert_fp8_mha_casts"], [34, 4, 1, "", "insert_matmul_casts"], [34, 4, 1, "", "is_const_input"], [34, 4, 1, "", "print_stat"], [34, 4, 1, "", "remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[35, 4, 1, "", "patch_gs_modules"]], "modelopt.onnx.quantization.int4": [[36, 1, 1, "", "AWQClipHelper"], [36, 1, 1, "", "AWQLiteHelper"], [36, 4, 1, "", "dq_tensor"], [36, 4, 1, "", "find_scales"], [36, 4, 1, "", "get_act_scale"], [36, 4, 1, "", "get_scale"], [36, 4, 1, "", "get_weight_scale"], [36, 4, 1, "", "quant_tensor"], [36, 4, 1, "", "quantize"], [36, 4, 1, "", "quantize_awq_clip"], [36, 4, 1, "", "quantize_awq_lite"], [36, 4, 1, "", "quantize_rtn"], [36, 4, 1, "", "rtn"]], "modelopt.onnx.quantization.int4.AWQClipHelper": [[36, 2, 1, "", "__init__"], [36, 5, 1, "", "alpha_step"], [36, 5, 1, "", "alphas"], [36, 5, 1, "", "min_alpha"], [36, 2, 1, "", "update_best_params"]], "modelopt.onnx.quantization.int4.AWQLiteHelper": [[36, 2, 1, "", "__init__"], [36, 5, 1, "", "alpha_step"]], "modelopt.onnx.quantization.int8": [[37, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.operators": [[38, 1, 1, "", "QDQConvTranspose"], [38, 1, 1, "", "QDQNormalization"]], "modelopt.onnx.quantization.operators.QDQConvTranspose": [[38, 2, 1, "", "__init__"], [38, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.operators.QDQNormalization": [[38, 2, 1, "", "__init__"], [38, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.ort_patching": [[39, 4, 1, "", "patch_ort_modules"]], "modelopt.onnx.quantization.ort_utils": [[40, 4, 1, "", "configure_ort"], [40, 4, 1, "", "create_inference_session"], [40, 4, 1, "", "get_quantizable_op_types"]], "modelopt.onnx.quantization.partitioning": [[41, 4, 1, "", "find_fusible_partitions"], [41, 4, 1, "", "find_hardcoded_patterns"], [41, 4, 1, "", "find_layer_norm_partitions"], [41, 4, 1, "", "find_mha_partitions"], [41, 4, 1, "", "find_non_quantizable_partitions_from_patterns"], [41, 4, 1, "", "find_quantizable_nodes"], [41, 4, 1, "", "get_skiped_output_layers"]], "modelopt.onnx.quantization.qdq_utils": [[42, 4, 1, "", "insert_dq_nodes"], [42, 4, 1, "", "insert_pre_quant_scale_nodes"], [42, 4, 1, "", "insert_qdq_nodes"], [42, 4, 1, "", "make_gs_awq_scale"], [42, 4, 1, "", "make_gs_dequantize_node"], [42, 4, 1, "", "make_gs_dequantize_output"], [42, 4, 1, "", "make_gs_pre_quant_scale_node"], [42, 4, 1, "", "make_gs_pre_quant_scale_output"], [42, 4, 1, "", "make_gs_quantize_node"], [42, 4, 1, "", "make_gs_quantize_output"], [42, 4, 1, "", "make_gs_quantized_weight"], [42, 4, 1, "", "make_gs_scale"], [42, 4, 1, "", "make_gs_zp"], [42, 4, 1, "", "qdq_to_dq"], [42, 4, 1, "", "replace_scale_values"], [42, 4, 1, "", "use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[43, 4, 1, "", "pack_float32_to_4bit_cpp_based"], [43, 4, 1, "", "pack_float32_to_4bit_optimized"]], "modelopt.onnx.utils": [[45, 4, 1, "", "duplicate_shared_constants"], [45, 4, 1, "", "find_lowest_common_ancestor"], [45, 4, 1, "", "gen_random_inputs"], [45, 4, 1, "", "get_all_input_names"], [45, 4, 1, "", "get_batch_size"], [45, 4, 1, "", "get_batch_size_from_bytes"], [45, 4, 1, "", "get_child_nodes"], [45, 4, 1, "", "get_input_names"], [45, 4, 1, "", "get_input_names_from_bytes"], [45, 4, 1, "", "get_input_shapes"], [45, 4, 1, "", "get_input_shapes_from_bytes"], [45, 4, 1, "", "get_node_names"], [45, 4, 1, "", "get_node_names_from_bytes"], [45, 4, 1, "", "get_output_names"], [45, 4, 1, "", "get_output_names_from_bytes"], [45, 4, 1, "", "get_output_shapes"], [45, 4, 1, "", "get_parent_nodes"], [45, 4, 1, "", "get_variable_inputs"], [45, 4, 1, "", "is_valid_onnx_model"], [45, 4, 1, "", "name_onnx_nodes"], [45, 4, 1, "", "randomize_weights"], [45, 4, 1, "", "randomize_weights_onnx_bytes"], [45, 4, 1, "", "remove_weights_data"], [45, 4, 1, "", "save_onnx"], [45, 4, 1, "", "save_onnx_bytes_to_dir"], [45, 4, 1, "", "udpate_domain"], [45, 4, 1, "", "validate_batch_size"], [45, 4, 1, "", "validate_onnx"]], "modelopt.torch": [[47, 0, 0, "-", "distill"], [55, 0, 0, "-", "export"], [69, 0, 0, "-", "nas"], [89, 0, 0, "-", "opt"], [99, 0, 0, "-", "prune"], [107, 0, 0, "-", "quantization"], [141, 0, 0, "-", "sparsity"], [150, 0, 0, "-", "speculative"], [158, 0, 0, "-", "trace"], [166, 0, 0, "-", "utils"]], "modelopt.torch.distill": [[48, 0, 0, "-", "config"], [49, 0, 0, "-", "distillation"], [50, 0, 0, "-", "distillation_model"], [51, 0, 0, "-", "loss_balancers"], [52, 0, 0, "-", "losses"], [53, 0, 0, "-", "mode"], [54, 0, 0, "-", "registry"]], "modelopt.torch.distill.config": [[48, 6, 1, "", "KDLossConfig"]], "modelopt.torch.distill.config.KDLossConfig": [[48, 7, 1, "", "criterion"], [48, 7, 1, "", "expose_minimal_state_dict"], [48, 7, 1, "", "loss_balancer"], [48, 2, 1, "", "model_dump"], [48, 7, 1, "", "teacher_model"]], "modelopt.torch.distill.distillation": [[49, 4, 1, "", "convert"], [49, 4, 1, "", "export"]], "modelopt.torch.distill.distillation_model": [[50, 1, 1, "", "DistillationModel"]], "modelopt.torch.distill.distillation_model.DistillationModel": [[50, 2, 1, "", "compute_kd_loss"], [50, 2, 1, "", "forward"], [50, 2, 1, "", "hide_loss_modules"], [50, 2, 1, "", "hide_teacher_model"], [50, 2, 1, "", "load_state_dict"], [50, 3, 1, "", "loss_balancer"], [50, 3, 1, "", "loss_modules"], [50, 2, 1, "", "modify"], [50, 2, 1, "", "state_dict"], [50, 3, 1, "", "teacher_model"]], "modelopt.torch.distill.loss_balancers": [[51, 1, 1, "", "DistillationLossBalancer"], [51, 1, 1, "", "StaticLossBalancer"]], "modelopt.torch.distill.loss_balancers.DistillationLossBalancer": [[51, 2, 1, "", "__init__"], [51, 2, 1, "", "forward"], [51, 2, 1, "", "set_student_loss_reduction_fn"]], "modelopt.torch.distill.loss_balancers.StaticLossBalancer": [[51, 2, 1, "", "__init__"], [51, 2, 1, "", "forward"]], "modelopt.torch.distill.losses": [[52, 1, 1, "", "LogitsDistillationLoss"], [52, 1, 1, "", "MGDLoss"]], "modelopt.torch.distill.losses.LogitsDistillationLoss": [[52, 2, 1, "", "__init__"], [52, 2, 1, "", "forward"]], "modelopt.torch.distill.losses.MGDLoss": [[52, 2, 1, "", "__init__"], [52, 2, 1, "", "forward"]], "modelopt.torch.distill.mode": [[53, 1, 1, "", "ExportStudentModeDescriptor"], [53, 1, 1, "", "KnowledgeDistillationModeDescriptor"]], "modelopt.torch.distill.mode.ExportStudentModeDescriptor": [[53, 3, 1, "", "config_class"], [53, 3, 1, "", "convert"], [53, 3, 1, "", "is_export_mode"], [53, 3, 1, "", "name"], [53, 3, 1, "", "restore"]], "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor": [[53, 3, 1, "", "config_class"], [53, 3, 1, "", "convert"], [53, 3, 1, "", "export_mode"], [53, 3, 1, "", "name"], [53, 3, 1, "", "next_modes"], [53, 3, 1, "", "restore"], [53, 3, 1, "", "update_for_new_mode"]], "modelopt.torch.export": [[56, 0, 0, "-", "distribute"], [57, 0, 0, "-", "hf_config_map"], [58, 0, 0, "-", "layer_utils"], [59, 0, 0, "-", "model_config"], [60, 0, 0, "-", "model_config_export"], [61, 0, 0, "-", "model_config_utils"], [62, 0, 0, "-", "postprocess"], [63, 0, 0, "-", "scaling_factor_utils"], [64, 0, 0, "-", "tensorrt_llm_type"], [65, 0, 0, "-", "tensorrt_llm_utils"], [66, 0, 0, "-", "transformer_engine"], [67, 0, 0, "-", "unified_export_hf"], [68, 0, 0, "-", "vllm"]], "modelopt.torch.export.distribute": [[56, 1, 1, "", "NFSWorkspace"], [56, 4, 1, "", "get_configs_parallel"], [56, 4, 1, "", "get_tensors_parallel"]], "modelopt.torch.export.distribute.NFSWorkspace": [[56, 2, 1, "", "__init__"], [56, 3, 1, "", "is_initialized"], [56, 2, 1, "", "read_configs_and_weights_from_rank"], [56, 2, 1, "", "write_configs_and_weights"]], "modelopt.torch.export.layer_utils": [[58, 4, 1, "", "build_attention_config"], [58, 4, 1, "", "build_conv_config"], [58, 4, 1, "", "build_decoder_config"], [58, 4, 1, "", "build_embedding_config"], [58, 4, 1, "", "build_layernorm_config"], [58, 4, 1, "", "build_linear_config"], [58, 4, 1, "", "build_medusa_heads_config"], [58, 4, 1, "", "build_mlp_config"], [58, 4, 1, "", "build_moe_config"], [58, 4, 1, "", "build_qkv"], [58, 4, 1, "", "build_recurrent_config"], [58, 4, 1, "", "build_stacked_experts"], [58, 4, 1, "", "check_model_compatibility"], [58, 4, 1, "", "get_activation_scaling_factor"], [58, 4, 1, "", "get_kv_cache_dtype"], [58, 4, 1, "", "get_kv_cache_scaling_factor"], [58, 4, 1, "", "get_prequant_scaling_factor"], [58, 4, 1, "", "get_qkv_and_avg_prequant_scale"], [58, 4, 1, "", "get_quantization_format"], [58, 4, 1, "", "get_scaling_factor"], [58, 4, 1, "", "get_transformer_layers"], [58, 4, 1, "", "get_weight_block_size"], [58, 4, 1, "", "get_weight_scaling_factor"], [58, 4, 1, "", "get_weight_scaling_factor_2"], [58, 4, 1, "", "is_attention"], [58, 4, 1, "", "is_decoder_list"], [58, 4, 1, "", "is_embedding"], [58, 4, 1, "", "is_layernorm"], [58, 4, 1, "", "is_linear"], [58, 4, 1, "", "is_mlp"], [58, 4, 1, "", "is_moe"], [58, 4, 1, "", "is_quantlinear"], [58, 4, 1, "", "is_recurrent"]], "modelopt.torch.export.model_config": [[59, 1, 1, "", "AttentionConfig"], [59, 1, 1, "", "ConvConfig"], [59, 1, 1, "", "DecoderLayerConfig"], [59, 1, 1, "", "EmbeddingConfig"], [59, 1, 1, "", "ExpertConfig"], [59, 1, 1, "", "LayernormConfig"], [59, 1, 1, "", "LinearActConfig"], [59, 1, 1, "", "LinearConfig"], [59, 1, 1, "", "MLPConfig"], [59, 1, 1, "", "MOEConfig"], [59, 1, 1, "", "MedusaHeadConfig"], [59, 1, 1, "", "ModelConfig"], [59, 1, 1, "", "QKVConfig"], [59, 1, 1, "", "RecurrentConfig"], [59, 1, 1, "", "RgLruConfig"]], "modelopt.torch.export.model_config.AttentionConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "clip_qkv"], [59, 5, 1, "", "dense"], [59, 5, 1, "", "kv_cache_dtype"], [59, 5, 1, "", "kv_cache_scaling_factor"], [59, 5, 1, "", "qkv"], [59, 5, 1, "", "rel_attn_table"], [59, 5, 1, "", "rotary_dim"]], "modelopt.torch.export.model_config.ConvConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "bias"], [59, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.DecoderLayerConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "alibi_bias_max"], [59, 5, 1, "", "apply_residual_connection_post_layernorm"], [59, 5, 1, "", "attention"], [59, 5, 1, "", "attention_head_size"], [59, 5, 1, "", "attention_layernorm"], [59, 5, 1, "", "attn_logit_softcapping"], [59, 5, 1, "", "blocksparse_block_size"], [59, 5, 1, "", "blocksparse_homo_head_pattern"], [59, 5, 1, "", "blocksparse_num_local_blocks"], [59, 5, 1, "", "blocksparse_vertical_stride"], [59, 5, 1, "", "clip_qkv"], [59, 5, 1, "", "cross_attention"], [59, 5, 1, "", "cross_attention_layernorm"], [59, 5, 1, "", "decoder_type"], [59, 5, 1, "", "dense_attention_every_n_layers"], [59, 5, 1, "", "emb_scale_by_sqrt_dim"], [59, 3, 1, "", "ffn_hidden_size_local"], [59, 5, 1, "", "final_logit_softcapping"], [59, 5, 1, "", "gegelu_limit"], [59, 3, 1, "", "hidden_size"], [59, 5, 1, "", "input_layernorm"], [59, 5, 1, "", "layer_types"], [59, 5, 1, "", "logits_soft_cap"], [59, 5, 1, "", "longrope_long_mscale"], [59, 5, 1, "", "longrope_scaling_long_factors"], [59, 5, 1, "", "longrope_scaling_short_factors"], [59, 5, 1, "", "longrope_short_mscale"], [59, 5, 1, "", "max_position_embeddings"], [59, 5, 1, "", "mlp"], [59, 5, 1, "", "mlp_layernorm"], [59, 5, 1, "", "model_name"], [59, 5, 1, "", "moe_num_experts"], [59, 5, 1, "", "moe_renorm_mode"], [59, 5, 1, "", "moe_top_k"], [59, 5, 1, "", "moe_tp_mode"], [59, 5, 1, "", "mup_attn_multiplier"], [59, 5, 1, "", "mup_embedding_multiplier"], [59, 5, 1, "", "mup_use_scaling"], [59, 5, 1, "", "mup_width_multiplier"], [59, 5, 1, "", "new_decoder_architecture"], [59, 5, 1, "", "num_attention_heads"], [59, 5, 1, "", "num_kv_heads"], [59, 5, 1, "", "original_max_position_embeddings"], [59, 5, 1, "", "parallel_attention"], [59, 5, 1, "", "partial_rotary_factor"], [59, 5, 1, "", "post_feedforward_layernorm"], [59, 5, 1, "", "post_layernorm"], [59, 5, 1, "", "pre_feedforward_layernorm"], [59, 5, 1, "", "quantization"], [59, 5, 1, "", "query_pre_attn_scalar"], [59, 5, 1, "", "qwen_type"], [59, 5, 1, "", "recurrent"], [59, 5, 1, "", "rel_attn_max_distance"], [59, 5, 1, "", "rel_attn_num_buckets"], [59, 5, 1, "", "residual_layernorm"], [59, 5, 1, "", "residual_mlp"], [59, 5, 1, "", "rnn_hidden_size"], [59, 5, 1, "", "rope_ratio"], [59, 5, 1, "", "rope_scaling"], [59, 5, 1, "", "rotary_base"], [59, 5, 1, "", "rotary_pct"], [59, 5, 1, "", "self_attention"], [59, 5, 1, "", "self_attention_layernorm"], [59, 5, 1, "", "seq_length"], [59, 5, 1, "", "use_alibi"], [59, 5, 1, "", "use_cache"]], "modelopt.torch.export.model_config.EmbeddingConfig": [[59, 2, 1, "", "__init__"], [59, 3, 1, "", "hidden_size"], [59, 3, 1, "", "local_vocab_size"], [59, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.ExpertConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "fc"], [59, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.LayernormConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "bias"], [59, 5, 1, "", "eps"], [59, 5, 1, "", "layernorm_type"], [59, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.LinearActConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "hidden_act"], [59, 5, 1, "", "linear"]], "modelopt.torch.export.model_config.LinearConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "activation_scaling_factor"], [59, 5, 1, "", "awq_block_size"], [59, 5, 1, "", "bias"], [59, 5, 1, "", "linear_type"], [59, 5, 1, "", "prequant_scaling_factor"], [59, 5, 1, "", "weight"], [59, 5, 1, "", "weights_scaling_factor"], [59, 5, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.MLPConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "fc"], [59, 5, 1, "", "gate"], [59, 5, 1, "", "hidden_act"], [59, 5, 1, "", "merged_fc1_gate"], [59, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.MOEConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "experts"], [59, 3, 1, "", "fc"], [59, 5, 1, "", "hidden_act"], [59, 5, 1, "", "router"]], "modelopt.torch.export.model_config.MedusaHeadConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "lm_head"], [59, 5, 1, "", "medusa_layers"]], "modelopt.torch.export.model_config.ModelConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "block_embedding"], [59, 5, 1, "", "dtype"], [59, 5, 1, "", "enc_dec"], [59, 5, 1, "", "encoder_head_size"], [59, 5, 1, "", "encoder_hidden_size"], [59, 5, 1, "", "encoder_num_heads"], [59, 3, 1, "", "hidden_act"], [59, 3, 1, "", "hidden_size"], [59, 5, 1, "", "layers"], [59, 5, 1, "", "lm_head"], [59, 5, 1, "", "ln_embed"], [59, 5, 1, "", "ln_f"], [59, 3, 1, "", "max_position_embeddings"], [59, 5, 1, "", "medusa_heads"], [59, 3, 1, "", "num_attention_heads"], [59, 3, 1, "", "num_kv_heads"], [59, 5, 1, "", "num_medusa_heads"], [59, 5, 1, "", "num_medusa_layers"], [59, 5, 1, "", "pipeline_parallel"], [59, 5, 1, "", "position_embedding"], [59, 5, 1, "", "quantization"], [59, 5, 1, "", "rank"], [59, 5, 1, "", "share_embedding_table"], [59, 5, 1, "", "tensor_parallel"], [59, 5, 1, "", "version"], [59, 5, 1, "", "vocab_embedding"], [59, 5, 1, "", "vocab_size"], [59, 3, 1, "", "vocab_size_padded"]], "modelopt.torch.export.model_config.QKVConfig": [[59, 2, 1, "", "__init__"], [59, 3, 1, "", "activation_scaling_factor"], [59, 3, 1, "", "awq_block_size"], [59, 3, 1, "", "bias"], [59, 5, 1, "", "k"], [59, 3, 1, "", "prequant_scaling_factor"], [59, 5, 1, "", "q"], [59, 5, 1, "", "v"], [59, 3, 1, "", "weight"], [59, 3, 1, "", "weights_scaling_factor"], [59, 3, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.RecurrentConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "conv1d"], [59, 5, 1, "", "linear_out"], [59, 5, 1, "", "linear_x"], [59, 5, 1, "", "linear_y"], [59, 5, 1, "", "rg_lru"], [59, 5, 1, "", "y_bias"]], "modelopt.torch.export.model_config.RgLruConfig": [[59, 2, 1, "", "__init__"], [59, 5, 1, "", "input_gate"], [59, 5, 1, "", "recurrent_gate"], [59, 5, 1, "", "recurrent_param"]], "modelopt.torch.export.model_config_export": [[60, 4, 1, "", "export_tensorrt_llm_checkpoint"], [60, 4, 1, "", "torch_to_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_utils": [[61, 4, 1, "", "from_quantized_weight"], [61, 4, 1, "", "merge_fc1_gate"], [61, 4, 1, "", "merge_qkv"], [61, 4, 1, "", "model_config_from_dict"], [61, 4, 1, "", "model_config_to_dict"], [61, 4, 1, "", "naive_quantization"], [61, 4, 1, "", "pack_linear_weights"], [61, 4, 1, "", "pad_weights"], [61, 4, 1, "", "restore_model_config"], [61, 4, 1, "", "split_config_and_weights"], [61, 4, 1, "", "to_quantized_weight"]], "modelopt.torch.export.postprocess": [[62, 4, 1, "", "check_weight_shape_valid"], [62, 4, 1, "", "pad_embedding_lm_head"], [62, 4, 1, "", "postprocess_model_config"], [62, 4, 1, "", "postprocess_tensors"], [62, 4, 1, "", "update_lm_head_quantization"]], "modelopt.torch.export.scaling_factor_utils": [[63, 4, 1, "", "adjust_attn_amax_values"], [63, 4, 1, "", "convert_state_dict_amax_to_scales"], [63, 4, 1, "", "get_weights_scaling_factor_and_amax"], [63, 4, 1, "", "resmooth_and_get_scale_and_amax"]], "modelopt.torch.export.tensorrt_llm_type": [[64, 1, 1, "", "LayerNormPositionType"], [64, 1, 1, "", "LayerNormType"], [64, 1, 1, "", "MLPType"]], "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType": [[64, 2, 1, "", "__new__"], [64, 5, 1, "", "post_layernorm"], [64, 5, 1, "", "pre_layernorm"]], "modelopt.torch.export.tensorrt_llm_type.LayerNormType": [[64, 5, 1, "", "GroupNorm"], [64, 5, 1, "", "LayerNorm"], [64, 5, 1, "", "RmsNorm"], [64, 2, 1, "", "__new__"]], "modelopt.torch.export.tensorrt_llm_type.MLPType": [[64, 5, 1, "", "FusedGatedMLP"], [64, 5, 1, "", "GatedMLP"], [64, 5, 1, "", "MLP"], [64, 2, 1, "", "__new__"]], "modelopt.torch.export.tensorrt_llm_utils": [[65, 4, 1, "", "convert_to_tensorrt_llm_config"], [65, 4, 1, "", "is_tensorrt_llm_0_8_or_9"], [65, 4, 1, "", "prepare_enc_dec_decoder_layer"], [65, 4, 1, "", "prepare_enc_dec_export_dir"], [65, 4, 1, "", "weights_to_npz"]], "modelopt.torch.export.transformer_engine": [[66, 4, 1, "", "convert_to_transformer_engine"]], "modelopt.torch.export.unified_export_hf": [[67, 4, 1, "", "export_hf"], [67, 4, 1, "", "export_hf_checkpoint"]], "modelopt.torch.export.vllm": [[68, 4, 1, "", "export_to_vllm"]], "modelopt.torch.nas": [[70, 0, 0, "-", "algorithms"], [71, 0, 0, "-", "autonas"], [72, 0, 0, "-", "config"], [73, 0, 0, "-", "conversion"], [74, 0, 0, "-", "hparams"], [77, 0, 0, "-", "mode"], [78, 0, 0, "-", "modules"], [84, 0, 0, "-", "plugins"], [85, 0, 0, "-", "registry"], [86, 0, 0, "-", "search_space"], [87, 0, 0, "-", "traced_hp"], [88, 0, 0, "-", "utils"]], "modelopt.torch.nas.algorithms": [[70, 4, 1, "", "profile"], [70, 4, 1, "", "search"]], "modelopt.torch.nas.autonas": [[71, 1, 1, "", "AutoNASPatchManager"], [71, 1, 1, "", "EvolveSearcher"], [71, 1, 1, "", "IterativeSearcher"], [71, 1, 1, "", "RandomSearcher"], [71, 4, 1, "", "convert_autonas_searchspace"], [71, 4, 1, "", "convert_searchspace"], [71, 4, 1, "", "export_searchspace"], [71, 4, 1, "", "restore_autonas_searchspace"], [71, 4, 1, "", "restore_export"], [71, 4, 1, "", "restore_searchspace"], [71, 4, 1, "", "update_autonas_metadata"]], "modelopt.torch.nas.autonas.AutoNASPatchManager": [[71, 3, 1, "", "sample_during_training"]], "modelopt.torch.nas.autonas.EvolveSearcher": [[71, 2, 1, "", "after_step"], [71, 2, 1, "", "before_search"], [71, 2, 1, "", "before_step"], [71, 5, 1, "", "candidates"], [71, 3, 1, "", "default_search_config"], [71, 3, 1, "", "default_state_dict"], [71, 5, 1, "", "population"], [71, 2, 1, "", "sample"]], "modelopt.torch.nas.autonas.IterativeSearcher": [[71, 2, 1, "", "after_search"], [71, 2, 1, "", "after_step"], [71, 2, 1, "", "before_search"], [71, 2, 1, "", "before_step"], [71, 5, 1, "", "best"], [71, 5, 1, "", "best_history"], [71, 5, 1, "", "candidate"], [71, 5, 1, "", "constraints_func"], [71, 3, 1, "", "default_search_config"], [71, 3, 1, "", "default_state_dict"], [71, 2, 1, "", "early_stop"], [71, 5, 1, "", "history"], [71, 5, 1, "", "iter_num"], [71, 5, 1, "", "num_satisfied"], [71, 2, 1, "", "run_search"], [71, 2, 1, "", "run_step"], [71, 2, 1, "", "sample"], [71, 5, 1, "", "samples"], [71, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.nas.autonas.RandomSearcher": [[71, 2, 1, "", "sample"]], "modelopt.torch.nas.config": [[72, 6, 1, "", "AutoNASConfig"], [72, 6, 1, "", "ExportConfig"]], "modelopt.torch.nas.config.AutoNASConfig": [[72, 7, 1, "", "nn_batchnorm1d"], [72, 7, 1, "", "nn_batchnorm2d"], [72, 7, 1, "", "nn_batchnorm3d"], [72, 7, 1, "", "nn_conv1d"], [72, 7, 1, "", "nn_conv2d"], [72, 7, 1, "", "nn_conv3d"], [72, 7, 1, "", "nn_convtranspose1d"], [72, 7, 1, "", "nn_convtranspose2d"], [72, 7, 1, "", "nn_convtranspose3d"], [72, 7, 1, "", "nn_groupnorm"], [72, 7, 1, "", "nn_instancenorm1d"], [72, 7, 1, "", "nn_instancenorm2d"], [72, 7, 1, "", "nn_instancenorm3d"], [72, 7, 1, "", "nn_layernorm"], [72, 7, 1, "", "nn_linear"], [72, 7, 1, "", "nn_sequential"], [72, 7, 1, "", "nn_syncbatchnorm"]], "modelopt.torch.nas.config.ExportConfig": [[72, 7, 1, "", "calib"], [72, 7, 1, "", "strict"]], "modelopt.torch.nas.conversion": [[73, 4, 1, "", "convert"], [73, 4, 1, "", "export"]], "modelopt.torch.nas.hparams": [[75, 0, 0, "-", "concat"], [76, 0, 0, "-", "container"]], "modelopt.torch.nas.hparams.concat": [[75, 1, 1, "", "ConcatTracedHp"]], "modelopt.torch.nas.hparams.concat.ConcatTracedHp": [[75, 3, 1, "", "active"], [75, 3, 1, "", "active_slice"]], "modelopt.torch.nas.hparams.container": [[76, 1, 1, "", "DepthHparam"]], "modelopt.torch.nas.mode": [[77, 1, 1, "", "AutoNASModeDescriptor"], [77, 1, 1, "", "ExportModeDescriptor"]], "modelopt.torch.nas.mode.AutoNASModeDescriptor": [[77, 3, 1, "", "config_class"], [77, 3, 1, "", "convert"], [77, 3, 1, "", "export_mode"], [77, 3, 1, "", "name"], [77, 3, 1, "", "next_modes"], [77, 3, 1, "", "restore"], [77, 3, 1, "", "search_algorithm"], [77, 3, 1, "", "update_for_new_mode"], [77, 3, 1, "", "update_for_save"]], "modelopt.torch.nas.mode.ExportModeDescriptor": [[77, 3, 1, "", "config_class"], [77, 3, 1, "", "convert"], [77, 3, 1, "", "is_export_mode"], [77, 3, 1, "", "name"], [77, 3, 1, "", "restore"]], "modelopt.torch.nas.modules": [[79, 0, 0, "-", "container"], [80, 0, 0, "-", "conv"], [81, 0, 0, "-", "linear"], [82, 0, 0, "-", "norm"], [83, 0, 0, "-", "utils"]], "modelopt.torch.nas.modules.utils": [[83, 4, 1, "", "get_sliced_tensor"], [83, 4, 1, "", "get_sliced_tensor_by_slices"]], "modelopt.torch.nas.search_space": [[86, 1, 1, "", "SearchSpace"], [86, 4, 1, "", "generate_search_space"]], "modelopt.torch.nas.search_space.SearchSpace": [[86, 2, 1, "", "__init__"], [86, 2, 1, "", "export"], [86, 2, 1, "", "generate"], [86, 2, 1, "", "print_summary"], [86, 2, 1, "", "sample"], [86, 2, 1, "", "sort_parameters"]], "modelopt.torch.nas.traced_hp": [[87, 1, 1, "", "TracedHp"], [87, 1, 1, "", "TracedHpRegistry"]], "modelopt.torch.nas.traced_hp.TracedHp": [[87, 2, 1, "", "initialize_from"], [87, 2, 1, "", "resolve_dependencies"]], "modelopt.torch.nas.traced_hp.TracedHpRegistry": [[87, 2, 1, "", "get"], [87, 2, 1, "", "initialize_from"], [87, 2, 1, "", "register"], [87, 2, 1, "", "unregister"]], "modelopt.torch.nas.utils": [[88, 1, 1, "", "enable_modelopt_patches"], [88, 4, 1, "", "get_subnet_config"], [88, 4, 1, "", "inference_flops"], [88, 4, 1, "", "is_modelopt_patches_enabled"], [88, 1, 1, "", "no_modelopt_patches"], [88, 4, 1, "", "print_search_space_summary"], [88, 4, 1, "", "replace_forward"], [88, 4, 1, "", "sample"], [88, 4, 1, "", "select"], [88, 1, 1, "", "set_modelopt_patches_enabled"]], "modelopt.torch.nas.utils.enable_modelopt_patches": [[88, 2, 1, "", "__init__"]], "modelopt.torch.nas.utils.no_modelopt_patches": [[88, 2, 1, "", "__init__"]], "modelopt.torch.nas.utils.set_modelopt_patches_enabled": [[88, 2, 1, "", "__init__"], [88, 2, 1, "", "clone"]], "modelopt.torch.opt": [[90, 0, 0, "-", "config"], [91, 0, 0, "-", "conversion"], [92, 0, 0, "-", "dynamic"], [93, 0, 0, "-", "hparam"], [94, 0, 0, "-", "mode"], [95, 0, 0, "-", "plugins"], [97, 0, 0, "-", "searcher"], [98, 0, 0, "-", "utils"]], "modelopt.torch.opt.config": [[90, 6, 1, "", "ModeloptBaseConfig"], [90, 6, 1, "", "ModeloptBaseRule"], [90, 6, 1, "", "ModeloptBaseRuleConfig"], [90, 4, 1, "", "ModeloptField"], [90, 4, 1, "", "get_kwargs_for_create_model_with_rules"]], "modelopt.torch.opt.config.ModeloptBaseConfig": [[90, 2, 1, "", "get"], [90, 2, 1, "", "get_field_name_from_key"], [90, 2, 1, "", "items"], [90, 2, 1, "", "keys"], [90, 2, 1, "", "model_dump"], [90, 2, 1, "", "model_dump_json"], [90, 2, 1, "", "update"], [90, 2, 1, "", "values"]], "modelopt.torch.opt.config.ModeloptBaseRule": [[90, 2, 1, "", "customize_rule"], [90, 2, 1, "", "get_rule_type"], [90, 2, 1, "", "validate_rule"]], "modelopt.torch.opt.config.ModeloptBaseRuleConfig": [[90, 2, 1, "", "register_default"], [90, 2, 1, "", "unregister_default"]], "modelopt.torch.opt.conversion": [[91, 1, 1, "", "ModeloptStateManager"], [91, 4, 1, "", "apply_mode"], [91, 4, 1, "", "modelopt_state"], [91, 4, 1, "", "restore"], [91, 4, 1, "", "restore_from_modelopt_state"], [91, 4, 1, "", "save"]], "modelopt.torch.opt.conversion.ModeloptStateManager": [[91, 2, 1, "", "__init__"], [91, 2, 1, "", "add_mode"], [91, 2, 1, "", "check_mode"], [91, 2, 1, "", "get_config_class"], [91, 3, 1, "", "has_state"], [91, 2, 1, "", "is_converted"], [91, 3, 1, "", "last_mode"], [91, 2, 1, "", "load_state_dict"], [91, 2, 1, "", "modes_with_states"], [91, 2, 1, "", "state_dict"], [91, 2, 1, "", "transfer_state_dict"], [91, 2, 1, "", "update_last_state_before_new_mode"], [91, 2, 1, "", "update_last_state_before_save"]], "modelopt.torch.opt.dynamic": [[92, 1, 1, "", "DynamicModule"], [92, 1, 1, "", "DynamicSpace"]], "modelopt.torch.opt.dynamic.DynamicModule": [[92, 2, 1, "", "__init__"], [92, 2, 1, "", "convert"], [92, 2, 1, "", "export"], [92, 2, 1, "", "extra_repr"], [92, 2, 1, "", "force_assign"], [92, 2, 1, "", "freeze"], [92, 2, 1, "", "get_hparam"], [92, 2, 1, "", "modify"], [92, 2, 1, "", "named_hparams"], [92, 3, 1, "", "original_cls"], [92, 2, 1, "", "reset_dynamic_attributes"]], "modelopt.torch.opt.dynamic.DynamicSpace": [[92, 2, 1, "", "__init__"], [92, 2, 1, "", "config"], [92, 2, 1, "", "convert_to_dynamic"], [92, 2, 1, "", "export"], [92, 2, 1, "", "get_hparam"], [92, 2, 1, "", "is_configurable"], [92, 2, 1, "", "is_dynamic"], [92, 2, 1, "", "named_dynamic_modules"], [92, 2, 1, "", "named_hparams"], [92, 2, 1, "", "select"], [92, 2, 1, "", "size"]], "modelopt.torch.opt.hparam": [[93, 1, 1, "", "Hparam"]], "modelopt.torch.opt.hparam.Hparam": [[93, 5, 1, "", "ActiveSlice"], [93, 5, 1, "", "Importance"], [93, 5, 1, "", "ImportanceEstimator"], [93, 2, 1, "", "__init__"], [93, 3, 1, "", "active"], [93, 3, 1, "", "active_slice"], [93, 3, 1, "", "choices"], [93, 2, 1, "", "enforce_order"], [93, 3, 1, "", "importance"], [93, 3, 1, "", "is_configurable"], [93, 3, 1, "", "is_sortable"], [93, 3, 1, "", "max"], [93, 3, 1, "", "min"], [93, 3, 1, "", "original"], [93, 2, 1, "", "register_importance"]], "modelopt.torch.opt.plugins": [[96, 0, 0, "-", "huggingface"]], "modelopt.torch.opt.plugins.huggingface": [[96, 4, 1, "", "enable_huggingface_checkpointing"]], "modelopt.torch.opt.searcher": [[97, 1, 1, "", "BaseSearcher"]], "modelopt.torch.opt.searcher.BaseSearcher": [[97, 2, 1, "", "__init__"], [97, 2, 1, "", "after_search"], [97, 2, 1, "", "before_search"], [97, 5, 1, "", "config"], [97, 5, 1, "", "constraints"], [97, 2, 1, "", "construct_forward_loop"], [97, 3, 1, "", "default_search_config"], [97, 3, 1, "", "default_state_dict"], [97, 5, 1, "", "deployment"], [97, 5, 1, "", "dummy_input"], [97, 2, 1, "", "eval_score"], [97, 5, 1, "", "forward_loop"], [97, 3, 1, "", "has_score"], [97, 2, 1, "", "load_search_checkpoint"], [97, 5, 1, "", "model"], [97, 2, 1, "", "reset_search"], [97, 2, 1, "", "run_search"], [97, 2, 1, "", "sanitize_search_config"], [97, 2, 1, "", "save_search_checkpoint"], [97, 2, 1, "", "search"], [97, 2, 1, "", "state_dict"]], "modelopt.torch.opt.utils": [[98, 4, 1, "", "get_hparam"], [98, 4, 1, "", "is_configurable"], [98, 4, 1, "", "is_dynamic"], [98, 4, 1, "", "named_dynamic_modules"], [98, 4, 1, "", "named_hparams"], [98, 4, 1, "", "search_space_size"]], "modelopt.torch.prune": [[100, 0, 0, "-", "config"], [101, 0, 0, "-", "fastnas"], [102, 0, 0, "-", "gradnas"], [103, 0, 0, "-", "mcore_gpt_minitron"], [104, 0, 0, "-", "mode"], [105, 0, 0, "-", "plugins"], [106, 0, 0, "-", "pruning"]], "modelopt.torch.prune.config": [[100, 6, 1, "", "FastNASConfig"], [100, 6, 1, "", "GradNASConfig"], [100, 6, 1, "", "MCoreGPTMinitronConfig"]], "modelopt.torch.prune.config.FastNASConfig": [[100, 7, 1, "", "nn_batchnorm1d"], [100, 7, 1, "", "nn_batchnorm2d"], [100, 7, 1, "", "nn_batchnorm3d"], [100, 7, 1, "", "nn_conv1d"], [100, 7, 1, "", "nn_conv2d"], [100, 7, 1, "", "nn_conv3d"], [100, 7, 1, "", "nn_convtranspose1d"], [100, 7, 1, "", "nn_convtranspose2d"], [100, 7, 1, "", "nn_convtranspose3d"], [100, 7, 1, "", "nn_groupnorm"], [100, 7, 1, "", "nn_instancenorm1d"], [100, 7, 1, "", "nn_instancenorm2d"], [100, 7, 1, "", "nn_instancenorm3d"], [100, 7, 1, "", "nn_layernorm"], [100, 7, 1, "", "nn_linear"], [100, 7, 1, "", "nn_syncbatchnorm"]], "modelopt.torch.prune.config.GradNASConfig": [[100, 7, 1, "", "nn_batchnorm1d"], [100, 7, 1, "", "nn_batchnorm2d"], [100, 7, 1, "", "nn_batchnorm3d"], [100, 7, 1, "", "nn_conv1d"], [100, 7, 1, "", "nn_conv2d"], [100, 7, 1, "", "nn_conv3d"], [100, 7, 1, "", "nn_convtranspose1d"], [100, 7, 1, "", "nn_convtranspose2d"], [100, 7, 1, "", "nn_convtranspose3d"], [100, 7, 1, "", "nn_groupnorm"], [100, 7, 1, "", "nn_instancenorm1d"], [100, 7, 1, "", "nn_instancenorm2d"], [100, 7, 1, "", "nn_instancenorm3d"], [100, 7, 1, "", "nn_layernorm"], [100, 7, 1, "", "nn_linear"], [100, 7, 1, "", "nn_syncbatchnorm"]], "modelopt.torch.prune.fastnas": [[101, 1, 1, "", "BinarySearcher"], [101, 1, 1, "", "FastNASPatchManager"], [101, 4, 1, "", "convert_fastnas_searchspace"], [101, 4, 1, "", "restore_fastnas_searchspace"]], "modelopt.torch.prune.fastnas.BinarySearcher": [[101, 2, 1, "", "after_step"], [101, 2, 1, "", "before_search"], [101, 2, 1, "", "before_step"], [101, 3, 1, "", "default_state_dict"], [101, 2, 1, "", "early_stop"], [101, 3, 1, "", "hparam_names_for_search"], [101, 3, 1, "", "hparam_types_for_search"], [101, 2, 1, "", "load_search_checkpoint"], [101, 5, 1, "", "max_degrade"], [101, 5, 1, "", "middle_value"], [101, 5, 1, "", "min_degrade"], [101, 5, 1, "", "original_score"], [101, 2, 1, "", "sample"], [101, 5, 1, "", "sensitivity_map"]], "modelopt.torch.prune.fastnas.FastNASPatchManager": [[101, 3, 1, "", "sample_during_training"]], "modelopt.torch.prune.gradnas": [[102, 1, 1, "", "GradientBinarySearcher"], [102, 1, 1, "", "GradientDataManager"]], "modelopt.torch.prune.gradnas.GradientBinarySearcher": [[102, 5, 1, "", "SETUP_GRADIENT_FUNC"], [102, 2, 1, "", "before_search"], [102, 3, 1, "", "default_search_config"], [102, 2, 1, "", "gradnas_score_func"], [102, 3, 1, "", "hparam_names_for_search"], [102, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.prune.gradnas.GradientDataManager": [[102, 2, 1, "", "__init__"], [102, 2, 1, "", "process_gradient"], [102, 3, 1, "", "score"]], "modelopt.torch.prune.mcore_gpt_minitron": [[103, 1, 1, "", "MCoreGPTMinitronSearcher"]], "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher": [[103, 5, 1, "", "SUPPORTED_HPARAMS"], [103, 2, 1, "", "before_search"], [103, 3, 1, "", "default_search_config"], [103, 3, 1, "", "default_state_dict"], [103, 2, 1, "", "run_search"], [103, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.prune.mode": [[104, 1, 1, "", "FastNASModeDescriptor"], [104, 1, 1, "", "GradNASModeDescriptor"], [104, 1, 1, "", "MCoreGPTMinitronModeDescriptor"]], "modelopt.torch.prune.mode.FastNASModeDescriptor": [[104, 3, 1, "", "config_class"], [104, 3, 1, "", "convert"], [104, 3, 1, "", "export_mode"], [104, 3, 1, "", "name"], [104, 3, 1, "", "next_modes"], [104, 3, 1, "", "restore"], [104, 3, 1, "", "search_algorithm"], [104, 3, 1, "", "update_for_new_mode"], [104, 3, 1, "", "update_for_save"]], "modelopt.torch.prune.mode.GradNASModeDescriptor": [[104, 3, 1, "", "config_class"], [104, 3, 1, "", "name"], [104, 3, 1, "", "search_algorithm"]], "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor": [[104, 3, 1, "", "config_class"], [104, 3, 1, "", "name"], [104, 3, 1, "", "search_algorithm"]], "modelopt.torch.prune.pruning": [[106, 4, 1, "", "prune"]], "modelopt.torch.quantization": [[108, 0, 0, "-", "algorithms"], [109, 0, 0, "-", "calib"], [113, 0, 0, "-", "config"], [114, 0, 0, "-", "conversion"], [115, 0, 0, "-", "extensions"], [116, 0, 0, "-", "mode"], [117, 0, 0, "-", "model_calib"], [118, 0, 0, "-", "model_quant"], [119, 0, 0, "-", "nn"], [132, 0, 0, "-", "optim"], [133, 0, 0, "-", "plugins"], [134, 0, 0, "-", "qtensor"], [138, 0, 0, "-", "quant_modules"], [139, 0, 0, "-", "tensor_quant"], [140, 0, 0, "-", "utils"]], "modelopt.torch.quantization.algorithms": [[108, 1, 1, "", "AutoQuantizeSearcher"], [108, 1, 1, "", "QuantRecipe"], [108, 1, 1, "", "QuantRecipeHparam"]], "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher": [[108, 2, 1, "", "before_search"], [108, 5, 1, "", "candidate_stats"], [108, 3, 1, "", "default_search_config"], [108, 3, 1, "", "default_state_dict"], [108, 5, 1, "", "gradient_checkpointing_enable_contexts"], [108, 2, 1, "", "insert_hparams_after_merge_rules"], [108, 2, 1, "", "register_gradient_checkpointing_enable_context"], [108, 5, 1, "", "rules"], [108, 2, 1, "", "run_search"], [108, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.quantization.algorithms.QuantRecipe": [[108, 2, 1, "", "__init__"], [108, 3, 1, "", "compression"], [108, 3, 1, "", "config"], [108, 2, 1, "", "disable_folding_pqs_to_weights"], [108, 2, 1, "", "fold_pqs_to_weights"]], "modelopt.torch.quantization.algorithms.QuantRecipeHparam": [[108, 2, 1, "", "__init__"], [108, 3, 1, "", "active"], [108, 3, 1, "", "importance"]], "modelopt.torch.quantization.calib": [[110, 0, 0, "-", "calibrator"], [111, 0, 0, "-", "histogram"], [112, 0, 0, "-", "max"]], "modelopt.torch.quantization.calib.histogram": [[111, 1, 1, "", "HistogramCalibrator"], [111, 4, 1, "", "calibrate_weights"]], "modelopt.torch.quantization.calib.histogram.HistogramCalibrator": [[111, 2, 1, "", "__init__"], [111, 2, 1, "", "collect"], [111, 2, 1, "", "compute_amax"], [111, 2, 1, "", "reset"]], "modelopt.torch.quantization.calib.max": [[112, 1, 1, "", "MaxCalibrator"]], "modelopt.torch.quantization.calib.max.MaxCalibrator": [[112, 2, 1, "", "__init__"], [112, 3, 1, "", "amaxs"], [112, 2, 1, "", "collect"], [112, 2, 1, "", "compute_amax"], [112, 2, 1, "", "reset"]], "modelopt.torch.quantization.config": [[113, 6, 1, "", "AWQClipCalibConfig"], [113, 6, 1, "", "AWQFullCalibConfig"], [113, 6, 1, "", "AWQLiteCalibConfig"], [113, 6, 1, "", "MaxCalibConfig"], [113, 6, 1, "", "QuantizeAlgorithmConfig"], [113, 6, 1, "", "QuantizeConfig"], [113, 6, 1, "", "QuantizerAttributeConfig"], [113, 6, 1, "", "RealQuantizeConfig"], [113, 6, 1, "", "SmoothQuantCalibConfig"]], "modelopt.torch.quantization.config.AWQClipCalibConfig": [[113, 7, 1, "", "debug"], [113, 7, 1, "", "max_co_batch_size"], [113, 7, 1, "", "max_tokens_per_batch"], [113, 7, 1, "", "min_clip_ratio"], [113, 7, 1, "", "shrink_step"]], "modelopt.torch.quantization.config.AWQFullCalibConfig": [[113, 7, 1, "", "debug"]], "modelopt.torch.quantization.config.AWQLiteCalibConfig": [[113, 7, 1, "", "alpha_step"], [113, 7, 1, "", "debug"]], "modelopt.torch.quantization.config.QuantizeAlgorithmConfig": [[113, 7, 1, "", "method"]], "modelopt.torch.quantization.config.QuantizeConfig": [[113, 7, 1, "", "algorithm"], [113, 7, 1, "", "quant_cfg"]], "modelopt.torch.quantization.config.QuantizerAttributeConfig": [[113, 7, 1, "", "axis"], [113, 7, 1, "", "block_sizes"], [113, 7, 1, "", "calibrator"], [113, 7, 1, "", "enable"], [113, 7, 1, "", "fake_quant"], [113, 7, 1, "", "learn_amax"], [113, 7, 1, "", "narrow_range"], [113, 7, 1, "", "num_bits"], [113, 7, 1, "", "trt_high_precision_dtype"], [113, 7, 1, "", "type"], [113, 7, 1, "", "unsigned"]], "modelopt.torch.quantization.config.RealQuantizeConfig": [[113, 7, 1, "", "additional_algorithm"]], "modelopt.torch.quantization.config.SmoothQuantCalibConfig": [[113, 7, 1, "", "alpha"]], "modelopt.torch.quantization.conversion": [[114, 4, 1, "", "register"], [114, 4, 1, "", "replace_quant_module"], [114, 4, 1, "", "set_quantizer_attribute"], [114, 4, 1, "", "set_quantizer_by_cfg"], [114, 4, 1, "", "set_quantizer_by_cfg_context"], [114, 4, 1, "", "unregister"]], "modelopt.torch.quantization.extensions": [[115, 4, 1, "", "get_cuda_ext"], [115, 4, 1, "", "get_cuda_ext_fp8"]], "modelopt.torch.quantization.mode": [[116, 1, 1, "", "QuantizeExportModeDescriptor"], [116, 1, 1, "", "QuantizeModeDescriptor"]], "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor": [[116, 3, 1, "", "config_class"], [116, 3, 1, "", "convert"], [116, 3, 1, "", "is_export_mode"], [116, 3, 1, "", "name"], [116, 3, 1, "", "restore"]], "modelopt.torch.quantization.mode.QuantizeModeDescriptor": [[116, 3, 1, "", "config_class"], [116, 3, 1, "", "convert"], [116, 3, 1, "", "export_mode"], [116, 3, 1, "", "name"], [116, 3, 1, "", "next_modes"], [116, 3, 1, "", "restore"], [116, 3, 1, "", "update_for_new_mode"], [116, 3, 1, "", "update_for_save"]], "modelopt.torch.quantization.model_calib": [[117, 4, 1, "", "calibrate"], [117, 4, 1, "", "postprocess_amax"]], "modelopt.torch.quantization.model_quant": [[118, 4, 1, "", "auto_quantize"], [118, 4, 1, "", "disable_quantizer"], [118, 4, 1, "", "enable_quantizer"], [118, 4, 1, "", "fold_weight"], [118, 4, 1, "", "print_quant_summary"], [118, 4, 1, "", "quantize"]], "modelopt.torch.quantization.nn": [[120, 0, 0, "-", "functional"], [121, 0, 0, "-", "modules"]], "modelopt.torch.quantization.nn.functional": [[120, 1, 1, "", "ClipFunction"]], "modelopt.torch.quantization.nn.functional.ClipFunction": [[120, 2, 1, "", "backward"], [120, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules": [[122, 0, 0, "-", "clip"], [123, 0, 0, "-", "quant_activations"], [124, 0, 0, "-", "quant_batchnorm"], [125, 0, 0, "-", "quant_conv"], [126, 0, 0, "-", "quant_instancenorm"], [127, 0, 0, "-", "quant_linear"], [128, 0, 0, "-", "quant_module"], [129, 0, 0, "-", "quant_pooling"], [130, 0, 0, "-", "quant_rnn"], [131, 0, 0, "-", "tensor_quantizer"]], "modelopt.torch.quantization.nn.modules.clip": [[122, 1, 1, "", "Clip"]], "modelopt.torch.quantization.nn.modules.clip.Clip": [[122, 2, 1, "", "__init__"], [122, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[125, 5, 1, "", "Conv1d"], [125, 5, 1, "", "Conv2d"], [125, 5, 1, "", "Conv3d"], [125, 5, 1, "", "ConvTranspose1d"], [125, 5, 1, "", "ConvTranspose2d"], [125, 5, 1, "", "ConvTranspose3d"], [125, 1, 1, "", "QuantConv1d"], [125, 1, 1, "", "QuantConv2d"], [125, 1, 1, "", "QuantConv3d"], [125, 1, 1, "", "QuantConvTranspose1d"], [125, 1, 1, "", "QuantConvTranspose2d"], [125, 1, 1, "", "QuantConvTranspose3d"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d": [[125, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d": [[125, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d": [[125, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d": [[125, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d": [[125, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d": [[125, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[126, 1, 1, "", "QuantInstanceNorm1d"], [126, 1, 1, "", "QuantInstanceNorm2d"], [126, 1, 1, "", "QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[127, 5, 1, "", "Linear"], [127, 1, 1, "", "QuantLinear"]], "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear": [[127, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_module": [[128, 1, 1, "", "QuantInputBase"], [128, 1, 1, "", "QuantLinearConvBase"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase": [[128, 5, 1, "", "default_quant_desc_input"], [128, 5, 1, "", "default_quant_desc_output"], [128, 2, 1, "", "forward"], [128, 5, 1, "", "input_quantizer"], [128, 5, 1, "", "output_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase": [[128, 5, 1, "", "default_quant_desc_weight"], [128, 2, 1, "", "forward"], [128, 2, 1, "", "initialize_quantizer_with_dummy_states"], [128, 2, 1, "", "quantize_weight"], [128, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[129, 5, 1, "", "AdaptiveAvgPool1d"], [129, 5, 1, "", "AdaptiveAvgPool2d"], [129, 5, 1, "", "AdaptiveAvgPool3d"], [129, 5, 1, "", "AvgPool1d"], [129, 5, 1, "", "AvgPool2d"], [129, 5, 1, "", "AvgPool3d"], [129, 5, 1, "", "MaxPool1d"], [129, 5, 1, "", "MaxPool2d"], [129, 5, 1, "", "MaxPool3d"], [129, 1, 1, "", "QuantAdaptiveAvgPool1d"], [129, 1, 1, "", "QuantAdaptiveAvgPool2d"], [129, 1, 1, "", "QuantAdaptiveAvgPool3d"], [129, 1, 1, "", "QuantAvgPool1d"], [129, 1, 1, "", "QuantAvgPool2d"], [129, 1, 1, "", "QuantAvgPool3d"], [129, 1, 1, "", "QuantMaxPool1d"], [129, 1, 1, "", "QuantMaxPool2d"], [129, 1, 1, "", "QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_rnn": [[130, 1, 1, "", "QuantRNNBase"], [130, 1, 1, "", "QuantRNNFullBase"], [130, 1, 1, "", "RNNLayerForward"], [130, 1, 1, "", "VFRNNForward"], [130, 4, 1, "", "get_quantized_rnn_layer_forward"], [130, 4, 1, "", "get_quantized_rnn_layer_variable_len_forward"], [130, 4, 1, "", "get_quantized_rnn_layer_variable_len_reverse_forward"], [130, 4, 1, "", "lstm_cell_with_proj"], [130, 4, 1, "", "quantized_cell_forward"]], "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase": [[130, 3, 1, "", "all_input_quantizers_disabled"], [130, 5, 1, "", "default_quant_desc_input"], [130, 5, 1, "", "default_quant_desc_weight"], [130, 2, 1, "", "forward"], [130, 3, 1, "", "functionals_to_replace"], [130, 2, 1, "", "quantize_weight"], [130, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward": [[130, 2, 1, "", "__init__"]], "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward": [[130, 2, 1, "", "__init__"], [130, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[131, 1, 1, "", "SequentialQuantizer"], [131, 1, 1, "", "TensorQuantizer"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer": [[131, 2, 1, "", "__init__"], [131, 2, 1, "", "disable"], [131, 2, 1, "", "get_modelopt_state"], [131, 2, 1, "", "replace_sequential_quantizer_with_single_quantizer"], [131, 2, 1, "", "set_from_attribute_config"], [131, 2, 1, "", "tensor_quantizer_iterator"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer": [[131, 2, 1, "", "__init__"], [131, 3, 1, "", "amax"], [131, 3, 1, "", "axis"], [131, 3, 1, "", "block_sizes"], [131, 2, 1, "", "clean_up_after_set_from_modelopt_state"], [131, 2, 1, "", "dequantize"], [131, 2, 1, "", "disable"], [131, 2, 1, "", "disable_calib"], [131, 2, 1, "", "disable_clip"], [131, 2, 1, "", "disable_quant"], [131, 2, 1, "", "enable"], [131, 2, 1, "", "enable_calib"], [131, 2, 1, "", "enable_clip"], [131, 2, 1, "", "enable_quant"], [131, 2, 1, "", "export_amax"], [131, 2, 1, "", "extra_repr"], [131, 3, 1, "", "fake_quant"], [131, 2, 1, "", "forward"], [131, 2, 1, "", "get_modelopt_state"], [131, 2, 1, "", "init_learn_amax"], [131, 3, 1, "", "is_enabled"], [131, 2, 1, "", "load_calib_amax"], [131, 3, 1, "", "maxbound"], [131, 3, 1, "", "narrow_range"], [131, 3, 1, "", "num_bits"], [131, 3, 1, "", "pre_quant_scale"], [131, 2, 1, "", "reset_amax"], [131, 3, 1, "", "scale"], [131, 2, 1, "", "set_from_attribute_config"], [131, 2, 1, "", "set_from_modelopt_state"], [131, 3, 1, "", "step_size"], [131, 2, 1, "", "sync_amax_across_distributed_group"], [131, 3, 1, "", "trt_high_precision_dtype"], [131, 3, 1, "", "unsigned"]], "modelopt.torch.quantization.optim": [[132, 4, 1, "", "freeze_parameters"], [132, 4, 1, "", "group_parameters"], [132, 4, 1, "", "match_parameters"], [132, 4, 1, "", "quant_weight_inplace"]], "modelopt.torch.quantization.qtensor": [[135, 0, 0, "-", "base_qtensor"], [136, 0, 0, "-", "int4_tensor"], [137, 0, 0, "-", "nf4_tensor"]], "modelopt.torch.quantization.qtensor.base_qtensor": [[135, 1, 1, "", "BaseQuantizedTensor"], [135, 1, 1, "", "QTensorWrapper"]], "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor": [[135, 2, 1, "", "__init__"], [135, 2, 1, "", "dequantize"], [135, 5, 1, "", "original_meta_tensor"], [135, 2, 1, "", "quantize"], [135, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper": [[135, 2, 1, "", "__new__"]], "modelopt.torch.quantization.qtensor.int4_tensor": [[136, 1, 1, "", "INT4QTensor"]], "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor": [[136, 2, 1, "", "dequantize"], [136, 2, 1, "", "quantize"], [136, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.nf4_tensor": [[137, 1, 1, "", "NF4QTensor"]], "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor": [[137, 2, 1, "", "dequantize"], [137, 2, 1, "", "double_quantization"], [137, 2, 1, "", "quantize"], [137, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.quant_modules": [[138, 4, 1, "", "deactivate"], [138, 4, 1, "", "enable_onnx_export"], [138, 4, 1, "", "initialize"]], "modelopt.torch.quantization.tensor_quant": [[139, 1, 1, "", "FakeAffineTensorQuantFunction"], [139, 1, 1, "", "FakeTensorQuantFunction"], [139, 1, 1, "", "LegacyFakeTensorQuantFunction"], [139, 1, 1, "", "ScaledE4M3Function"], [139, 1, 1, "", "TensorQuantFunction"], [139, 4, 1, "", "fake_quant_impl"], [139, 4, 1, "", "quantize_op_abstract"], [139, 4, 1, "", "scaled_e4m3_impl"]], "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction": [[139, 2, 1, "", "backward"], [139, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction": [[139, 2, 1, "", "backward"], [139, 2, 1, "", "forward"], [139, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction": [[139, 2, 1, "", "backward"], [139, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function": [[139, 2, 1, "", "backward"], [139, 2, 1, "", "forward"], [139, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.TensorQuantFunction": [[139, 2, 1, "", "backward"], [139, 2, 1, "", "forward"], [139, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.utils": [[140, 4, 1, "", "export_torch_mode"], [140, 4, 1, "", "get_parallel_state"], [140, 4, 1, "", "is_quantized"], [140, 4, 1, "", "is_quantized_column_parallel_linear"], [140, 4, 1, "", "is_quantized_layer_with_weight"], [140, 4, 1, "", "is_quantized_row_parallel_linear"], [140, 4, 1, "", "is_torch_library_supported"], [140, 4, 1, "", "reduce_amax"], [140, 4, 1, "", "replace_function"]], "modelopt.torch.sparsity": [[142, 0, 0, "-", "config"], [143, 0, 0, "-", "magnitude"], [144, 0, 0, "-", "mode"], [145, 0, 0, "-", "module"], [146, 0, 0, "-", "plugins"], [147, 0, 0, "-", "searcher"], [148, 0, 0, "-", "sparsegpt"], [149, 0, 0, "-", "sparsification"]], "modelopt.torch.sparsity.config": [[142, 6, 1, "", "ExportSparseConfig"], [142, 6, 1, "", "SparseGPTConfig"], [142, 6, 1, "", "SparseMagnitudeConfig"]], "modelopt.torch.sparsity.config.SparseGPTConfig": [[142, 7, 1, "", "nn_conv2d"], [142, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.config.SparseMagnitudeConfig": [[142, 7, 1, "", "nn_conv2d"], [142, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.magnitude": [[143, 1, 1, "", "MagnitudeSearcher"], [143, 4, 1, "", "compute_valid_1d_patterns"], [143, 4, 1, "", "create_asp_mask"], [143, 4, 1, "", "fill"], [143, 4, 1, "", "get_nmprune_info"], [143, 4, 1, "", "m4n2_1d"], [143, 4, 1, "", "mn_1d_best"], [143, 4, 1, "", "reshape_1d"]], "modelopt.torch.sparsity.mode": [[144, 1, 1, "", "ExportSparseModeDescriptor"], [144, 1, 1, "", "SparseGPTModeDescriptor"], [144, 1, 1, "", "SparseMagnitudeModeDescriptor"], [144, 4, 1, "", "convert_sparse_model"], [144, 4, 1, "", "export_sparse"], [144, 4, 1, "", "restore_export_sparse"], [144, 4, 1, "", "restore_sparse_model"], [144, 4, 1, "", "update_sparse_metadata"]], "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor": [[144, 3, 1, "", "config_class"], [144, 3, 1, "", "convert"], [144, 3, 1, "", "is_export_mode"], [144, 3, 1, "", "name"], [144, 3, 1, "", "restore"]], "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor": [[144, 3, 1, "", "config_class"], [144, 3, 1, "", "name"], [144, 3, 1, "", "search_algorithm"]], "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor": [[144, 3, 1, "", "config_class"], [144, 3, 1, "", "convert"], [144, 3, 1, "", "export_mode"], [144, 3, 1, "", "name"], [144, 3, 1, "", "next_modes"], [144, 3, 1, "", "restore"], [144, 3, 1, "", "search_algorithm"], [144, 3, 1, "", "update_for_new_mode"], [144, 3, 1, "", "update_for_save"]], "modelopt.torch.sparsity.module": [[145, 1, 1, "", "SparseModule"]], "modelopt.torch.sparsity.module.SparseModule": [[145, 2, 1, "", "modify"], [145, 2, 1, "", "set_mask"]], "modelopt.torch.sparsity.searcher": [[147, 1, 1, "", "BaseSparseSearcher"]], "modelopt.torch.sparsity.searcher.BaseSparseSearcher": [[147, 3, 1, "", "default_search_config"], [147, 3, 1, "", "default_state_dict"], [147, 2, 1, "", "run_search"], [147, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.sparsity.sparsegpt": [[148, 1, 1, "", "SparseGPTSearcher"], [148, 4, 1, "", "create_sgpt_mask"], [148, 4, 1, "", "invert"], [148, 4, 1, "", "prepare"]], "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher": [[148, 2, 1, "", "after_search"], [148, 2, 1, "", "before_search"], [148, 3, 1, "", "default_search_config"]], "modelopt.torch.sparsity.sparsification": [[149, 4, 1, "", "export"], [149, 4, 1, "", "sparsify"]], "modelopt.torch.speculative": [[151, 0, 0, "-", "config"], [152, 0, 0, "-", "medusa"], [155, 0, 0, "-", "mode"], [156, 0, 0, "-", "plugins"], [157, 0, 0, "-", "speculative_decoding"]], "modelopt.torch.speculative.config": [[151, 6, 1, "", "MedusaConfig"]], "modelopt.torch.speculative.config.MedusaConfig": [[151, 7, 1, "", "medusa_num_heads"], [151, 7, 1, "", "medusa_num_layers"]], "modelopt.torch.speculative.medusa": [[153, 0, 0, "-", "conversion"], [154, 0, 0, "-", "medusa_model"]], "modelopt.torch.speculative.medusa.conversion": [[153, 4, 1, "", "convert_to_medusa_model"], [153, 4, 1, "", "restore_medusa_model"]], "modelopt.torch.speculative.medusa.medusa_model": [[154, 1, 1, "", "MedusaModel"], [154, 1, 1, "", "ResBlock"]], "modelopt.torch.speculative.medusa.medusa_model.MedusaModel": [[154, 2, 1, "", "modify"]], "modelopt.torch.speculative.medusa.medusa_model.ResBlock": [[154, 2, 1, "", "__init__"], [154, 2, 1, "", "forward"]], "modelopt.torch.speculative.mode": [[155, 1, 1, "", "MedusaModeDescriptor"]], "modelopt.torch.speculative.mode.MedusaModeDescriptor": [[155, 3, 1, "", "config_class"], [155, 3, 1, "", "convert"], [155, 3, 1, "", "name"], [155, 3, 1, "", "restore"]], "modelopt.torch.speculative.speculative_decoding": [[157, 4, 1, "", "convert"]], "modelopt.torch.trace": [[159, 0, 0, "-", "analyzer"], [160, 0, 0, "-", "modules"], [163, 0, 0, "-", "plugins"], [164, 0, 0, "-", "symbols"], [165, 0, 0, "-", "tracer"]], "modelopt.torch.trace.analyzer": [[159, 4, 1, "", "analyze_symbols"]], "modelopt.torch.trace.modules": [[161, 0, 0, "-", "concat"], [162, 0, 0, "-", "nn"]], "modelopt.torch.trace.modules.concat": [[161, 1, 1, "", "ConcatNodeProcessor"], [161, 1, 1, "", "ConcatSymbol"]], "modelopt.torch.trace.modules.concat.ConcatNodeProcessor": [[161, 2, 1, "", "__init__"], [161, 2, 1, "", "is_special_node"], [161, 2, 1, "", "post_process"], [161, 2, 1, "", "process"], [161, 2, 1, "", "reset"]], "modelopt.torch.trace.modules.concat.ConcatSymbol": [[161, 1, 1, "", "Input"], [161, 2, 1, "", "__init__"], [161, 2, 1, "", "disable"], [161, 3, 1, "", "input_syms"], [161, 3, 1, "", "is_constant"], [161, 3, 1, "", "is_searchable"], [161, 2, 1, "", "link_to"]], "modelopt.torch.trace.modules.concat.ConcatSymbol.Input": [[161, 2, 1, "", "__init__"], [161, 3, 1, "", "concat_sym"], [161, 2, 1, "", "convert"], [161, 2, 1, "", "create_linked_copy"], [161, 2, 1, "", "link_to"]], "modelopt.torch.trace.modules.nn": [[162, 1, 1, "", "SymDepth"]], "modelopt.torch.trace.modules.nn.SymDepth": [[162, 2, 1, "", "__init__"], [162, 2, 1, "", "disable"], [162, 2, 1, "", "is_skippable"], [162, 2, 1, "", "link_to"], [162, 3, 1, "", "max_depth"], [162, 3, 1, "", "min_depth"], [162, 2, 1, "", "set_skippable"], [162, 3, 1, "", "skippable_idxs"]], "modelopt.torch.trace.symbols": [[164, 1, 1, "", "SymInfo"], [164, 1, 1, "", "SymMap"], [164, 1, 1, "", "Symbol"]], "modelopt.torch.trace.symbols.SymInfo": [[164, 5, 1, "", "SymDict"], [164, 2, 1, "", "__init__"], [164, 3, 1, "", "is_shape_preserving"]], "modelopt.torch.trace.symbols.SymMap": [[164, 5, 1, "", "SymRegisterFunc"], [164, 2, 1, "", "__init__"], [164, 2, 1, "", "add_sym_info"], [164, 2, 1, "", "get_symbol"], [164, 2, 1, "", "is_shape_preserving"], [164, 2, 1, "", "items"], [164, 2, 1, "", "named_modules"], [164, 2, 1, "", "named_sym_dicts"], [164, 2, 1, "", "named_symbols"], [164, 2, 1, "", "pop"], [164, 2, 1, "", "prune"], [164, 2, 1, "", "register"], [164, 2, 1, "", "set_symbol"], [164, 2, 1, "", "unregister"]], "modelopt.torch.trace.symbols.Symbol": [[164, 1, 1, "", "CLType"], [164, 2, 1, "", "__init__"], [164, 3, 1, "", "cl_type"], [164, 2, 1, "", "disable"], [164, 3, 1, "", "elastic_dims"], [164, 3, 1, "", "is_constant"], [164, 3, 1, "", "is_cross_layer"], [164, 3, 1, "", "is_dangling"], [164, 3, 1, "", "is_dynamic"], [164, 3, 1, "", "is_free"], [164, 3, 1, "", "is_incoming"], [164, 3, 1, "", "is_outgoing"], [164, 3, 1, "", "is_searchable"], [164, 3, 1, "", "is_sortable"], [164, 2, 1, "", "link_to"], [164, 3, 1, "", "parent"]], "modelopt.torch.trace.symbols.Symbol.CLType": [[164, 5, 1, "", "INCOMING"], [164, 5, 1, "", "NONE"], [164, 5, 1, "", "OUTGOING"]], "modelopt.torch.trace.tracer": [[165, 1, 1, "", "GraphCollection"], [165, 1, 1, "", "RobustTracer"], [165, 4, 1, "", "recursive_trace"]], "modelopt.torch.trace.tracer.GraphCollection": [[165, 2, 1, "", "__init__"], [165, 2, 1, "", "failure_msg"], [165, 2, 1, "", "is_failed"], [165, 2, 1, "", "is_unvisited"], [165, 2, 1, "", "recursive_trace"]], "modelopt.torch.trace.tracer.RobustTracer": [[165, 2, 1, "", "__init__"], [165, 2, 1, "", "failure_msg"], [165, 2, 1, "", "is_failed"], [165, 2, 1, "", "is_leaf_module"], [165, 2, 1, "", "is_registered_leaf"], [165, 2, 1, "", "is_unvisited"], [165, 2, 1, "", "record_call_module"], [165, 2, 1, "", "register_leaf"], [165, 2, 1, "", "trace"], [165, 2, 1, "", "unregister_leaf"]], "modelopt.torch.utils": [[167, 0, 0, "-", "cpp_extension"], [168, 0, 0, "-", "dataset_utils"], [169, 0, 0, "-", "distributed"], [170, 0, 0, "-", "graph"], [171, 0, 0, "-", "list"], [172, 0, 0, "-", "logging"], [173, 0, 0, "-", "network"], [174, 0, 0, "-", "perf"], [175, 0, 0, "-", "random"], [176, 0, 0, "-", "tensor"]], "modelopt.torch.utils.cpp_extension": [[167, 4, 1, "", "load_cpp_extension"]], "modelopt.torch.utils.dataset_utils": [[168, 4, 1, "", "create_forward_loop"], [168, 4, 1, "", "get_dataset_dataloader"]], "modelopt.torch.utils.distributed": [[169, 4, 1, "", "backend"], [169, 4, 1, "", "barrier"], [169, 4, 1, "", "get_data_parallel_group"], [169, 4, 1, "", "get_tensor_parallel_group"], [169, 4, 1, "", "is_available"], [169, 4, 1, "", "is_initialized"], [169, 4, 1, "", "is_master"], [169, 4, 1, "", "rank"], [169, 4, 1, "", "set_data_parallel_group"], [169, 4, 1, "", "set_tensor_parallel_group"], [169, 4, 1, "", "size"]], "modelopt.torch.utils.graph": [[170, 4, 1, "", "match"]], "modelopt.torch.utils.list": [[171, 4, 1, "", "list_closest_to_median"], [171, 4, 1, "", "stats"], [171, 4, 1, "", "val2list"], [171, 4, 1, "", "val2tuple"]], "modelopt.torch.utils.logging": [[172, 8, 1, "", "DeprecatedError"], [172, 4, 1, "", "no_stdout"], [172, 4, 1, "", "num2hrb"], [172, 4, 1, "", "print_rank_0"]], "modelopt.torch.utils.network": [[173, 4, 1, "", "compare_dict"], [173, 4, 1, "", "create_param_grad_clear_hook"], [173, 4, 1, "", "get_model_attributes"], [173, 4, 1, "", "get_module_device"], [173, 4, 1, "", "get_same_padding"], [173, 4, 1, "", "get_unwrapped_name"], [173, 4, 1, "", "init_model_from_model_like"], [173, 4, 1, "", "is_channels_last"], [173, 4, 1, "", "is_parallel"], [173, 4, 1, "", "make_divisible"], [173, 4, 1, "", "model_to"], [173, 4, 1, "", "param_num"], [173, 4, 1, "", "param_num_from_forward"], [173, 4, 1, "", "remove_bn"], [173, 4, 1, "", "run_forward_loop"], [173, 4, 1, "", "set_submodule"], [173, 4, 1, "", "standardize_constructor_args"], [173, 4, 1, "", "standardize_model_args"], [173, 4, 1, "", "standardize_model_like_tuple"], [173, 4, 1, "", "standardize_named_model_args"], [173, 4, 1, "", "unwrap_model"], [173, 4, 1, "", "zero_grad"]], "modelopt.torch.utils.perf": [[174, 1, 1, "", "Timer"], [174, 4, 1, "", "clear_cuda_cache"], [174, 4, 1, "", "get_cuda_memory_stats"], [174, 4, 1, "", "report_memory"]], "modelopt.torch.utils.perf.Timer": [[174, 2, 1, "", "__init__"], [174, 2, 1, "", "start"], [174, 2, 1, "", "stop"]], "modelopt.torch.utils.random": [[175, 4, 1, "", "centroid"], [175, 4, 1, "", "choice"], [175, 4, 1, "", "original"], [175, 4, 1, "", "random"], [175, 4, 1, "", "sample"], [175, 4, 1, "", "shuffle"]], "modelopt.torch.utils.tensor": [[176, 4, 1, "", "numpy_to_torch"], [176, 4, 1, "", "torch_detach"], [176, 4, 1, "", "torch_to"], [176, 4, 1, "", "torch_to_numpy"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:function", "5": "py:attribute", "6": "py:pydantic_model", "7": "py:pydantic_field", "8": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "function", "Python function"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "pydantic_model", "Python model"], "7": ["py", "pydantic_field", "Python field"], "8": ["py", "exception", "Python exception"]}, "titleterms": {"tensorrt": [0, 4], "llm": [0, 25], "deploy": [0, 6, 21], "export": [0, 8, 55], "quantiz": [0, 3, 4, 6, 10, 17, 18, 19, 20, 30, 44, 107, 113], "model": [0, 2, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 19, 20, 21, 22], "support": [0, 12, 21], "matrix": 0, "checkpoint": [0, 15], "convert": [0, 12, 13, 16], "all": 1, "github": 1, "exampl": [1, 21, 113], "resnet20": 2, "cifar": 2, "10": [2, 22], "prune": [2, 3, 4, 7, 11, 12, 99, 106, 178], "dataset": [2, 19], "imag": 2, "classif": 2, "resnet": 2, "set": [2, 7, 8], "up": [2, 7, 8], "train": [2, 8, 9, 11, 12, 14, 17, 19, 20], "baselin": 2, "fastna": [2, 101], "optim": [2, 4, 5, 20, 21, 22, 132], "base": [2, 8, 12], "store": [2, 11, 20], "net": 2, "restor": [2, 12, 14, 15, 20], "subnet": [2, 11, 12], "us": [2, 15, 20], "mto": 2, "fine": [2, 11, 12, 16], "tune": [2, 11, 12, 16], "evalu": [2, 20], "search": [2, 7, 11, 12, 178], "hf": 3, "bert": 3, "distil": [3, 4, 8, 13, 47, 49], "prerequisit": [3, 11, 12], "full": 3, "code": 3, "command": 3, "overview": [4, 12, 13], "nvidia": 4, "techniqu": 4, "sparsiti": [4, 9, 14, 141], "instal": 5, "system": 5, "requir": [5, 19], "check": 5, "quick": [6, 7, 8, 9], "start": [6, 7, 8, 9, 21], "ptq": [6, 19, 20], "pytorch": [6, 9, 20], "your": [7, 8, 12], "meta": 8, "dure": 8, "post": [9, 14, 19, 20], "sparsif": [9, 14, 149], "pt": 9, "awar": [9, 17, 20], "sat": 9, "perform": [11, 12, 19], "result": 11, "custom": [11, 20], "config": [11, 20, 48, 72, 90, 100, 113, 142, 151], "profil": [11, 12], "space": [11, 12], "choos": [11, 18], "constraint": 11, "load": 11, "run": 11, "deploi": [11, 19, 24], "concept": [11, 12, 13, 14, 16, 17], "na": [12, 69, 178], "introduct": [12, 13, 14, 16], "save": [12, 14, 15, 16], "architectur": 12, "The": 12, "convers": [12, 73, 91, 114, 153], "process": 12, "layer": 12, "gener": [12, 26], "traceabl": 12, "distributeddataparallel": 12, "auxiliari": 12, "modul": [12, 20, 78, 121, 145, 160], "known": [12, 178], "limit": 12, "glossari": [12, 13], "neural": 12, "hyperparamet": 12, "modelopt": [12, 15, 21, 23, 44], "select": 12, "v": 12, "integr": 13, "knowledg": 13, "student": 13, "teacher": 13, "loss": [13, 52], "balanc": 13, "soft": 13, "label": 13, "spars": 14, "structur": 14, "unstructur": 14, "n": 14, "m": 14, "algorithm": [14, 16, 17, 70, 108], "state": 15, "weight": 15, "togeth": 15, "separ": 15, "huggingfac": [15, 96], "api": [15, 23], "specul": [16, 150], "decod": 16, "medusa": [16, 152], "sepcul": 16, "basic": 17, "precis": 17, "format": [17, 113], "scale": 17, "factor": 17, "block": 17, "calibr": [17, 19, 110], "qat": [17, 20], "more": 17, "read": 17, "best": 18, "practic": 18, "right": 18, "method": 18, "onnx": [19, 28, 44], "beta": 19, "appli": [19, 20], "prepar": 19, "call": 19, "function": [19, 120, 178], "compar": 19, "partial": 20, "autoquant": 20, "auto_quant": 20, "advanc": 20, "topic": 20, "tensorquant": 20, "placement": 20, "fast": 20, "migrat": 20, "from": 20, "pytorch_quant": 20, "welcom": 21, "document": 21, "get": 21, "guid": 21, "refer": 21, "changelog": 22, "0": 22, "17": 22, "2024": 22, "09": 22, "15": 22, "07": 22, "25": 22, "13": 22, "06": 22, "14": 22, "11": 22, "05": 22, "nemo_util": 27, "op_typ": 29, "calib_util": 31, "extens": [32, 115], "fp8": 33, "graph_util": 34, "gs_patch": 35, "int4": 36, "int8": 37, "oper": 38, "ort_patch": 39, "ort_util": 40, "partit": 41, "qdq_util": 42, "quant_util": 43, "util": [45, 83, 88, 98, 140, 166], "torch": 46, "distillation_model": 50, "loss_balanc": 51, "mode": [53, 77, 94, 104, 116, 144, 155], "registri": [54, 85], "distribut": [56, 169], "hf_config_map": 57, "layer_util": 58, "model_config": 59, "model_config_export": 60, "model_config_util": 61, "postprocess": 62, "scaling_factor_util": 63, "tensorrt_llm_typ": 64, "tensorrt_llm_util": 65, "transformer_engin": 66, "unified_export_hf": 67, "vllm": 68, "autona": 71, "hparam": [74, 93], "concat": [75, 161], "contain": [76, 79], "conv": 80, "linear": 81, "norm": 82, "plugin": [84, 95, 105, 133, 146, 156, 163], "search_spac": 86, "traced_hp": 87, "opt": 89, "dynam": 92, "searcher": [97, 147], "gradna": 102, "summari": 102, "detail": 102, "mcore_gpt_minitron": 103, "calib": 109, "histogram": 111, "max": 112, "configur": 113, "model_calib": 117, "model_qu": 118, "nn": [119, 162], "clip": 122, "quant_activ": 123, "quant_batchnorm": 124, "quant_conv": 125, "quant_instancenorm": 126, "quant_linear": 127, "quant_modul": [128, 138], "quant_pool": 129, "quant_rnn": 130, "tensor_quant": 131, "qtensor": 134, "base_qtensor": 135, "int4_tensor": 136, "nf4_tensor": 137, "tensor_qu": 139, "magnitud": 143, "sparsegpt": 148, "medusa_model": 154, "speculative_decod": 157, "trace": 158, "analyz": 159, "symbol": 164, "tracer": 165, "cpp_extens": 167, "dataset_util": 168, "graph": 170, "list": 171, "log": 172, "network": 173, "perf": 174, "random": 175, "tensor": 176, "contact": 177, "u": 177, "faq": 178, "parallel": 178, "monkei": 178, "patch": 178, "issu": 178, "1": 178, "potenti": 178, "memori": 178, "leak": 178, "fsdp": 178, "use_orig_param": 178, "true": 178}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"TensorRT-LLM Deployment": [[0, "tensorrt-llm-deployment"]], "Export Quantized Model": [[0, "export-quantized-model"]], "Model support matrix for the TensorRT-LLM checkpoint export": [[0, "id1"]], "Convert to TensorRT-LLM": [[0, "convert-to-tensorrt-llm"]], "All GitHub Examples": [[1, "all-github-examples"]], "ResNet20 on CIFAR-10: Pruning": [[2, "ResNet20-on-CIFAR-10:-Pruning"]], "CIFAR-10 Dataset for Image Classification": [[2, "CIFAR-10-Dataset-for-Image-Classification"]], "ResNet for CIFAR dataset": [[2, "ResNet-for-CIFAR-dataset"]], "Setting up the model": [[2, "Setting-up-the-model"]], "Training a baseline model": [[2, "Training-a-baseline-model"]], "FastNAS Pruning with Model Optimizer": [[2, "FastNAS-Pruning-with-Model-Optimizer"]], "Prune base model and store pruned net": [[2, "Prune-base-model-and-store-pruned-net"]], "Restore the pruned subnet using mto.restore": [[2, "Restore-the-pruned-subnet-using-mto.restore"]], "Fine-tuning": [[2, "Fine-tuning"], [11, "fine-tuning"], [12, "fine-tuning"]], "Evaluate the searched subnet": [[2, "Evaluate-the-searched-subnet"]], "HF BERT: Prune, Distill & Quantize": [[3, "hf-bert-prune-distill-quantize"]], "Prerequisites": [[3, "prerequisites"], [11, "prerequisites"], [11, "id1"], [12, "prerequisites"], [12, "id1"], [12, "id2"]], "Full code": [[3, "full-code"]], "Commands": [[3, "commands"]], "Overview": [[4, "overview"], [12, "overview"], [13, "overview"]], "NVIDIA TensorRT Model Optimizer": [[4, "nvidia-tensorrt-model-optimizer"]], "Techniques": [[4, "techniques"]], "Quantization": [[4, "quantization"], [6, "quantization"], [10, "quantization"]], "Sparsity": [[4, "sparsity"], [9, "sparsity"], [14, "sparsity"]], "Distillation": [[4, "distillation"], [13, "distillation"]], "Pruning": [[4, "pruning"], [11, "pruning"]], "Installation": [[5, "installation"]], "System requirements": [[5, "system-requirements"]], "Install Model Optimizer": [[5, "install-model-optimizer"]], "Check installation": [[5, "check-installation"]], "Quick Start: Quantization": [[6, "quick-start-quantization"]], "PTQ for PyTorch models": [[6, "ptq-for-pytorch-models"]], "Deployment": [[6, "deployment"], [21, null]], "Quick Start: Pruning": [[7, "quick-start-pruning"]], "Set up your model": [[7, "set-up-your-model"]], "Set up the search": [[7, "set-up-the-search"]], "Prune the model": [[7, "prune-the-model"]], "Quick Start: Distillation": [[8, "quick-start-distillation"]], "Set up your base models": [[8, "set-up-your-base-models"]], "Set up the meta model": [[8, "set-up-the-meta-model"]], "Distill during training": [[8, "distill-during-training"]], "Export trained model": [[8, "export-trained-model"]], "Quick Start: Sparsity": [[9, "quick-start-sparsity"]], "Post-Training Sparsification (PTS) for PyTorch models": [[9, "post-training-sparsification-pts-for-pytorch-models"]], "Sparsity-aware Training (SAT) for PyTorch models": [[9, "sparsity-aware-training-sat-for-pytorch-models"]], "Training": [[11, "training"], [12, "training"]], "Pruning and subnet search": [[11, "pruning-and-subnet-search"]], "Perform pruning": [[11, "perform-pruning"]], "Storing the prune results": [[11, "storing-the-prune-results"]], "Customizing pruning config": [[11, "customizing-pruning-config"]], "Profiling the search space and choosing constraints": [[11, "profiling-the-search-space-and-choosing-constraints"]], "Load the pruned model": [[11, "load-the-pruned-model"]], "Run fine-tuning": [[11, "run-fine-tuning"]], "Deploy": [[11, "deploy"]], "Pruning Concepts": [[11, "pruning-concepts"]], "NAS": [[12, "nas"]], "Introduction": [[12, "introduction"], [13, "introduction"], [14, "introduction"], [16, "introduction"]], "Convert and save": [[12, "convert-and-save"]], "Profiling a search space": [[12, "profiling-a-search-space"]], "NAS training": [[12, "nas-training"]], "Restore the search space": [[12, "restore-the-search-space"]], "Subnet architecture search": [[12, "subnet-architecture-search"]], "Performing search": [[12, "performing-search"]], "NAS Model Prerequisites": [[12, "nas-model-prerequisites"]], "Convert your model": [[12, "convert-your-model"]], "The conversion process": [[12, "the-conversion-process"]], "Layer support": [[12, "layer-support"]], "Generating a search space": [[12, "generating-a-search-space"]], "Traceability": [[12, "traceability"]], "DistributedDataParallel": [[12, "distributeddataparallel"]], "Auxiliary modules": [[12, "auxiliary-modules"]], "Known limitations": [[12, "known-limitations"]], "NAS Concepts": [[12, "nas-concepts"]], "Glossary": [[12, "id4"], [13, "id3"]], "Concepts": [[12, "concepts"], [13, "concepts"]], "Neural Architecture Search (NAS)": [[12, "neural-architecture-search-nas"]], "Search space": [[12, "search-space"]], "Architecture hyperparameters": [[12, "architecture-hyperparameters"]], "Subnet": [[12, "subnet"]], "ModelOpt-converted model": [[12, "modelopt-converted-model"]], "NAS-based training": [[12, "nas-based-training"]], "Architecture search & selection": [[12, "architecture-search-selection"]], "Subnet fine-tuning": [[12, "subnet-fine-tuning"]], "NAS vs. Pruning": [[12, "nas-vs-pruning"]], "Convert and integrate": [[13, "convert-and-integrate"]], "Distillation Concepts": [[13, "distillation-concepts"]], "Knowledge Distillation": [[13, "knowledge-distillation"]], "Student": [[13, "student"]], "Teacher": [[13, "teacher"]], "Distillation loss": [[13, "distillation-loss"]], "Loss Balancer": [[13, "loss-balancer"]], "Soft-label Distillation": [[13, "soft-label-distillation"]], "Post-Training Sparsification": [[14, "post-training-sparsification"]], "Save and restore the sparse model": [[14, "save-and-restore-the-sparse-model"]], "Sparsity Concepts": [[14, "sparsity-concepts"]], "Structured and Unstructured Sparsity": [[14, "structured-and-unstructured-sparsity"]], "N:M Sparsity": [[14, "n-m-sparsity"]], "Sparsification algorithm": [[14, "sparsification-algorithm"]], "Saving & Restoring": [[15, "saving-restoring"]], "Saving ModelOpt Models": [[15, "saving-modelopt-models"]], "Saving ModelOpt state & model weights together": [[15, "saving-modelopt-state-model-weights-together"]], "Saving ModelOpt state and model weights separately": [[15, "saving-modelopt-state-and-model-weights-separately"]], "Restoring ModelOpt Models": [[15, "restoring-modelopt-models"]], "Restoring ModelOpt state & model weights together": [[15, "restoring-modelopt-state-model-weights-together"]], "Restoring ModelOpt state and model weights separately": [[15, "restoring-modelopt-state-and-model-weights-separately"]], "ModelOpt Save/Restore Using Huggingface Checkpointing APIs": [[15, "modelopt-save-restore-using-huggingface-checkpointing-apis"]], "Speculative Decoding": [[16, "speculative-decoding"]], "Convert": [[16, "convert"]], "Fine-tune Medusa model and save": [[16, "fine-tune-medusa-model-and-save"]], "Speculative Decoding Concepts": [[16, "speculative-decoding-concepts"]], "Sepculative decoding": [[16, "sepculative-decoding"]], "Medusa algorithm": [[16, "medusa-algorithm"]], "Basic Concepts": [[17, "basic-concepts"]], "Precision format": [[17, "precision-format"]], "Scaling factor": [[17, "scaling-factor"]], "Block format": [[17, "block-format"]], "Calibration algorithm": [[17, "calibration-algorithm"]], "Quantization-aware training (QAT)": [[17, "quantization-aware-training-qat"]], "More Readings": [[17, "more-readings"]], "Best practices to choose the right quantization methods": [[18, "best-practices-to-choose-the-right-quantization-methods"]], "ONNX Quantization (Beta)": [[19, "onnx-quantization-beta"]], "Requirements": [[19, "requirements"]], "Apply Post Training Quantization (PTQ)": [[19, "apply-post-training-quantization-ptq"], [20, "apply-post-training-quantization-ptq"]], "Prepare calibration dataset": [[19, "prepare-calibration-dataset"]], "Call PTQ function": [[19, "call-ptq-function"]], "Deploy Quantized ONNX Model": [[19, "deploy-quantized-onnx-model"]], "Compare the performance": [[19, "compare-the-performance"]], "PyTorch Quantization": [[20, "pytorch-quantization"]], "Quantization-aware Training (QAT)": [[20, "quantization-aware-training-qat"]], "Storing and restoring quantized model": [[20, "storing-and-restoring-quantized-model"]], "Optimal Partial Quantization using AutoQuantize(auto_quantize)": [[20, "optimal-partial-quantization-using-autoquantize-auto-quantize"]], "Advanced Topics": [[20, "advanced-topics"]], "TensorQuantizer": [[20, "tensorquantizer"]], "Customize quantizer config": [[20, "customize-quantizer-config"]], "Custom quantized module and quantizer placement": [[20, "custom-quantized-module-and-quantizer-placement"]], "Fast evaluation": [[20, "fast-evaluation"]], "Migrate from pytorch_quantization": [[20, "migrate-from-pytorch-quantization"]], "Welcome to Model Optimizer (ModelOpt) documentation!": [[21, "welcome-to-model-optimizer-modelopt-documentation"]], "Getting Started": [[21, null]], "Guides": [[21, null]], "Examples": [[21, null]], "Reference": [[21, null]], "Support": [[21, null]], "Changelog": [[22, "changelog"]], "Model Optimizer Changelog": [[22, "model-optimizer-changelog"]], "0.17 (2024-09-10)": [[22, "id1"]], "0.15 (2024-07-25)": [[22, "id2"]], "0.13 (2024-06-14)": [[22, "id3"]], "0.11 (2024-05-07)": [[22, "id5"]], "modelopt API": [[23, "modelopt-api"]], "deploy": [[24, "deploy"]], "llm": [[25, "llm"]], "generate": [[26, "generate"]], "nemo_utils": [[27, "nemo-utils"]], "onnx": [[28, "onnx"]], "op_types": [[29, "op-types"]], "quantization": [[30, "quantization"], [107, "quantization"]], "calib_utils": [[31, "calib-utils"]], "extensions": [[32, "extensions"], [115, "extensions"]], "fp8": [[33, "fp8"]], "graph_utils": [[34, "graph-utils"]], "gs_patching": [[35, "gs-patching"]], "int4": [[36, "int4"]], "int8": [[37, "int8"]], "operators": [[38, "operators"]], "ort_patching": [[39, "ort-patching"]], "ort_utils": [[40, "ort-utils"]], "partitioning": [[41, "partitioning"]], "qdq_utils": [[42, "qdq-utils"]], "quant_utils": [[43, "quant-utils"]], "modelopt.onnx.quantization.quantize": [[44, "modelopt-onnx-quantization-quantize"]], "utils": [[45, "utils"], [83, "utils"], [88, "utils"], [98, "utils"], [140, "utils"], [166, "utils"]], "torch": [[46, "torch"]], "distill": [[47, "distill"]], "config": [[48, "config"], [72, "config"], [90, "config"], [100, "config"], [113, "config"], [142, "config"], [151, "config"]], "distillation": [[49, "distillation"]], "distillation_model": [[50, "distillation-model"]], "loss_balancers": [[51, "loss-balancers"]], "losses": [[52, "losses"]], "mode": [[53, "mode"], [77, "mode"], [94, "mode"], [104, "mode"], [116, "mode"], [144, "mode"], [155, "mode"]], "registry": [[54, "registry"], [85, "registry"]], "export": [[55, "export"]], "distribute": [[56, "distribute"]], "hf_config_map": [[57, "hf-config-map"]], "layer_utils": [[58, "layer-utils"]], "model_config": [[59, "model-config"]], "model_config_export": [[60, "model-config-export"]], "model_config_utils": [[61, "model-config-utils"]], "postprocess": [[62, "postprocess"]], "scaling_factor_utils": [[63, "scaling-factor-utils"]], "tensorrt_llm_type": [[64, "tensorrt-llm-type"]], "tensorrt_llm_utils": [[65, "tensorrt-llm-utils"]], "transformer_engine": [[66, "transformer-engine"]], "unified_export_hf": [[67, "unified-export-hf"]], "vllm": [[68, "vllm"]], "nas": [[69, "nas"]], "algorithms": [[70, "algorithms"], [108, "algorithms"]], "autonas": [[71, "autonas"]], "conversion": [[73, "conversion"], [91, "conversion"], [114, "conversion"], [153, "conversion"]], "hparams": [[74, "hparams"]], "concat": [[75, "concat"], [161, "concat"]], "container": [[76, "container"], [79, "container"]], "modules": [[78, "modules"], [121, "modules"], [160, "modules"]], "conv": [[80, "conv"]], "linear": [[81, "linear"]], "norm": [[82, "norm"]], "plugins": [[84, "plugins"], [95, "plugins"], [105, "plugins"], [133, "plugins"], [146, "plugins"], [156, "plugins"], [163, "plugins"]], "search_space": [[86, "search-space"]], "traced_hp": [[87, "traced-hp"]], "opt": [[89, "opt"]], "dynamic": [[92, "dynamic"]], "hparam": [[93, "hparam"]], "huggingface": [[96, "huggingface"]], "searcher": [[97, "searcher"], [147, "searcher"]], "prune": [[99, "prune"]], "fastnas": [[101, "fastnas"]], "gradnas": [[102, "gradnas"]], "Summary:": [[102, "summary"]], "Details:": [[102, "details"]], "mcore_gpt_minitron": [[103, "mcore-gpt-minitron"]], "pruning": [[106, "pruning"]], "calib": [[109, "calib"]], "calibrator": [[110, "calibrator"]], "histogram": [[111, "histogram"]], "max": [[112, "max"]], "Quantization Formats": [[113, "quantization-formats"]], "Quantization Configs": [[113, "quantization-configs"]], "Example Quantization Configurations": [[113, "example-quantization-configurations"]], "model_calib": [[117, "model-calib"]], "model_quant": [[118, "model-quant"]], "nn": [[119, "nn"], [162, "nn"]], "functional": [[120, "functional"]], "clip": [[122, "clip"]], "quant_activations": [[123, "quant-activations"]], "quant_batchnorm": [[124, "quant-batchnorm"]], "quant_conv": [[125, "quant-conv"]], "quant_instancenorm": [[126, "quant-instancenorm"]], "quant_linear": [[127, "quant-linear"]], "quant_module": [[128, "quant-module"]], "quant_pooling": [[129, "quant-pooling"]], "quant_rnn": [[130, "quant-rnn"]], "tensor_quantizer": [[131, "tensor-quantizer"]], "optim": [[132, "optim"]], "qtensor": [[134, "qtensor"]], "base_qtensor": [[135, "base-qtensor"]], "int4_tensor": [[136, "int4-tensor"]], "nf4_tensor": [[137, "nf4-tensor"]], "quant_modules": [[138, "quant-modules"]], "tensor_quant": [[139, "tensor-quant"]], "sparsity": [[141, "sparsity"]], "magnitude": [[143, "magnitude"]], "module": [[145, "module"]], "sparsegpt": [[148, "sparsegpt"]], "sparsification": [[149, "sparsification"]], "speculative": [[150, "speculative"]], "medusa": [[152, "medusa"]], "medusa_model": [[154, "medusa-model"]], "speculative_decoding": [[157, "speculative-decoding"]], "trace": [[158, "trace"]], "analyzer": [[159, "analyzer"]], "symbols": [[164, "symbols"]], "tracer": [[165, "tracer"]], "cpp_extension": [[167, "cpp-extension"]], "dataset_utils": [[168, "dataset-utils"]], "distributed": [[169, "distributed"]], "graph": [[170, "graph"]], "list": [[171, "list"]], "logging": [[172, "logging"]], "network": [[173, "network"]], "perf": [[174, "perf"]], "random": [[175, "random"]], "tensor": [[176, "tensor"]], "Contact us": [[177, "contact-us"]], "FAQs": [[178, "faqs"]], "NAS/Pruning": [[178, "nas-pruning"]], "Parallel search": [[178, "parallel-search"]], "Monkey-patched functions": [[178, "monkey-patched-functions"]], "Known Issues": [[178, "known-issues"]], "1. Potential memory leak for FSDP with use_orig_params=True": [[178, "potential-memory-leak-for-fsdp-with-use-orig-params-true"]]}, "indexentries": {"modelopt.deploy": [[24, "module-modelopt.deploy"]], "module": [[24, "module-modelopt.deploy"], [25, "module-modelopt.deploy.llm"], [26, "module-modelopt.deploy.llm.generate"], [27, "module-modelopt.deploy.llm.nemo_utils"], [28, "module-modelopt.onnx"], [29, "module-modelopt.onnx.op_types"], [30, "module-modelopt.onnx.quantization"], [31, "module-modelopt.onnx.quantization.calib_utils"], [32, "module-modelopt.onnx.quantization.extensions"], [33, "module-modelopt.onnx.quantization.fp8"], [34, "module-modelopt.onnx.quantization.graph_utils"], [35, "module-modelopt.onnx.quantization.gs_patching"], [36, "module-modelopt.onnx.quantization.int4"], [37, "module-modelopt.onnx.quantization.int8"], [38, "module-modelopt.onnx.quantization.operators"], [39, "module-modelopt.onnx.quantization.ort_patching"], [40, "module-modelopt.onnx.quantization.ort_utils"], [41, "module-modelopt.onnx.quantization.partitioning"], [42, "module-modelopt.onnx.quantization.qdq_utils"], [43, "module-modelopt.onnx.quantization.quant_utils"], [45, "module-modelopt.onnx.utils"], [46, "module-modelopt.torch"], [47, "module-modelopt.torch.distill"], [48, "module-modelopt.torch.distill.config"], [49, "module-modelopt.torch.distill.distillation"], [50, "module-modelopt.torch.distill.distillation_model"], [51, "module-modelopt.torch.distill.loss_balancers"], [52, "module-modelopt.torch.distill.losses"], [53, "module-modelopt.torch.distill.mode"], [54, "module-modelopt.torch.distill.registry"], [55, "module-modelopt.torch.export"], [56, "module-modelopt.torch.export.distribute"], [57, "module-modelopt.torch.export.hf_config_map"], [58, "module-modelopt.torch.export.layer_utils"], [59, "module-modelopt.torch.export.model_config"], [60, "module-modelopt.torch.export.model_config_export"], [61, "module-modelopt.torch.export.model_config_utils"], [62, "module-modelopt.torch.export.postprocess"], [63, "module-modelopt.torch.export.scaling_factor_utils"], [64, "module-modelopt.torch.export.tensorrt_llm_type"], [65, "module-modelopt.torch.export.tensorrt_llm_utils"], [66, "module-modelopt.torch.export.transformer_engine"], [67, "module-modelopt.torch.export.unified_export_hf"], [68, "module-modelopt.torch.export.vllm"], [69, "module-modelopt.torch.nas"], [70, "module-modelopt.torch.nas.algorithms"], [71, "module-modelopt.torch.nas.autonas"], [72, "module-modelopt.torch.nas.config"], [73, "module-modelopt.torch.nas.conversion"], [74, "module-modelopt.torch.nas.hparams"], [75, "module-modelopt.torch.nas.hparams.concat"], [76, "module-modelopt.torch.nas.hparams.container"], [77, "module-modelopt.torch.nas.mode"], [78, "module-modelopt.torch.nas.modules"], [79, "module-modelopt.torch.nas.modules.container"], [80, "module-modelopt.torch.nas.modules.conv"], [81, "module-modelopt.torch.nas.modules.linear"], [82, "module-modelopt.torch.nas.modules.norm"], [83, "module-modelopt.torch.nas.modules.utils"], [84, "module-modelopt.torch.nas.plugins"], [85, "module-modelopt.torch.nas.registry"], [86, "module-modelopt.torch.nas.search_space"], [87, "module-modelopt.torch.nas.traced_hp"], [88, "module-modelopt.torch.nas.utils"], [89, "module-modelopt.torch.opt"], [90, "module-modelopt.torch.opt.config"], [91, "module-modelopt.torch.opt.conversion"], [92, "module-modelopt.torch.opt.dynamic"], [93, "module-modelopt.torch.opt.hparam"], [94, "module-modelopt.torch.opt.mode"], [95, "module-modelopt.torch.opt.plugins"], [96, "module-modelopt.torch.opt.plugins.huggingface"], [97, "module-modelopt.torch.opt.searcher"], [98, "module-modelopt.torch.opt.utils"], [99, "module-modelopt.torch.prune"], [100, "module-modelopt.torch.prune.config"], [101, "module-modelopt.torch.prune.fastnas"], [102, "module-modelopt.torch.prune.gradnas"], [103, "module-modelopt.torch.prune.mcore_gpt_minitron"], [104, "module-modelopt.torch.prune.mode"], [105, "module-modelopt.torch.prune.plugins"], [106, "module-modelopt.torch.prune.pruning"], [107, "module-modelopt.torch.quantization"], [108, "module-modelopt.torch.quantization.algorithms"], [109, "module-modelopt.torch.quantization.calib"], [110, "module-modelopt.torch.quantization.calib.calibrator"], [111, "module-modelopt.torch.quantization.calib.histogram"], [112, "module-modelopt.torch.quantization.calib.max"], [113, "module-modelopt.torch.quantization.config"], [114, "module-modelopt.torch.quantization.conversion"], [115, "module-modelopt.torch.quantization.extensions"], [116, "module-modelopt.torch.quantization.mode"], [117, "module-modelopt.torch.quantization.model_calib"], [118, "module-modelopt.torch.quantization.model_quant"], [119, "module-modelopt.torch.quantization.nn"], [120, "module-modelopt.torch.quantization.nn.functional"], [121, "module-modelopt.torch.quantization.nn.modules"], [122, "module-modelopt.torch.quantization.nn.modules.clip"], [123, "module-modelopt.torch.quantization.nn.modules.quant_activations"], [124, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"], [125, "module-modelopt.torch.quantization.nn.modules.quant_conv"], [126, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"], [127, "module-modelopt.torch.quantization.nn.modules.quant_linear"], [128, "module-modelopt.torch.quantization.nn.modules.quant_module"], [129, "module-modelopt.torch.quantization.nn.modules.quant_pooling"], [130, "module-modelopt.torch.quantization.nn.modules.quant_rnn"], [131, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"], [132, "module-modelopt.torch.quantization.optim"], [133, "module-modelopt.torch.quantization.plugins"], [134, "module-modelopt.torch.quantization.qtensor"], [135, "module-modelopt.torch.quantization.qtensor.base_qtensor"], [136, "module-modelopt.torch.quantization.qtensor.int4_tensor"], [137, "module-modelopt.torch.quantization.qtensor.nf4_tensor"], [138, "module-modelopt.torch.quantization.quant_modules"], [139, "module-modelopt.torch.quantization.tensor_quant"], [140, "module-modelopt.torch.quantization.utils"], [141, "module-modelopt.torch.sparsity"], [142, "module-modelopt.torch.sparsity.config"], [143, "module-modelopt.torch.sparsity.magnitude"], [144, "module-modelopt.torch.sparsity.mode"], [145, "module-modelopt.torch.sparsity.module"], [146, "module-modelopt.torch.sparsity.plugins"], [147, "module-modelopt.torch.sparsity.searcher"], [148, "module-modelopt.torch.sparsity.sparsegpt"], [149, "module-modelopt.torch.sparsity.sparsification"], [150, "module-modelopt.torch.speculative"], [151, "module-modelopt.torch.speculative.config"], [152, "module-modelopt.torch.speculative.medusa"], [153, "module-modelopt.torch.speculative.medusa.conversion"], [154, "module-modelopt.torch.speculative.medusa.medusa_model"], [155, "module-modelopt.torch.speculative.mode"], [156, "module-modelopt.torch.speculative.plugins"], [157, "module-modelopt.torch.speculative.speculative_decoding"], [158, "module-modelopt.torch.trace"], [159, "module-modelopt.torch.trace.analyzer"], [160, "module-modelopt.torch.trace.modules"], [161, "module-modelopt.torch.trace.modules.concat"], [162, "module-modelopt.torch.trace.modules.nn"], [163, "module-modelopt.torch.trace.plugins"], [164, "module-modelopt.torch.trace.symbols"], [165, "module-modelopt.torch.trace.tracer"], [166, "module-modelopt.torch.utils"], [167, "module-modelopt.torch.utils.cpp_extension"], [168, "module-modelopt.torch.utils.dataset_utils"], [169, "module-modelopt.torch.utils.distributed"], [170, "module-modelopt.torch.utils.graph"], [171, "module-modelopt.torch.utils.list"], [172, "module-modelopt.torch.utils.logging"], [173, "module-modelopt.torch.utils.network"], [174, "module-modelopt.torch.utils.perf"], [175, "module-modelopt.torch.utils.random"], [176, "module-modelopt.torch.utils.tensor"]], "modelopt.deploy.llm": [[25, "module-modelopt.deploy.llm"]], "llm (class in modelopt.deploy.llm.generate)": [[26, "modelopt.deploy.llm.generate.LLM"]], "__init__() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.__init__"]], "generate_context_logits() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.generate_context_logits"]], "generate_text() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.generate_text"]], "generate_tokens() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.generate_tokens"]], "max_beam_width (llm property)": [[26, "modelopt.deploy.llm.generate.LLM.max_beam_width"]], "max_input_len (llm property)": [[26, "modelopt.deploy.llm.generate.LLM.max_input_len"]], "modelopt.deploy.llm.generate": [[26, "module-modelopt.deploy.llm.generate"]], "customsentencepiecetokenizer (class in modelopt.deploy.llm.nemo_utils)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer"]], "__init__() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.__init__"]], "batch_decode() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_decode"]], "batch_encode_plus() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_encode_plus"]], "decode() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.decode"]], "encode() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.encode"]], "eos_token (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token"]], "eos_token_id (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token_id"]], "get_nemo_tokenizer() (in module modelopt.deploy.llm.nemo_utils)": [[27, "modelopt.deploy.llm.nemo_utils.get_nemo_tokenizer"]], "get_tokenzier() (in module modelopt.deploy.llm.nemo_utils)": [[27, "modelopt.deploy.llm.nemo_utils.get_tokenzier"]], "modelopt.deploy.llm.nemo_utils": [[27, "module-modelopt.deploy.llm.nemo_utils"]], "pad_token (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token"]], "pad_token_id (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token_id"]], "modelopt.onnx": [[28, "module-modelopt.onnx"]], "is_binary_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_binary_op"]], "is_control_flow_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_control_flow_op"]], "is_conversion_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_conversion_op"]], "is_copy_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_copy_op"]], "is_default_quantizable_op_by_ort() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_default_quantizable_op_by_ort"]], "is_fusible_reduction_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_fusible_reduction_op"]], "is_generator_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_generator_op"]], "is_irregular_mem_access_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_irregular_mem_access_op"]], "is_linear_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_linear_op"]], "is_modifier_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_modifier_op"]], "is_multiclass_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_multiclass_op"]], "is_non_reshape_copy_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_non_reshape_copy_op"]], "is_normalization_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_normalization_op"]], "is_pointwise_or_elementwise_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_pointwise_or_elementwise_op"]], "is_pooling_or_window_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_pooling_or_window_op"]], "is_recurrent_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_recurrent_op"]], "is_selection_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_selection_op"]], "is_sequence_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_sequence_op"]], "is_shape_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_shape_op"]], "is_unary_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_unary_op"]], "modelopt.onnx.op_types": [[29, "module-modelopt.onnx.op_types"]], "modelopt.onnx.quantization": [[30, "module-modelopt.onnx.quantization"]], "calibrationdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[31, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider"]], "randomdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[31, "modelopt.onnx.quantization.calib_utils.RandomDataProvider"]], "__init__() (calibrationdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.__init__"]], "__init__() (randomdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.__init__"]], "get_next() (calibrationdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.get_next"]], "get_next() (randomdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.get_next"]], "import_scales_from_calib_cache() (in module modelopt.onnx.quantization.calib_utils)": [[31, "modelopt.onnx.quantization.calib_utils.import_scales_from_calib_cache"]], "modelopt.onnx.quantization.calib_utils": [[31, "module-modelopt.onnx.quantization.calib_utils"]], "modelopt.onnx.quantization.extensions": [[32, "module-modelopt.onnx.quantization.extensions"]], "int8_to_fp8() (in module modelopt.onnx.quantization.fp8)": [[33, "modelopt.onnx.quantization.fp8.int8_to_fp8"]], "modelopt.onnx.quantization.fp8": [[33, "module-modelopt.onnx.quantization.fp8"]], "quantize() (in module modelopt.onnx.quantization.fp8)": [[33, "modelopt.onnx.quantization.fp8.quantize"]], "add_fp16_fp32_cast() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast"]], "build_non_residual_input_map() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.build_non_residual_input_map"]], "classify_partition_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.classify_partition_nodes"]], "expand_node_names_from_patterns() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.expand_node_names_from_patterns"]], "filter_quantizable_kgen_heads() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads"]], "find_fp8_mha_partitions() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_mha_partitions"]], "find_nodes_from_mha_to_exclude() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_nodes_from_mha_to_exclude"]], "find_nodes_to_exclude() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude"]], "get_fusible_backbone() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.get_fusible_backbone"]], "get_tensor_consumer_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.get_tensor_consumer_nodes"]], "get_tensor_producer_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.get_tensor_producer_nodes"]], "has_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.has_const_input"]], "has_path_type() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.has_path_type"]], "insert_fp8_mha_casts() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts"]], "insert_matmul_casts() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.insert_matmul_casts"]], "is_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.is_const_input"]], "modelopt.onnx.quantization.graph_utils": [[34, "module-modelopt.onnx.quantization.graph_utils"]], "print_stat() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.print_stat"]], "remove_partial_input_qdq() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[35, "module-modelopt.onnx.quantization.gs_patching"]], "patch_gs_modules() (in module modelopt.onnx.quantization.gs_patching)": [[35, "modelopt.onnx.quantization.gs_patching.patch_gs_modules"]], "awqcliphelper (class in modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper"]], "awqlitehelper (class in modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper"]], "__init__() (awqcliphelper method)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.__init__"]], "__init__() (awqlitehelper method)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper.__init__"]], "alpha_step (awqcliphelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.alpha_step"]], "alpha_step (awqlitehelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper.alpha_step"]], "alphas (awqcliphelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.alphas"]], "dq_tensor() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.dq_tensor"]], "find_scales() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.find_scales"]], "get_act_scale() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_act_scale"]], "get_scale() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_scale"]], "get_weight_scale() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_weight_scale"]], "min_alpha (awqcliphelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.min_alpha"]], "modelopt.onnx.quantization.int4": [[36, "module-modelopt.onnx.quantization.int4"]], "quant_tensor() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quant_tensor"]], "quantize() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quantize"]], "quantize_awq_clip() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quantize_awq_clip"]], "quantize_awq_lite() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quantize_awq_lite"]], "quantize_rtn() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quantize_rtn"]], "rtn() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.rtn"]], "update_best_params() (awqcliphelper method)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.update_best_params"]], "modelopt.onnx.quantization.int8": [[37, "module-modelopt.onnx.quantization.int8"]], "quantize() (in module modelopt.onnx.quantization.int8)": [[37, "modelopt.onnx.quantization.int8.quantize"]], "qdqconvtranspose (class in modelopt.onnx.quantization.operators)": [[38, "modelopt.onnx.quantization.operators.QDQConvTranspose"]], "qdqnormalization (class in modelopt.onnx.quantization.operators)": [[38, "modelopt.onnx.quantization.operators.QDQNormalization"]], "__init__() (qdqconvtranspose method)": [[38, "modelopt.onnx.quantization.operators.QDQConvTranspose.__init__"]], "__init__() (qdqnormalization method)": [[38, "modelopt.onnx.quantization.operators.QDQNormalization.__init__"]], "modelopt.onnx.quantization.operators": [[38, "module-modelopt.onnx.quantization.operators"]], "quantize() (qdqconvtranspose method)": [[38, "modelopt.onnx.quantization.operators.QDQConvTranspose.quantize"]], "quantize() (qdqnormalization method)": [[38, "modelopt.onnx.quantization.operators.QDQNormalization.quantize"]], "modelopt.onnx.quantization.ort_patching": [[39, "module-modelopt.onnx.quantization.ort_patching"]], "patch_ort_modules() (in module modelopt.onnx.quantization.ort_patching)": [[39, "modelopt.onnx.quantization.ort_patching.patch_ort_modules"]], "configure_ort() (in module modelopt.onnx.quantization.ort_utils)": [[40, "modelopt.onnx.quantization.ort_utils.configure_ort"]], "create_inference_session() (in module modelopt.onnx.quantization.ort_utils)": [[40, "modelopt.onnx.quantization.ort_utils.create_inference_session"]], "get_quantizable_op_types() (in module modelopt.onnx.quantization.ort_utils)": [[40, "modelopt.onnx.quantization.ort_utils.get_quantizable_op_types"]], "modelopt.onnx.quantization.ort_utils": [[40, "module-modelopt.onnx.quantization.ort_utils"]], "find_fusible_partitions() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_fusible_partitions"]], "find_hardcoded_patterns() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_hardcoded_patterns"]], "find_layer_norm_partitions() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_layer_norm_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_mha_partitions"]], "find_non_quantizable_partitions_from_patterns() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_non_quantizable_partitions_from_patterns"]], "find_quantizable_nodes() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_quantizable_nodes"]], "get_skiped_output_layers() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.get_skiped_output_layers"]], "modelopt.onnx.quantization.partitioning": [[41, "module-modelopt.onnx.quantization.partitioning"]], "insert_dq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.insert_dq_nodes"]], "insert_pre_quant_scale_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.insert_pre_quant_scale_nodes"]], "insert_qdq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.insert_qdq_nodes"]], "make_gs_awq_scale() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_awq_scale"]], "make_gs_dequantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_node"]], "make_gs_dequantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_output"]], "make_gs_pre_quant_scale_node() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_pre_quant_scale_node"]], "make_gs_pre_quant_scale_output() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_pre_quant_scale_output"]], "make_gs_quantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_node"]], "make_gs_quantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_output"]], "make_gs_quantized_weight() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_quantized_weight"]], "make_gs_scale() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_scale"]], "make_gs_zp() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_zp"]], "modelopt.onnx.quantization.qdq_utils": [[42, "module-modelopt.onnx.quantization.qdq_utils"]], "qdq_to_dq() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.qdq_to_dq"]], "replace_scale_values() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.replace_scale_values"]], "use_trt_qdq_ops() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[43, "module-modelopt.onnx.quantization.quant_utils"]], "pack_float32_to_4bit_cpp_based() (in module modelopt.onnx.quantization.quant_utils)": [[43, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_cpp_based"]], "pack_float32_to_4bit_optimized() (in module modelopt.onnx.quantization.quant_utils)": [[43, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_optimized"]], "quantize() (in module modelopt.onnx.quantization)": [[44, "modelopt.onnx.quantization.quantize"]], "duplicate_shared_constants() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.duplicate_shared_constants"]], "find_lowest_common_ancestor() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.find_lowest_common_ancestor"]], "gen_random_inputs() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.gen_random_inputs"]], "get_all_input_names() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_all_input_names"]], "get_batch_size() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_batch_size"]], "get_batch_size_from_bytes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_batch_size_from_bytes"]], "get_child_nodes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_child_nodes"]], "get_input_names() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_input_names"]], "get_input_names_from_bytes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_input_names_from_bytes"]], "get_input_shapes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_input_shapes"]], "get_input_shapes_from_bytes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_input_shapes_from_bytes"]], "get_node_names() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_node_names"]], "get_node_names_from_bytes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_node_names_from_bytes"]], "get_output_names() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_output_names"]], "get_output_names_from_bytes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_output_names_from_bytes"]], "get_output_shapes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_output_shapes"]], "get_parent_nodes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_parent_nodes"]], "get_variable_inputs() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.get_variable_inputs"]], "is_valid_onnx_model() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.is_valid_onnx_model"]], "modelopt.onnx.utils": [[45, "module-modelopt.onnx.utils"]], "name_onnx_nodes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.name_onnx_nodes"]], "randomize_weights() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.randomize_weights"]], "randomize_weights_onnx_bytes() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.randomize_weights_onnx_bytes"]], "remove_weights_data() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.remove_weights_data"]], "save_onnx() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.save_onnx"]], "save_onnx_bytes_to_dir() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.save_onnx_bytes_to_dir"]], "udpate_domain() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.udpate_domain"]], "validate_batch_size() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.validate_batch_size"]], "validate_onnx() (in module modelopt.onnx.utils)": [[45, "modelopt.onnx.utils.validate_onnx"]], "modelopt.torch": [[46, "module-modelopt.torch"]], "modelopt.torch.distill": [[47, "module-modelopt.torch.distill"]], "criterion (kdlossconfig attribute)": [[48, "modelopt.torch.distill.config.KDLossConfig.criterion"]], "expose_minimal_state_dict (kdlossconfig attribute)": [[48, "modelopt.torch.distill.config.KDLossConfig.expose_minimal_state_dict"]], "loss_balancer (kdlossconfig attribute)": [[48, "modelopt.torch.distill.config.KDLossConfig.loss_balancer"]], "model_dump() (kdlossconfig method)": [[48, "modelopt.torch.distill.config.KDLossConfig.model_dump"]], "modelopt.torch.distill.config": [[48, "module-modelopt.torch.distill.config"]], "teacher_model (kdlossconfig attribute)": [[48, "modelopt.torch.distill.config.KDLossConfig.teacher_model"]], "convert() (in module modelopt.torch.distill.distillation)": [[49, "modelopt.torch.distill.distillation.convert"]], "export() (in module modelopt.torch.distill.distillation)": [[49, "modelopt.torch.distill.distillation.export"]], "modelopt.torch.distill.distillation": [[49, "module-modelopt.torch.distill.distillation"]], "distillationmodel (class in modelopt.torch.distill.distillation_model)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel"]], "compute_kd_loss() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.compute_kd_loss"]], "forward() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.forward"]], "hide_loss_modules() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.hide_loss_modules"]], "hide_teacher_model() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.hide_teacher_model"]], "load_state_dict() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.load_state_dict"]], "loss_balancer (distillationmodel property)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.loss_balancer"]], "loss_modules (distillationmodel property)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.loss_modules"]], "modelopt.torch.distill.distillation_model": [[50, "module-modelopt.torch.distill.distillation_model"]], "modify() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.modify"]], "state_dict() (distillationmodel method)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.state_dict"]], "teacher_model (distillationmodel property)": [[50, "modelopt.torch.distill.distillation_model.DistillationModel.teacher_model"]], "distillationlossbalancer (class in modelopt.torch.distill.loss_balancers)": [[51, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer"]], "staticlossbalancer (class in modelopt.torch.distill.loss_balancers)": [[51, "modelopt.torch.distill.loss_balancers.StaticLossBalancer"]], "__init__() (distillationlossbalancer method)": [[51, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.__init__"]], "__init__() (staticlossbalancer method)": [[51, "modelopt.torch.distill.loss_balancers.StaticLossBalancer.__init__"]], "forward() (distillationlossbalancer method)": [[51, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.forward"]], "forward() (staticlossbalancer method)": [[51, "modelopt.torch.distill.loss_balancers.StaticLossBalancer.forward"]], "modelopt.torch.distill.loss_balancers": [[51, "module-modelopt.torch.distill.loss_balancers"]], "set_student_loss_reduction_fn() (distillationlossbalancer method)": [[51, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.set_student_loss_reduction_fn"]], "logitsdistillationloss (class in modelopt.torch.distill.losses)": [[52, "modelopt.torch.distill.losses.LogitsDistillationLoss"]], "mgdloss (class in modelopt.torch.distill.losses)": [[52, "modelopt.torch.distill.losses.MGDLoss"]], "__init__() (logitsdistillationloss method)": [[52, "modelopt.torch.distill.losses.LogitsDistillationLoss.__init__"]], "__init__() (mgdloss method)": [[52, "modelopt.torch.distill.losses.MGDLoss.__init__"]], "forward() (logitsdistillationloss method)": [[52, "modelopt.torch.distill.losses.LogitsDistillationLoss.forward"]], "forward() (mgdloss method)": [[52, "modelopt.torch.distill.losses.MGDLoss.forward"]], "modelopt.torch.distill.losses": [[52, "module-modelopt.torch.distill.losses"]], "exportstudentmodedescriptor (class in modelopt.torch.distill.mode)": [[53, "modelopt.torch.distill.mode.ExportStudentModeDescriptor"]], "knowledgedistillationmodedescriptor (class in modelopt.torch.distill.mode)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor"]], "config_class (exportstudentmodedescriptor property)": [[53, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.config_class"]], "config_class (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.config_class"]], "convert (exportstudentmodedescriptor property)": [[53, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.convert"]], "convert (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.convert"]], "export_mode (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.export_mode"]], "is_export_mode (exportstudentmodedescriptor property)": [[53, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.is_export_mode"]], "modelopt.torch.distill.mode": [[53, "module-modelopt.torch.distill.mode"]], "name (exportstudentmodedescriptor property)": [[53, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.name"]], "name (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.name"]], "next_modes (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.next_modes"]], "restore (exportstudentmodedescriptor property)": [[53, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.restore"]], "restore (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.restore"]], "update_for_new_mode (knowledgedistillationmodedescriptor property)": [[53, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.update_for_new_mode"]], "modelopt.torch.distill.registry": [[54, "module-modelopt.torch.distill.registry"]], "modelopt.torch.export": [[55, "module-modelopt.torch.export"]], "nfsworkspace (class in modelopt.torch.export.distribute)": [[56, "modelopt.torch.export.distribute.NFSWorkspace"]], "__init__() (nfsworkspace method)": [[56, "modelopt.torch.export.distribute.NFSWorkspace.__init__"]], "get_configs_parallel() (in module modelopt.torch.export.distribute)": [[56, "modelopt.torch.export.distribute.get_configs_parallel"]], "get_tensors_parallel() (in module modelopt.torch.export.distribute)": [[56, "modelopt.torch.export.distribute.get_tensors_parallel"]], "is_initialized (nfsworkspace property)": [[56, "modelopt.torch.export.distribute.NFSWorkspace.is_initialized"]], "modelopt.torch.export.distribute": [[56, "module-modelopt.torch.export.distribute"]], "read_configs_and_weights_from_rank() (nfsworkspace method)": [[56, "modelopt.torch.export.distribute.NFSWorkspace.read_configs_and_weights_from_rank"]], "write_configs_and_weights() (nfsworkspace method)": [[56, "modelopt.torch.export.distribute.NFSWorkspace.write_configs_and_weights"]], "modelopt.torch.export.hf_config_map": [[57, "module-modelopt.torch.export.hf_config_map"]], "build_attention_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_attention_config"]], "build_conv_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_conv_config"]], "build_decoder_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_decoder_config"]], "build_embedding_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_embedding_config"]], "build_layernorm_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_layernorm_config"]], "build_linear_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_linear_config"]], "build_medusa_heads_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_medusa_heads_config"]], "build_mlp_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_mlp_config"]], "build_moe_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_moe_config"]], "build_qkv() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_qkv"]], "build_recurrent_config() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_recurrent_config"]], "build_stacked_experts() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.build_stacked_experts"]], "check_model_compatibility() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.check_model_compatibility"]], "get_activation_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_activation_scaling_factor"]], "get_kv_cache_dtype() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_kv_cache_dtype"]], "get_kv_cache_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_kv_cache_scaling_factor"]], "get_prequant_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_prequant_scaling_factor"]], "get_qkv_and_avg_prequant_scale() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_qkv_and_avg_prequant_scale"]], "get_quantization_format() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_quantization_format"]], "get_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_scaling_factor"]], "get_transformer_layers() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_transformer_layers"]], "get_weight_block_size() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_weight_block_size"]], "get_weight_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_weight_scaling_factor"]], "get_weight_scaling_factor_2() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.get_weight_scaling_factor_2"]], "is_attention() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_attention"]], "is_decoder_list() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_decoder_list"]], "is_embedding() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_embedding"]], "is_layernorm() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_layernorm"]], "is_linear() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_linear"]], "is_mlp() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_mlp"]], "is_moe() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_moe"]], "is_quantlinear() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_quantlinear"]], "is_recurrent() (in module modelopt.torch.export.layer_utils)": [[58, "modelopt.torch.export.layer_utils.is_recurrent"]], "modelopt.torch.export.layer_utils": [[58, "module-modelopt.torch.export.layer_utils"]], "attentionconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.AttentionConfig"]], "convconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.ConvConfig"]], "decoderlayerconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig"]], "embeddingconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.EmbeddingConfig"]], "expertconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.ExpertConfig"]], "layernormconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.LayernormConfig"]], "linearactconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.LinearActConfig"]], "linearconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.LinearConfig"]], "mlpconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.MLPConfig"]], "moeconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.MOEConfig"]], "medusaheadconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.MedusaHeadConfig"]], "modelconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.ModelConfig"]], "qkvconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.QKVConfig"]], "recurrentconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.RecurrentConfig"]], "rglruconfig (class in modelopt.torch.export.model_config)": [[59, "modelopt.torch.export.model_config.RgLruConfig"]], "__init__() (attentionconfig method)": [[59, "modelopt.torch.export.model_config.AttentionConfig.__init__"]], "__init__() (convconfig method)": [[59, "modelopt.torch.export.model_config.ConvConfig.__init__"]], "__init__() (decoderlayerconfig method)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.__init__"]], "__init__() (embeddingconfig method)": [[59, "modelopt.torch.export.model_config.EmbeddingConfig.__init__"]], "__init__() (expertconfig method)": [[59, "modelopt.torch.export.model_config.ExpertConfig.__init__"]], "__init__() (layernormconfig method)": [[59, "modelopt.torch.export.model_config.LayernormConfig.__init__"]], "__init__() (linearactconfig method)": [[59, "modelopt.torch.export.model_config.LinearActConfig.__init__"]], "__init__() (linearconfig method)": [[59, "modelopt.torch.export.model_config.LinearConfig.__init__"]], "__init__() (mlpconfig method)": [[59, "modelopt.torch.export.model_config.MLPConfig.__init__"]], "__init__() (moeconfig method)": [[59, "modelopt.torch.export.model_config.MOEConfig.__init__"]], "__init__() (medusaheadconfig method)": [[59, "modelopt.torch.export.model_config.MedusaHeadConfig.__init__"]], "__init__() (modelconfig method)": [[59, "modelopt.torch.export.model_config.ModelConfig.__init__"]], "__init__() (qkvconfig method)": [[59, "modelopt.torch.export.model_config.QKVConfig.__init__"]], "__init__() (recurrentconfig method)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.__init__"]], "__init__() (rglruconfig method)": [[59, "modelopt.torch.export.model_config.RgLruConfig.__init__"]], "activation_scaling_factor (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.activation_scaling_factor"]], "activation_scaling_factor (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.activation_scaling_factor"]], "alibi_bias_max (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.alibi_bias_max"]], "apply_residual_connection_post_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.apply_residual_connection_post_layernorm"]], "attention (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.attention"]], "attention_head_size (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_head_size"]], "attention_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_layernorm"]], "attn_logit_softcapping (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.attn_logit_softcapping"]], "awq_block_size (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.awq_block_size"]], "awq_block_size (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.awq_block_size"]], "bias (convconfig attribute)": [[59, "modelopt.torch.export.model_config.ConvConfig.bias"]], "bias (layernormconfig attribute)": [[59, "modelopt.torch.export.model_config.LayernormConfig.bias"]], "bias (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.bias"]], "bias (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.bias"]], "block_embedding (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.block_embedding"]], "blocksparse_block_size (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_block_size"]], "blocksparse_homo_head_pattern (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_homo_head_pattern"]], "blocksparse_num_local_blocks (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_num_local_blocks"]], "blocksparse_vertical_stride (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_vertical_stride"]], "clip_qkv (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.clip_qkv"]], "clip_qkv (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.clip_qkv"]], "conv1d (recurrentconfig attribute)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.conv1d"]], "cross_attention (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.cross_attention"]], "cross_attention_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.cross_attention_layernorm"]], "decoder_type (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.decoder_type"]], "dense (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.dense"]], "dense_attention_every_n_layers (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.dense_attention_every_n_layers"]], "dtype (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.dtype"]], "emb_scale_by_sqrt_dim (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.emb_scale_by_sqrt_dim"]], "enc_dec (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.enc_dec"]], "encoder_head_size (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.encoder_head_size"]], "encoder_hidden_size (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.encoder_hidden_size"]], "encoder_num_heads (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.encoder_num_heads"]], "eps (layernormconfig attribute)": [[59, "modelopt.torch.export.model_config.LayernormConfig.eps"]], "experts (moeconfig attribute)": [[59, "modelopt.torch.export.model_config.MOEConfig.experts"]], "fc (expertconfig attribute)": [[59, "modelopt.torch.export.model_config.ExpertConfig.fc"]], "fc (mlpconfig attribute)": [[59, "modelopt.torch.export.model_config.MLPConfig.fc"]], "fc (moeconfig property)": [[59, "modelopt.torch.export.model_config.MOEConfig.fc"]], "ffn_hidden_size_local (decoderlayerconfig property)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.ffn_hidden_size_local"]], "final_logit_softcapping (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.final_logit_softcapping"]], "gate (mlpconfig attribute)": [[59, "modelopt.torch.export.model_config.MLPConfig.gate"]], "gegelu_limit (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.gegelu_limit"]], "hidden_act (linearactconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearActConfig.hidden_act"]], "hidden_act (mlpconfig attribute)": [[59, "modelopt.torch.export.model_config.MLPConfig.hidden_act"]], "hidden_act (moeconfig attribute)": [[59, "modelopt.torch.export.model_config.MOEConfig.hidden_act"]], "hidden_act (modelconfig property)": [[59, "modelopt.torch.export.model_config.ModelConfig.hidden_act"]], "hidden_size (decoderlayerconfig property)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.hidden_size"]], "hidden_size (embeddingconfig property)": [[59, "modelopt.torch.export.model_config.EmbeddingConfig.hidden_size"]], "hidden_size (modelconfig property)": [[59, "modelopt.torch.export.model_config.ModelConfig.hidden_size"]], "input_gate (rglruconfig attribute)": [[59, "modelopt.torch.export.model_config.RgLruConfig.input_gate"]], "input_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.input_layernorm"]], "k (qkvconfig attribute)": [[59, "modelopt.torch.export.model_config.QKVConfig.k"]], "kv_cache_dtype (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_dtype"]], "kv_cache_scaling_factor (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_scaling_factor"]], "layer_types (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.layer_types"]], "layernorm_type (layernormconfig attribute)": [[59, "modelopt.torch.export.model_config.LayernormConfig.layernorm_type"]], "layers (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.layers"]], "linear (linearactconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearActConfig.linear"]], "linear_out (recurrentconfig attribute)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.linear_out"]], "linear_type (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.linear_type"]], "linear_x (recurrentconfig attribute)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.linear_x"]], "linear_y (recurrentconfig attribute)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.linear_y"]], "lm_head (medusaheadconfig attribute)": [[59, "modelopt.torch.export.model_config.MedusaHeadConfig.lm_head"]], "lm_head (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.lm_head"]], "ln_embed (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.ln_embed"]], "ln_f (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.ln_f"]], "local_vocab_size (embeddingconfig property)": [[59, "modelopt.torch.export.model_config.EmbeddingConfig.local_vocab_size"]], "logits_soft_cap (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.logits_soft_cap"]], "longrope_long_mscale (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_long_mscale"]], "longrope_scaling_long_factors (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_scaling_long_factors"]], "longrope_scaling_short_factors (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_scaling_short_factors"]], "longrope_short_mscale (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_short_mscale"]], "max_position_embeddings (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.max_position_embeddings"]], "max_position_embeddings (modelconfig property)": [[59, "modelopt.torch.export.model_config.ModelConfig.max_position_embeddings"]], "medusa_heads (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.medusa_heads"]], "medusa_layers (medusaheadconfig attribute)": [[59, "modelopt.torch.export.model_config.MedusaHeadConfig.medusa_layers"]], "merged_fc1_gate (mlpconfig attribute)": [[59, "modelopt.torch.export.model_config.MLPConfig.merged_fc1_gate"]], "mlp (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp"]], "mlp_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp_layernorm"]], "model_name (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.model_name"]], "modelopt.torch.export.model_config": [[59, "module-modelopt.torch.export.model_config"]], "moe_num_experts (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_num_experts"]], "moe_renorm_mode (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_renorm_mode"]], "moe_top_k (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_top_k"]], "moe_tp_mode (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_tp_mode"]], "mup_attn_multiplier (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_attn_multiplier"]], "mup_embedding_multiplier (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_embedding_multiplier"]], "mup_use_scaling (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_use_scaling"]], "mup_width_multiplier (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_width_multiplier"]], "new_decoder_architecture (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.new_decoder_architecture"]], "num_attention_heads (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.num_attention_heads"]], "num_attention_heads (modelconfig property)": [[59, "modelopt.torch.export.model_config.ModelConfig.num_attention_heads"]], "num_kv_heads (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.num_kv_heads"]], "num_kv_heads (modelconfig property)": [[59, "modelopt.torch.export.model_config.ModelConfig.num_kv_heads"]], "num_medusa_heads (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.num_medusa_heads"]], "num_medusa_layers (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.num_medusa_layers"]], "original_max_position_embeddings (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.original_max_position_embeddings"]], "parallel_attention (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.parallel_attention"]], "partial_rotary_factor (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.partial_rotary_factor"]], "pipeline_parallel (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.pipeline_parallel"]], "position_embedding (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.position_embedding"]], "post_feedforward_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.post_feedforward_layernorm"]], "post_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.post_layernorm"]], "pre_feedforward_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.pre_feedforward_layernorm"]], "prequant_scaling_factor (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.prequant_scaling_factor"]], "prequant_scaling_factor (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.prequant_scaling_factor"]], "proj (expertconfig attribute)": [[59, "modelopt.torch.export.model_config.ExpertConfig.proj"]], "proj (mlpconfig attribute)": [[59, "modelopt.torch.export.model_config.MLPConfig.proj"]], "q (qkvconfig attribute)": [[59, "modelopt.torch.export.model_config.QKVConfig.q"]], "qkv (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.qkv"]], "quantization (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.quantization"]], "quantization (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.quantization"]], "query_pre_attn_scalar (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.query_pre_attn_scalar"]], "qwen_type (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.qwen_type"]], "rank (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.rank"]], "recurrent (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.recurrent"]], "recurrent_gate (rglruconfig attribute)": [[59, "modelopt.torch.export.model_config.RgLruConfig.recurrent_gate"]], "recurrent_param (rglruconfig attribute)": [[59, "modelopt.torch.export.model_config.RgLruConfig.recurrent_param"]], "rel_attn_max_distance (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rel_attn_max_distance"]], "rel_attn_num_buckets (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rel_attn_num_buckets"]], "rel_attn_table (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.rel_attn_table"]], "residual_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_layernorm"]], "residual_mlp (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_mlp"]], "rg_lru (recurrentconfig attribute)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.rg_lru"]], "rnn_hidden_size (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rnn_hidden_size"]], "rope_ratio (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rope_ratio"]], "rope_scaling (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rope_scaling"]], "rotary_base (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_base"]], "rotary_dim (attentionconfig attribute)": [[59, "modelopt.torch.export.model_config.AttentionConfig.rotary_dim"]], "rotary_pct (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_pct"]], "router (moeconfig attribute)": [[59, "modelopt.torch.export.model_config.MOEConfig.router"]], "self_attention (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.self_attention"]], "self_attention_layernorm (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.self_attention_layernorm"]], "seq_length (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.seq_length"]], "share_embedding_table (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.share_embedding_table"]], "tensor_parallel (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.tensor_parallel"]], "use_alibi (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.use_alibi"]], "use_cache (decoderlayerconfig attribute)": [[59, "modelopt.torch.export.model_config.DecoderLayerConfig.use_cache"]], "v (qkvconfig attribute)": [[59, "modelopt.torch.export.model_config.QKVConfig.v"]], "version (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.version"]], "vocab_embedding (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.vocab_embedding"]], "vocab_size (modelconfig attribute)": [[59, "modelopt.torch.export.model_config.ModelConfig.vocab_size"]], "vocab_size_padded (modelconfig property)": [[59, "modelopt.torch.export.model_config.ModelConfig.vocab_size_padded"]], "weight (convconfig attribute)": [[59, "modelopt.torch.export.model_config.ConvConfig.weight"]], "weight (embeddingconfig attribute)": [[59, "modelopt.torch.export.model_config.EmbeddingConfig.weight"]], "weight (layernormconfig attribute)": [[59, "modelopt.torch.export.model_config.LayernormConfig.weight"]], "weight (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.weight"]], "weight (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.weight"]], "weights_scaling_factor (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor"]], "weights_scaling_factor (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor"]], "weights_scaling_factor_2 (linearconfig attribute)": [[59, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor_2"]], "weights_scaling_factor_2 (qkvconfig property)": [[59, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor_2"]], "y_bias (recurrentconfig attribute)": [[59, "modelopt.torch.export.model_config.RecurrentConfig.y_bias"]], "export_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[60, "modelopt.torch.export.model_config_export.export_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_export": [[60, "module-modelopt.torch.export.model_config_export"]], "torch_to_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[60, "modelopt.torch.export.model_config_export.torch_to_tensorrt_llm_checkpoint"]], "from_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.from_quantized_weight"]], "merge_fc1_gate() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.merge_fc1_gate"]], "merge_qkv() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.merge_qkv"]], "model_config_from_dict() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.model_config_from_dict"]], "model_config_to_dict() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.model_config_to_dict"]], "modelopt.torch.export.model_config_utils": [[61, "module-modelopt.torch.export.model_config_utils"]], "naive_quantization() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.naive_quantization"]], "pack_linear_weights() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.pack_linear_weights"]], "pad_weights() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.pad_weights"]], "restore_model_config() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.restore_model_config"]], "split_config_and_weights() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.split_config_and_weights"]], "to_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[61, "modelopt.torch.export.model_config_utils.to_quantized_weight"]], "check_weight_shape_valid() (in module modelopt.torch.export.postprocess)": [[62, "modelopt.torch.export.postprocess.check_weight_shape_valid"]], "modelopt.torch.export.postprocess": [[62, "module-modelopt.torch.export.postprocess"]], "pad_embedding_lm_head() (in module modelopt.torch.export.postprocess)": [[62, "modelopt.torch.export.postprocess.pad_embedding_lm_head"]], "postprocess_model_config() (in module modelopt.torch.export.postprocess)": [[62, "modelopt.torch.export.postprocess.postprocess_model_config"]], "postprocess_tensors() (in module modelopt.torch.export.postprocess)": [[62, "modelopt.torch.export.postprocess.postprocess_tensors"]], "update_lm_head_quantization() (in module modelopt.torch.export.postprocess)": [[62, "modelopt.torch.export.postprocess.update_lm_head_quantization"]], "adjust_attn_amax_values() (in module modelopt.torch.export.scaling_factor_utils)": [[63, "modelopt.torch.export.scaling_factor_utils.adjust_attn_amax_values"]], "convert_state_dict_amax_to_scales() (in module modelopt.torch.export.scaling_factor_utils)": [[63, "modelopt.torch.export.scaling_factor_utils.convert_state_dict_amax_to_scales"]], "get_weights_scaling_factor_and_amax() (in module modelopt.torch.export.scaling_factor_utils)": [[63, "modelopt.torch.export.scaling_factor_utils.get_weights_scaling_factor_and_amax"]], "modelopt.torch.export.scaling_factor_utils": [[63, "module-modelopt.torch.export.scaling_factor_utils"]], "resmooth_and_get_scale_and_amax() (in module modelopt.torch.export.scaling_factor_utils)": [[63, "modelopt.torch.export.scaling_factor_utils.resmooth_and_get_scale_and_amax"]], "fusedgatedmlp (mlptype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.MLPType.FusedGatedMLP"]], "gatedmlp (mlptype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.MLPType.GatedMLP"]], "groupnorm (layernormtype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.GroupNorm"]], "layernorm (layernormtype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.LayerNorm"]], "layernormpositiontype (class in modelopt.torch.export.tensorrt_llm_type)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType"]], "layernormtype (class in modelopt.torch.export.tensorrt_llm_type)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormType"]], "mlp (mlptype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.MLPType.MLP"]], "mlptype (class in modelopt.torch.export.tensorrt_llm_type)": [[64, "modelopt.torch.export.tensorrt_llm_type.MLPType"]], "rmsnorm (layernormtype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.RmsNorm"]], "__new__() (layernormpositiontype method)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType.__new__"]], "__new__() (layernormtype method)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.__new__"]], "__new__() (mlptype method)": [[64, "modelopt.torch.export.tensorrt_llm_type.MLPType.__new__"]], "modelopt.torch.export.tensorrt_llm_type": [[64, "module-modelopt.torch.export.tensorrt_llm_type"]], "post_layernorm (layernormpositiontype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType.post_layernorm"]], "pre_layernorm (layernormpositiontype attribute)": [[64, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType.pre_layernorm"]], "convert_to_tensorrt_llm_config() (in module modelopt.torch.export.tensorrt_llm_utils)": [[65, "modelopt.torch.export.tensorrt_llm_utils.convert_to_tensorrt_llm_config"]], "is_tensorrt_llm_0_8_or_9() (in module modelopt.torch.export.tensorrt_llm_utils)": [[65, "modelopt.torch.export.tensorrt_llm_utils.is_tensorrt_llm_0_8_or_9"]], "modelopt.torch.export.tensorrt_llm_utils": [[65, "module-modelopt.torch.export.tensorrt_llm_utils"]], "prepare_enc_dec_decoder_layer() (in module modelopt.torch.export.tensorrt_llm_utils)": [[65, "modelopt.torch.export.tensorrt_llm_utils.prepare_enc_dec_decoder_layer"]], "prepare_enc_dec_export_dir() (in module modelopt.torch.export.tensorrt_llm_utils)": [[65, "modelopt.torch.export.tensorrt_llm_utils.prepare_enc_dec_export_dir"]], "weights_to_npz() (in module modelopt.torch.export.tensorrt_llm_utils)": [[65, "modelopt.torch.export.tensorrt_llm_utils.weights_to_npz"]], "convert_to_transformer_engine() (in module modelopt.torch.export.transformer_engine)": [[66, "modelopt.torch.export.transformer_engine.convert_to_transformer_engine"]], "modelopt.torch.export.transformer_engine": [[66, "module-modelopt.torch.export.transformer_engine"]], "export_hf() (in module modelopt.torch.export.unified_export_hf)": [[67, "modelopt.torch.export.unified_export_hf.export_hf"]], "export_hf_checkpoint() (in module modelopt.torch.export.unified_export_hf)": [[67, "modelopt.torch.export.unified_export_hf.export_hf_checkpoint"]], "modelopt.torch.export.unified_export_hf": [[67, "module-modelopt.torch.export.unified_export_hf"]], "export_to_vllm() (in module modelopt.torch.export.vllm)": [[68, "modelopt.torch.export.vllm.export_to_vllm"]], "modelopt.torch.export.vllm": [[68, "module-modelopt.torch.export.vllm"]], "modelopt.torch.nas": [[69, "module-modelopt.torch.nas"]], "modelopt.torch.nas.algorithms": [[70, "module-modelopt.torch.nas.algorithms"]], "profile() (in module modelopt.torch.nas.algorithms)": [[70, "modelopt.torch.nas.algorithms.profile"]], "search() (in module modelopt.torch.nas.algorithms)": [[70, "modelopt.torch.nas.algorithms.search"]], "autonaspatchmanager (class in modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.AutoNASPatchManager"]], "evolvesearcher (class in modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher"]], "iterativesearcher (class in modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher"]], "randomsearcher (class in modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.RandomSearcher"]], "after_search() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.after_search"]], "after_step() (evolvesearcher method)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.after_step"]], "after_step() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.after_step"]], "before_search() (evolvesearcher method)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.before_search"]], "before_search() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.before_search"]], "before_step() (evolvesearcher method)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.before_step"]], "before_step() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.before_step"]], "best (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.best"]], "best_history (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.best_history"]], "candidate (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.candidate"]], "candidates (evolvesearcher attribute)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.candidates"]], "constraints_func (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.constraints_func"]], "convert_autonas_searchspace() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.convert_autonas_searchspace"]], "convert_searchspace() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.convert_searchspace"]], "default_search_config (evolvesearcher property)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.default_search_config"]], "default_search_config (iterativesearcher property)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.default_search_config"]], "default_state_dict (evolvesearcher property)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.default_state_dict"]], "default_state_dict (iterativesearcher property)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.default_state_dict"]], "early_stop() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.early_stop"]], "export_searchspace() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.export_searchspace"]], "history (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.history"]], "iter_num (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.iter_num"]], "modelopt.torch.nas.autonas": [[71, "module-modelopt.torch.nas.autonas"]], "num_satisfied (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.num_satisfied"]], "population (evolvesearcher attribute)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.population"]], "restore_autonas_searchspace() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.restore_autonas_searchspace"]], "restore_export() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.restore_export"]], "restore_searchspace() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.restore_searchspace"]], "run_search() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.run_search"]], "run_step() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.run_step"]], "sample() (evolvesearcher method)": [[71, "modelopt.torch.nas.autonas.EvolveSearcher.sample"]], "sample() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.sample"]], "sample() (randomsearcher method)": [[71, "modelopt.torch.nas.autonas.RandomSearcher.sample"]], "sample_during_training (autonaspatchmanager property)": [[71, "modelopt.torch.nas.autonas.AutoNASPatchManager.sample_during_training"]], "samples (iterativesearcher attribute)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.samples"]], "sanitize_search_config() (iterativesearcher method)": [[71, "modelopt.torch.nas.autonas.IterativeSearcher.sanitize_search_config"]], "update_autonas_metadata() (in module modelopt.torch.nas.autonas)": [[71, "modelopt.torch.nas.autonas.update_autonas_metadata"]], "calib (exportconfig attribute)": [[72, "modelopt.torch.nas.config.ExportConfig.calib"]], "modelopt.torch.nas.config": [[72, "module-modelopt.torch.nas.config"]], "nn_batchnorm1d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_batchnorm1d"]], "nn_batchnorm2d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_batchnorm2d"]], "nn_batchnorm3d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_batchnorm3d"]], "nn_conv1d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_conv1d"]], "nn_conv2d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_conv2d"]], "nn_conv3d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_conv3d"]], "nn_convtranspose1d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_convtranspose1d"]], "nn_convtranspose2d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_convtranspose2d"]], "nn_convtranspose3d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_convtranspose3d"]], "nn_groupnorm (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_groupnorm"]], "nn_instancenorm1d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_instancenorm1d"]], "nn_instancenorm2d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_instancenorm2d"]], "nn_instancenorm3d (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_instancenorm3d"]], "nn_layernorm (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_layernorm"]], "nn_linear (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_linear"]], "nn_sequential (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_sequential"]], "nn_syncbatchnorm (autonasconfig attribute)": [[72, "modelopt.torch.nas.config.AutoNASConfig.nn_syncbatchnorm"]], "strict (exportconfig attribute)": [[72, "modelopt.torch.nas.config.ExportConfig.strict"]], "convert() (in module modelopt.torch.nas.conversion)": [[73, "modelopt.torch.nas.conversion.convert"]], "export() (in module modelopt.torch.nas.conversion)": [[73, "modelopt.torch.nas.conversion.export"]], "modelopt.torch.nas.conversion": [[73, "module-modelopt.torch.nas.conversion"]], "modelopt.torch.nas.hparams": [[74, "module-modelopt.torch.nas.hparams"]], "concattracedhp (class in modelopt.torch.nas.hparams.concat)": [[75, "modelopt.torch.nas.hparams.concat.ConcatTracedHp"]], "active (concattracedhp property)": [[75, "modelopt.torch.nas.hparams.concat.ConcatTracedHp.active"]], "active_slice (concattracedhp property)": [[75, "modelopt.torch.nas.hparams.concat.ConcatTracedHp.active_slice"]], "modelopt.torch.nas.hparams.concat": [[75, "module-modelopt.torch.nas.hparams.concat"]], "depthhparam (class in modelopt.torch.nas.hparams.container)": [[76, "modelopt.torch.nas.hparams.container.DepthHparam"]], "modelopt.torch.nas.hparams.container": [[76, "module-modelopt.torch.nas.hparams.container"]], "autonasmodedescriptor (class in modelopt.torch.nas.mode)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor"]], "exportmodedescriptor (class in modelopt.torch.nas.mode)": [[77, "modelopt.torch.nas.mode.ExportModeDescriptor"]], "config_class (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.config_class"]], "config_class (exportmodedescriptor property)": [[77, "modelopt.torch.nas.mode.ExportModeDescriptor.config_class"]], "convert (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.convert"]], "convert (exportmodedescriptor property)": [[77, "modelopt.torch.nas.mode.ExportModeDescriptor.convert"]], "export_mode (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.export_mode"]], "is_export_mode (exportmodedescriptor property)": [[77, "modelopt.torch.nas.mode.ExportModeDescriptor.is_export_mode"]], "modelopt.torch.nas.mode": [[77, "module-modelopt.torch.nas.mode"]], "name (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.name"]], "name (exportmodedescriptor property)": [[77, "modelopt.torch.nas.mode.ExportModeDescriptor.name"]], "next_modes (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.next_modes"]], "restore (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.restore"]], "restore (exportmodedescriptor property)": [[77, "modelopt.torch.nas.mode.ExportModeDescriptor.restore"]], "search_algorithm (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.search_algorithm"]], "update_for_new_mode (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.update_for_new_mode"]], "update_for_save (autonasmodedescriptor property)": [[77, "modelopt.torch.nas.mode.AutoNASModeDescriptor.update_for_save"]], "modelopt.torch.nas.modules": [[78, "module-modelopt.torch.nas.modules"]], "modelopt.torch.nas.modules.container": [[79, "module-modelopt.torch.nas.modules.container"]], "modelopt.torch.nas.modules.conv": [[80, "module-modelopt.torch.nas.modules.conv"]], "modelopt.torch.nas.modules.linear": [[81, "module-modelopt.torch.nas.modules.linear"]], "modelopt.torch.nas.modules.norm": [[82, "module-modelopt.torch.nas.modules.norm"]], "get_sliced_tensor() (in module modelopt.torch.nas.modules.utils)": [[83, "modelopt.torch.nas.modules.utils.get_sliced_tensor"]], "get_sliced_tensor_by_slices() (in module modelopt.torch.nas.modules.utils)": [[83, "modelopt.torch.nas.modules.utils.get_sliced_tensor_by_slices"]], "modelopt.torch.nas.modules.utils": [[83, "module-modelopt.torch.nas.modules.utils"]], "modelopt.torch.nas.plugins": [[84, "module-modelopt.torch.nas.plugins"]], "modelopt.torch.nas.registry": [[85, "module-modelopt.torch.nas.registry"]], "searchspace (class in modelopt.torch.nas.search_space)": [[86, "modelopt.torch.nas.search_space.SearchSpace"]], "__init__() (searchspace method)": [[86, "modelopt.torch.nas.search_space.SearchSpace.__init__"]], "export() (searchspace method)": [[86, "modelopt.torch.nas.search_space.SearchSpace.export"]], "generate() (searchspace method)": [[86, "modelopt.torch.nas.search_space.SearchSpace.generate"]], "generate_search_space() (in module modelopt.torch.nas.search_space)": [[86, "modelopt.torch.nas.search_space.generate_search_space"]], "modelopt.torch.nas.search_space": [[86, "module-modelopt.torch.nas.search_space"]], "print_summary() (searchspace method)": [[86, "modelopt.torch.nas.search_space.SearchSpace.print_summary"]], "sample() (searchspace method)": [[86, "modelopt.torch.nas.search_space.SearchSpace.sample"]], "sort_parameters() (searchspace method)": [[86, "modelopt.torch.nas.search_space.SearchSpace.sort_parameters"]], "tracedhp (class in modelopt.torch.nas.traced_hp)": [[87, "modelopt.torch.nas.traced_hp.TracedHp"]], "tracedhpregistry (class in modelopt.torch.nas.traced_hp)": [[87, "modelopt.torch.nas.traced_hp.TracedHpRegistry"]], "get() (tracedhpregistry class method)": [[87, "modelopt.torch.nas.traced_hp.TracedHpRegistry.get"]], "initialize_from() (tracedhp class method)": [[87, "modelopt.torch.nas.traced_hp.TracedHp.initialize_from"]], "initialize_from() (tracedhpregistry class method)": [[87, "modelopt.torch.nas.traced_hp.TracedHpRegistry.initialize_from"]], "modelopt.torch.nas.traced_hp": [[87, "module-modelopt.torch.nas.traced_hp"]], "register() (tracedhpregistry class method)": [[87, "modelopt.torch.nas.traced_hp.TracedHpRegistry.register"]], "resolve_dependencies() (tracedhp method)": [[87, "modelopt.torch.nas.traced_hp.TracedHp.resolve_dependencies"]], "unregister() (tracedhpregistry class method)": [[87, "modelopt.torch.nas.traced_hp.TracedHpRegistry.unregister"]], "__init__() (enable_modelopt_patches method)": [[88, "modelopt.torch.nas.utils.enable_modelopt_patches.__init__"]], "__init__() (no_modelopt_patches method)": [[88, "modelopt.torch.nas.utils.no_modelopt_patches.__init__"]], "__init__() (set_modelopt_patches_enabled method)": [[88, "modelopt.torch.nas.utils.set_modelopt_patches_enabled.__init__"]], "clone() (set_modelopt_patches_enabled method)": [[88, "modelopt.torch.nas.utils.set_modelopt_patches_enabled.clone"]], "enable_modelopt_patches (class in modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.enable_modelopt_patches"]], "get_subnet_config() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.get_subnet_config"]], "inference_flops() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.inference_flops"]], "is_modelopt_patches_enabled() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.is_modelopt_patches_enabled"]], "modelopt.torch.nas.utils": [[88, "module-modelopt.torch.nas.utils"]], "no_modelopt_patches (class in modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.no_modelopt_patches"]], "print_search_space_summary() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.print_search_space_summary"]], "replace_forward() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.replace_forward"]], "sample() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.sample"]], "select() (in module modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.select"]], "set_modelopt_patches_enabled (class in modelopt.torch.nas.utils)": [[88, "modelopt.torch.nas.utils.set_modelopt_patches_enabled"]], "modelopt.torch.opt": [[89, "module-modelopt.torch.opt"]], "modeloptfield() (in module modelopt.torch.opt.config)": [[90, "modelopt.torch.opt.config.ModeloptField"]], "customize_rule() (modeloptbaserule class method)": [[90, "modelopt.torch.opt.config.ModeloptBaseRule.customize_rule"]], "get() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.get"]], "get_field_name_from_key() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.get_field_name_from_key"]], "get_kwargs_for_create_model_with_rules() (in module modelopt.torch.opt.config)": [[90, "modelopt.torch.opt.config.get_kwargs_for_create_model_with_rules"]], "get_rule_type() (modeloptbaserule class method)": [[90, "modelopt.torch.opt.config.ModeloptBaseRule.get_rule_type"]], "items() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.items"]], "keys() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.keys"]], "model_dump() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump"]], "model_dump_json() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump_json"]], "modelopt.torch.opt.config": [[90, "module-modelopt.torch.opt.config"]], "register_default() (modeloptbaseruleconfig class method)": [[90, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.register_default"]], "unregister_default() (modeloptbaseruleconfig class method)": [[90, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.unregister_default"]], "update() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.update"]], "validate_rule() (modeloptbaserule class method)": [[90, "modelopt.torch.opt.config.ModeloptBaseRule.validate_rule"]], "values() (modeloptbaseconfig method)": [[90, "modelopt.torch.opt.config.ModeloptBaseConfig.values"]], "modeloptstatemanager (class in modelopt.torch.opt.conversion)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager"]], "__init__() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.__init__"]], "add_mode() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.add_mode"]], "apply_mode() (in module modelopt.torch.opt.conversion)": [[91, "modelopt.torch.opt.conversion.apply_mode"]], "check_mode() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.check_mode"]], "get_config_class() (modeloptstatemanager static method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.get_config_class"]], "has_state (modeloptstatemanager property)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.has_state"]], "is_converted() (modeloptstatemanager class method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.is_converted"]], "last_mode (modeloptstatemanager property)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.last_mode"]], "load_state_dict() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.load_state_dict"]], "modelopt.torch.opt.conversion": [[91, "module-modelopt.torch.opt.conversion"]], "modelopt_state() (in module modelopt.torch.opt.conversion)": [[91, "modelopt.torch.opt.conversion.modelopt_state"]], "modes_with_states() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.modes_with_states"]], "restore() (in module modelopt.torch.opt.conversion)": [[91, "modelopt.torch.opt.conversion.restore"]], "restore_from_modelopt_state() (in module modelopt.torch.opt.conversion)": [[91, "modelopt.torch.opt.conversion.restore_from_modelopt_state"]], "save() (in module modelopt.torch.opt.conversion)": [[91, "modelopt.torch.opt.conversion.save"]], "state_dict() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.state_dict"]], "transfer_state_dict() (modeloptstatemanager class method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.transfer_state_dict"]], "update_last_state_before_new_mode() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_new_mode"]], "update_last_state_before_save() (modeloptstatemanager method)": [[91, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_save"]], "dynamicmodule (class in modelopt.torch.opt.dynamic)": [[92, "modelopt.torch.opt.dynamic.DynamicModule"]], "dynamicspace (class in modelopt.torch.opt.dynamic)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace"]], "__init__() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.__init__"]], "__init__() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.__init__"]], "config() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.config"]], "convert() (dynamicmodule class method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.convert"]], "convert_to_dynamic() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.convert_to_dynamic"]], "export() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.export"]], "export() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.export"]], "extra_repr() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.extra_repr"]], "force_assign() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.force_assign"]], "freeze() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.freeze"]], "get_hparam() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.get_hparam"]], "get_hparam() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.get_hparam"]], "is_configurable() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.is_configurable"]], "is_dynamic() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.is_dynamic"]], "modelopt.torch.opt.dynamic": [[92, "module-modelopt.torch.opt.dynamic"]], "modify() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.modify"]], "named_dynamic_modules() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.named_dynamic_modules"]], "named_hparams() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.named_hparams"]], "named_hparams() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.named_hparams"]], "original_cls (dynamicmodule property)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.original_cls"]], "reset_dynamic_attributes() (dynamicmodule method)": [[92, "modelopt.torch.opt.dynamic.DynamicModule.reset_dynamic_attributes"]], "select() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.select"]], "size() (dynamicspace method)": [[92, "modelopt.torch.opt.dynamic.DynamicSpace.size"]], "activeslice (hparam attribute)": [[93, "modelopt.torch.opt.hparam.Hparam.ActiveSlice"]], "hparam (class in modelopt.torch.opt.hparam)": [[93, "modelopt.torch.opt.hparam.Hparam"]], "importance (hparam attribute)": [[93, "modelopt.torch.opt.hparam.Hparam.Importance"]], "importanceestimator (hparam attribute)": [[93, "modelopt.torch.opt.hparam.Hparam.ImportanceEstimator"]], "__init__() (hparam method)": [[93, "modelopt.torch.opt.hparam.Hparam.__init__"]], "active (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.active"]], "active_slice (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.active_slice"]], "choices (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.choices"]], "enforce_order() (hparam method)": [[93, "modelopt.torch.opt.hparam.Hparam.enforce_order"]], "importance (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.importance"]], "is_configurable (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.is_configurable"]], "is_sortable (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.is_sortable"]], "max (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.max"]], "min (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.min"]], "modelopt.torch.opt.hparam": [[93, "module-modelopt.torch.opt.hparam"]], "original (hparam property)": [[93, "modelopt.torch.opt.hparam.Hparam.original"]], "register_importance() (hparam method)": [[93, "modelopt.torch.opt.hparam.Hparam.register_importance"]], "modelopt.torch.opt.mode": [[94, "module-modelopt.torch.opt.mode"]], "modelopt.torch.opt.plugins": [[95, "module-modelopt.torch.opt.plugins"]], "enable_huggingface_checkpointing() (in module modelopt.torch.opt.plugins.huggingface)": [[96, "modelopt.torch.opt.plugins.huggingface.enable_huggingface_checkpointing"]], "modelopt.torch.opt.plugins.huggingface": [[96, "module-modelopt.torch.opt.plugins.huggingface"]], "basesearcher (class in modelopt.torch.opt.searcher)": [[97, "modelopt.torch.opt.searcher.BaseSearcher"]], "__init__() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.__init__"]], "after_search() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.after_search"]], "before_search() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.before_search"]], "config (basesearcher attribute)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.config"]], "constraints (basesearcher attribute)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.constraints"]], "construct_forward_loop() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.construct_forward_loop"]], "default_search_config (basesearcher property)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.default_search_config"]], "default_state_dict (basesearcher property)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.default_state_dict"]], "deployment (basesearcher attribute)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.deployment"]], "dummy_input (basesearcher attribute)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.dummy_input"]], "eval_score() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.eval_score"]], "forward_loop (basesearcher attribute)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.forward_loop"]], "has_score (basesearcher property)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.has_score"]], "load_search_checkpoint() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.load_search_checkpoint"]], "model (basesearcher attribute)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.model"]], "modelopt.torch.opt.searcher": [[97, "module-modelopt.torch.opt.searcher"]], "reset_search() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.reset_search"]], "run_search() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.run_search"]], "sanitize_search_config() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.sanitize_search_config"]], "save_search_checkpoint() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.save_search_checkpoint"]], "search() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.search"]], "state_dict() (basesearcher method)": [[97, "modelopt.torch.opt.searcher.BaseSearcher.state_dict"]], "get_hparam() (in module modelopt.torch.opt.utils)": [[98, "modelopt.torch.opt.utils.get_hparam"]], "is_configurable() (in module modelopt.torch.opt.utils)": [[98, "modelopt.torch.opt.utils.is_configurable"]], "is_dynamic() (in module modelopt.torch.opt.utils)": [[98, "modelopt.torch.opt.utils.is_dynamic"]], "modelopt.torch.opt.utils": [[98, "module-modelopt.torch.opt.utils"]], "named_dynamic_modules() (in module modelopt.torch.opt.utils)": [[98, "modelopt.torch.opt.utils.named_dynamic_modules"]], "named_hparams() (in module modelopt.torch.opt.utils)": [[98, "modelopt.torch.opt.utils.named_hparams"]], "search_space_size() (in module modelopt.torch.opt.utils)": [[98, "modelopt.torch.opt.utils.search_space_size"]], "modelopt.torch.prune": [[99, "module-modelopt.torch.prune"]], "modelopt.torch.prune.config": [[100, "module-modelopt.torch.prune.config"]], "nn_batchnorm1d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_batchnorm1d"]], "nn_batchnorm1d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_batchnorm1d"]], "nn_batchnorm2d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_batchnorm2d"]], "nn_batchnorm2d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_batchnorm2d"]], "nn_batchnorm3d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_batchnorm3d"]], "nn_batchnorm3d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_batchnorm3d"]], "nn_conv1d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_conv1d"]], "nn_conv1d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_conv1d"]], "nn_conv2d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_conv2d"]], "nn_conv2d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_conv2d"]], "nn_conv3d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_conv3d"]], "nn_conv3d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_conv3d"]], "nn_convtranspose1d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_convtranspose1d"]], "nn_convtranspose1d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_convtranspose1d"]], "nn_convtranspose2d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_convtranspose2d"]], "nn_convtranspose2d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_convtranspose2d"]], "nn_convtranspose3d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_convtranspose3d"]], "nn_convtranspose3d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_convtranspose3d"]], "nn_groupnorm (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_groupnorm"]], "nn_groupnorm (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_groupnorm"]], "nn_instancenorm1d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_instancenorm1d"]], "nn_instancenorm1d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_instancenorm1d"]], "nn_instancenorm2d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_instancenorm2d"]], "nn_instancenorm2d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_instancenorm2d"]], "nn_instancenorm3d (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_instancenorm3d"]], "nn_instancenorm3d (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_instancenorm3d"]], "nn_layernorm (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_layernorm"]], "nn_layernorm (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_layernorm"]], "nn_linear (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_linear"]], "nn_linear (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_linear"]], "nn_syncbatchnorm (fastnasconfig attribute)": [[100, "modelopt.torch.prune.config.FastNASConfig.nn_syncbatchnorm"]], "nn_syncbatchnorm (gradnasconfig attribute)": [[100, "modelopt.torch.prune.config.GradNASConfig.nn_syncbatchnorm"]], "binarysearcher (class in modelopt.torch.prune.fastnas)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher"]], "fastnaspatchmanager (class in modelopt.torch.prune.fastnas)": [[101, "modelopt.torch.prune.fastnas.FastNASPatchManager"]], "after_step() (binarysearcher method)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.after_step"]], "before_search() (binarysearcher method)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.before_search"]], "before_step() (binarysearcher method)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.before_step"]], "convert_fastnas_searchspace() (in module modelopt.torch.prune.fastnas)": [[101, "modelopt.torch.prune.fastnas.convert_fastnas_searchspace"]], "default_state_dict (binarysearcher property)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.default_state_dict"]], "early_stop() (binarysearcher method)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.early_stop"]], "hparam_names_for_search (binarysearcher property)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.hparam_names_for_search"]], "hparam_types_for_search (binarysearcher property)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.hparam_types_for_search"]], "load_search_checkpoint() (binarysearcher method)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.load_search_checkpoint"]], "max_degrade (binarysearcher attribute)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.max_degrade"]], "middle_value (binarysearcher attribute)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.middle_value"]], "min_degrade (binarysearcher attribute)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.min_degrade"]], "modelopt.torch.prune.fastnas": [[101, "module-modelopt.torch.prune.fastnas"]], "original_score (binarysearcher attribute)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.original_score"]], "restore_fastnas_searchspace() (in module modelopt.torch.prune.fastnas)": [[101, "modelopt.torch.prune.fastnas.restore_fastnas_searchspace"]], "sample() (binarysearcher method)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.sample"]], "sample_during_training (fastnaspatchmanager property)": [[101, "modelopt.torch.prune.fastnas.FastNASPatchManager.sample_during_training"]], "sensitivity_map (binarysearcher attribute)": [[101, "modelopt.torch.prune.fastnas.BinarySearcher.sensitivity_map"]], "gradientbinarysearcher (class in modelopt.torch.prune.gradnas)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher"]], "gradientdatamanager (class in modelopt.torch.prune.gradnas)": [[102, "modelopt.torch.prune.gradnas.GradientDataManager"]], "setup_gradient_func (gradientbinarysearcher attribute)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher.SETUP_GRADIENT_FUNC"]], "__init__() (gradientdatamanager method)": [[102, "modelopt.torch.prune.gradnas.GradientDataManager.__init__"]], "before_search() (gradientbinarysearcher method)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher.before_search"]], "default_search_config (gradientbinarysearcher property)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher.default_search_config"]], "gradnas_score_func() (gradientbinarysearcher static method)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher.gradnas_score_func"]], "hparam_names_for_search (gradientbinarysearcher property)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher.hparam_names_for_search"]], "modelopt.torch.prune.gradnas": [[102, "module-modelopt.torch.prune.gradnas"]], "process_gradient() (gradientdatamanager method)": [[102, "modelopt.torch.prune.gradnas.GradientDataManager.process_gradient"]], "sanitize_search_config() (gradientbinarysearcher method)": [[102, "modelopt.torch.prune.gradnas.GradientBinarySearcher.sanitize_search_config"]], "score (gradientdatamanager property)": [[102, "modelopt.torch.prune.gradnas.GradientDataManager.score"]], "mcoregptminitronsearcher (class in modelopt.torch.prune.mcore_gpt_minitron)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher"]], "supported_hparams (mcoregptminitronsearcher attribute)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.SUPPORTED_HPARAMS"]], "before_search() (mcoregptminitronsearcher method)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.before_search"]], "default_search_config (mcoregptminitronsearcher property)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.default_search_config"]], "default_state_dict (mcoregptminitronsearcher property)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.default_state_dict"]], "modelopt.torch.prune.mcore_gpt_minitron": [[103, "module-modelopt.torch.prune.mcore_gpt_minitron"]], "run_search() (mcoregptminitronsearcher method)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.run_search"]], "sanitize_search_config() (mcoregptminitronsearcher method)": [[103, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.sanitize_search_config"]], "fastnasmodedescriptor (class in modelopt.torch.prune.mode)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor"]], "gradnasmodedescriptor (class in modelopt.torch.prune.mode)": [[104, "modelopt.torch.prune.mode.GradNASModeDescriptor"]], "mcoregptminitronmodedescriptor (class in modelopt.torch.prune.mode)": [[104, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor"]], "config_class (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.config_class"]], "config_class (gradnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.GradNASModeDescriptor.config_class"]], "config_class (mcoregptminitronmodedescriptor property)": [[104, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor.config_class"]], "convert (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.convert"]], "export_mode (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.export_mode"]], "modelopt.torch.prune.mode": [[104, "module-modelopt.torch.prune.mode"]], "name (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.name"]], "name (gradnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.GradNASModeDescriptor.name"]], "name (mcoregptminitronmodedescriptor property)": [[104, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor.name"]], "next_modes (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.next_modes"]], "restore (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.restore"]], "search_algorithm (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.search_algorithm"]], "search_algorithm (gradnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.GradNASModeDescriptor.search_algorithm"]], "search_algorithm (mcoregptminitronmodedescriptor property)": [[104, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor.search_algorithm"]], "update_for_new_mode (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.update_for_new_mode"]], "update_for_save (fastnasmodedescriptor property)": [[104, "modelopt.torch.prune.mode.FastNASModeDescriptor.update_for_save"]], "modelopt.torch.prune.plugins": [[105, "module-modelopt.torch.prune.plugins"]], "modelopt.torch.prune.pruning": [[106, "module-modelopt.torch.prune.pruning"]], "prune() (in module modelopt.torch.prune.pruning)": [[106, "modelopt.torch.prune.pruning.prune"]], "modelopt.torch.quantization": [[107, "module-modelopt.torch.quantization"]], "autoquantizesearcher (class in modelopt.torch.quantization.algorithms)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher"]], "quantrecipe (class in modelopt.torch.quantization.algorithms)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipe"]], "quantrecipehparam (class in modelopt.torch.quantization.algorithms)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipeHparam"]], "__init__() (quantrecipe method)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipe.__init__"]], "__init__() (quantrecipehparam method)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.__init__"]], "active (quantrecipehparam property)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.active"]], "before_search() (autoquantizesearcher method)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.before_search"]], "candidate_stats (autoquantizesearcher attribute)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.candidate_stats"]], "compression (quantrecipe property)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipe.compression"]], "config (quantrecipe property)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipe.config"]], "default_search_config (autoquantizesearcher property)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.default_search_config"]], "default_state_dict (autoquantizesearcher property)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.default_state_dict"]], "disable_folding_pqs_to_weights() (quantrecipe static method)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipe.disable_folding_pqs_to_weights"]], "fold_pqs_to_weights() (quantrecipe static method)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipe.fold_pqs_to_weights"]], "gradient_checkpointing_enable_contexts (autoquantizesearcher attribute)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.gradient_checkpointing_enable_contexts"]], "importance (quantrecipehparam property)": [[108, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.importance"]], "insert_hparams_after_merge_rules() (autoquantizesearcher class method)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.insert_hparams_after_merge_rules"]], "modelopt.torch.quantization.algorithms": [[108, "module-modelopt.torch.quantization.algorithms"]], "register_gradient_checkpointing_enable_context() (autoquantizesearcher class method)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.register_gradient_checkpointing_enable_context"]], "rules (autoquantizesearcher attribute)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.rules"]], "run_search() (autoquantizesearcher method)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.run_search"]], "sanitize_search_config() (autoquantizesearcher method)": [[108, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.sanitize_search_config"]], "modelopt.torch.quantization.calib": [[109, "module-modelopt.torch.quantization.calib"]], "modelopt.torch.quantization.calib.calibrator": [[110, "module-modelopt.torch.quantization.calib.calibrator"]], "histogramcalibrator (class in modelopt.torch.quantization.calib.histogram)": [[111, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator"]], "__init__() (histogramcalibrator method)": [[111, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.__init__"]], "calibrate_weights() (in module modelopt.torch.quantization.calib.histogram)": [[111, "modelopt.torch.quantization.calib.histogram.calibrate_weights"]], "collect() (histogramcalibrator method)": [[111, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.collect"]], "compute_amax() (histogramcalibrator method)": [[111, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.histogram": [[111, "module-modelopt.torch.quantization.calib.histogram"]], "reset() (histogramcalibrator method)": [[111, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.reset"]], "maxcalibrator (class in modelopt.torch.quantization.calib.max)": [[112, "modelopt.torch.quantization.calib.max.MaxCalibrator"]], "__init__() (maxcalibrator method)": [[112, "modelopt.torch.quantization.calib.max.MaxCalibrator.__init__"]], "amaxs (maxcalibrator property)": [[112, "modelopt.torch.quantization.calib.max.MaxCalibrator.amaxs"]], "collect() (maxcalibrator method)": [[112, "modelopt.torch.quantization.calib.max.MaxCalibrator.collect"]], "compute_amax() (maxcalibrator method)": [[112, "modelopt.torch.quantization.calib.max.MaxCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.max": [[112, "module-modelopt.torch.quantization.calib.max"]], "reset() (maxcalibrator method)": [[112, "modelopt.torch.quantization.calib.max.MaxCalibrator.reset"]], "additional_algorithm (realquantizeconfig attribute)": [[113, "modelopt.torch.quantization.config.RealQuantizeConfig.additional_algorithm"]], "algorithm (quantizeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizeConfig.algorithm"]], "alpha (smoothquantcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.SmoothQuantCalibConfig.alpha"]], "alpha_step (awqlitecalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQLiteCalibConfig.alpha_step"]], "axis (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.axis"]], "block_sizes (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.block_sizes"]], "calibrator (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.calibrator"]], "debug (awqclipcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQClipCalibConfig.debug"]], "debug (awqfullcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQFullCalibConfig.debug"]], "debug (awqlitecalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQLiteCalibConfig.debug"]], "enable (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.enable"]], "fake_quant (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.fake_quant"]], "learn_amax (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.learn_amax"]], "max_co_batch_size (awqclipcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQClipCalibConfig.max_co_batch_size"]], "max_tokens_per_batch (awqclipcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQClipCalibConfig.max_tokens_per_batch"]], "method (quantizealgorithmconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizeAlgorithmConfig.method"]], "min_clip_ratio (awqclipcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQClipCalibConfig.min_clip_ratio"]], "modelopt.torch.quantization.config": [[113, "module-modelopt.torch.quantization.config"]], "narrow_range (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.narrow_range"]], "num_bits (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.num_bits"]], "quant_cfg (quantizeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizeConfig.quant_cfg"]], "shrink_step (awqclipcalibconfig attribute)": [[113, "modelopt.torch.quantization.config.AWQClipCalibConfig.shrink_step"]], "trt_high_precision_dtype (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.trt_high_precision_dtype"]], "type (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.type"]], "unsigned (quantizerattributeconfig attribute)": [[113, "modelopt.torch.quantization.config.QuantizerAttributeConfig.unsigned"]], "modelopt.torch.quantization.conversion": [[114, "module-modelopt.torch.quantization.conversion"]], "register() (in module modelopt.torch.quantization.conversion)": [[114, "modelopt.torch.quantization.conversion.register"]], "replace_quant_module() (in module modelopt.torch.quantization.conversion)": [[114, "modelopt.torch.quantization.conversion.replace_quant_module"]], "set_quantizer_attribute() (in module modelopt.torch.quantization.conversion)": [[114, "modelopt.torch.quantization.conversion.set_quantizer_attribute"]], "set_quantizer_by_cfg() (in module modelopt.torch.quantization.conversion)": [[114, "modelopt.torch.quantization.conversion.set_quantizer_by_cfg"]], "set_quantizer_by_cfg_context() (in module modelopt.torch.quantization.conversion)": [[114, "modelopt.torch.quantization.conversion.set_quantizer_by_cfg_context"]], "unregister() (in module modelopt.torch.quantization.conversion)": [[114, "modelopt.torch.quantization.conversion.unregister"]], "get_cuda_ext() (in module modelopt.torch.quantization.extensions)": [[115, "modelopt.torch.quantization.extensions.get_cuda_ext"]], "get_cuda_ext_fp8() (in module modelopt.torch.quantization.extensions)": [[115, "modelopt.torch.quantization.extensions.get_cuda_ext_fp8"]], "modelopt.torch.quantization.extensions": [[115, "module-modelopt.torch.quantization.extensions"]], "quantizeexportmodedescriptor (class in modelopt.torch.quantization.mode)": [[116, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor"]], "quantizemodedescriptor (class in modelopt.torch.quantization.mode)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor"]], "config_class (quantizeexportmodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.config_class"]], "config_class (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.config_class"]], "convert (quantizeexportmodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.convert"]], "convert (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.convert"]], "export_mode (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.export_mode"]], "is_export_mode (quantizeexportmodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.is_export_mode"]], "modelopt.torch.quantization.mode": [[116, "module-modelopt.torch.quantization.mode"]], "name (quantizeexportmodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.name"]], "name (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.name"]], "next_modes (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.next_modes"]], "restore (quantizeexportmodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.restore"]], "restore (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.restore"]], "update_for_new_mode (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_new_mode"]], "update_for_save (quantizemodedescriptor property)": [[116, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_save"]], "calibrate() (in module modelopt.torch.quantization.model_calib)": [[117, "modelopt.torch.quantization.model_calib.calibrate"]], "modelopt.torch.quantization.model_calib": [[117, "module-modelopt.torch.quantization.model_calib"]], "postprocess_amax() (in module modelopt.torch.quantization.model_calib)": [[117, "modelopt.torch.quantization.model_calib.postprocess_amax"]], "auto_quantize() (in module modelopt.torch.quantization.model_quant)": [[118, "modelopt.torch.quantization.model_quant.auto_quantize"]], "disable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[118, "modelopt.torch.quantization.model_quant.disable_quantizer"]], "enable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[118, "modelopt.torch.quantization.model_quant.enable_quantizer"]], "fold_weight() (in module modelopt.torch.quantization.model_quant)": [[118, "modelopt.torch.quantization.model_quant.fold_weight"]], "modelopt.torch.quantization.model_quant": [[118, "module-modelopt.torch.quantization.model_quant"]], "print_quant_summary() (in module modelopt.torch.quantization.model_quant)": [[118, "modelopt.torch.quantization.model_quant.print_quant_summary"]], "quantize() (in module modelopt.torch.quantization.model_quant)": [[118, "modelopt.torch.quantization.model_quant.quantize"]], "modelopt.torch.quantization.nn": [[119, "module-modelopt.torch.quantization.nn"]], "clipfunction (class in modelopt.torch.quantization.nn.functional)": [[120, "modelopt.torch.quantization.nn.functional.ClipFunction"]], "backward() (clipfunction static method)": [[120, "modelopt.torch.quantization.nn.functional.ClipFunction.backward"]], "forward() (clipfunction static method)": [[120, "modelopt.torch.quantization.nn.functional.ClipFunction.forward"]], "modelopt.torch.quantization.nn.functional": [[120, "module-modelopt.torch.quantization.nn.functional"]], "modelopt.torch.quantization.nn.modules": [[121, "module-modelopt.torch.quantization.nn.modules"]], "clip (class in modelopt.torch.quantization.nn.modules.clip)": [[122, "modelopt.torch.quantization.nn.modules.clip.Clip"]], "__init__() (clip method)": [[122, "modelopt.torch.quantization.nn.modules.clip.Clip.__init__"]], "forward() (clip method)": [[122, "modelopt.torch.quantization.nn.modules.clip.Clip.forward"]], "modelopt.torch.quantization.nn.modules.clip": [[122, "module-modelopt.torch.quantization.nn.modules.clip"]], "modelopt.torch.quantization.nn.modules.quant_activations": [[123, "module-modelopt.torch.quantization.nn.modules.quant_activations"]], "modelopt.torch.quantization.nn.modules.quant_batchnorm": [[124, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"]], "conv1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.Conv1d"]], "conv2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.Conv2d"]], "conv3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.Conv3d"]], "convtranspose1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose1d"]], "convtranspose2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose2d"]], "convtranspose3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose3d"]], "quantconv1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d"]], "quantconv2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d"]], "quantconv3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d"]], "quantconvtranspose1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d"]], "quantconvtranspose2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d"]], "quantconvtranspose3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d"]], "default_quant_desc_weight (quantconv1d attribute)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv2d attribute)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv3d attribute)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose1d attribute)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose2d attribute)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose3d attribute)": [[125, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[125, "module-modelopt.torch.quantization.nn.modules.quant_conv"]], "quantinstancenorm1d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[126, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm1d"]], "quantinstancenorm2d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[126, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm2d"]], "quantinstancenorm3d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[126, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[126, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"]], "linear (in module modelopt.torch.quantization.nn.modules.quant_linear)": [[127, "modelopt.torch.quantization.nn.modules.quant_linear.Linear"]], "quantlinear (class in modelopt.torch.quantization.nn.modules.quant_linear)": [[127, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear"]], "default_quant_desc_weight (quantlinear attribute)": [[127, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[127, "module-modelopt.torch.quantization.nn.modules.quant_linear"]], "quantinputbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase"]], "quantlinearconvbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase"]], "default_quant_desc_input (quantinputbase attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_input"]], "default_quant_desc_output (quantinputbase attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_output"]], "default_quant_desc_weight (quantlinearconvbase attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.default_quant_desc_weight"]], "forward() (quantinputbase method)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.forward"]], "forward() (quantlinearconvbase method)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.forward"]], "initialize_quantizer_with_dummy_states() (quantlinearconvbase static method)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.initialize_quantizer_with_dummy_states"]], "input_quantizer (quantinputbase attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.input_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module": [[128, "module-modelopt.torch.quantization.nn.modules.quant_module"]], "output_quantizer (quantinputbase attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.output_quantizer"]], "quantize_weight() (quantlinearconvbase method)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.quantize_weight"]], "weight_quantizer (quantlinearconvbase attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.weight_quantizer"]], "adaptiveavgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool1d"]], "adaptiveavgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool2d"]], "adaptiveavgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool3d"]], "avgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool1d"]], "avgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool2d"]], "avgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool3d"]], "maxpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool1d"]], "maxpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool2d"]], "maxpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool3d"]], "quantadaptiveavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool1d"]], "quantadaptiveavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool2d"]], "quantadaptiveavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool3d"]], "quantavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool1d"]], "quantavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool2d"]], "quantavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool3d"]], "quantmaxpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool1d"]], "quantmaxpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool2d"]], "quantmaxpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[129, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[129, "module-modelopt.torch.quantization.nn.modules.quant_pooling"]], "quantrnnbase (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase"]], "quantrnnfullbase (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNFullBase"]], "rnnlayerforward (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward"]], "vfrnnforward (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward"]], "__init__() (rnnlayerforward method)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward.__init__"]], "__init__() (vfrnnforward method)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward.__init__"]], "all_input_quantizers_disabled (quantrnnbase property)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.all_input_quantizers_disabled"]], "default_quant_desc_input (quantrnnbase attribute)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.default_quant_desc_input"]], "default_quant_desc_weight (quantrnnbase attribute)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.default_quant_desc_weight"]], "forward() (quantrnnbase method)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.forward"]], "forward() (vfrnnforward method)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward.forward"]], "functionals_to_replace (quantrnnbase property)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.functionals_to_replace"]], "get_quantized_rnn_layer_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_forward"]], "get_quantized_rnn_layer_variable_len_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_variable_len_forward"]], "get_quantized_rnn_layer_variable_len_reverse_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_variable_len_reverse_forward"]], "lstm_cell_with_proj() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.lstm_cell_with_proj"]], "modelopt.torch.quantization.nn.modules.quant_rnn": [[130, "module-modelopt.torch.quantization.nn.modules.quant_rnn"]], "quantize_weight() (quantrnnbase method)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.quantize_weight"]], "quantized_cell_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.quantized_cell_forward"]], "weight_quantizer (quantrnnbase attribute)": [[130, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.weight_quantizer"]], "sequentialquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer"]], "tensorquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer"]], "__init__() (sequentialquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.__init__"]], "__init__() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.__init__"]], "amax (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.amax"]], "axis (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.axis"]], "block_sizes (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.block_sizes"]], "clean_up_after_set_from_modelopt_state() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.clean_up_after_set_from_modelopt_state"]], "dequantize() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.dequantize"]], "disable() (sequentialquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.disable"]], "disable() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable"]], "disable_calib() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_calib"]], "disable_clip() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_clip"]], "disable_quant() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_quant"]], "enable() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable"]], "enable_calib() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_calib"]], "enable_clip() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_clip"]], "enable_quant() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_quant"]], "export_amax() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.export_amax"]], "extra_repr() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.extra_repr"]], "fake_quant (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.fake_quant"]], "forward() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.forward"]], "get_modelopt_state() (sequentialquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.get_modelopt_state"]], "get_modelopt_state() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.get_modelopt_state"]], "init_learn_amax() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.init_learn_amax"]], "is_enabled (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.is_enabled"]], "load_calib_amax() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.load_calib_amax"]], "maxbound (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.maxbound"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[131, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"]], "narrow_range (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.narrow_range"]], "num_bits (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.num_bits"]], "pre_quant_scale (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.pre_quant_scale"]], "replace_sequential_quantizer_with_single_quantizer() (sequentialquantizer static method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.replace_sequential_quantizer_with_single_quantizer"]], "reset_amax() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.reset_amax"]], "scale (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.scale"]], "set_from_attribute_config() (sequentialquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.set_from_attribute_config"]], "set_from_attribute_config() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_attribute_config"]], "set_from_modelopt_state() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_modelopt_state"]], "step_size (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.step_size"]], "sync_amax_across_distributed_group() (tensorquantizer method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.sync_amax_across_distributed_group"]], "tensor_quantizer_iterator() (sequentialquantizer static method)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.tensor_quantizer_iterator"]], "trt_high_precision_dtype (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.trt_high_precision_dtype"]], "unsigned (tensorquantizer property)": [[131, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.unsigned"]], "freeze_parameters() (in module modelopt.torch.quantization.optim)": [[132, "modelopt.torch.quantization.optim.freeze_parameters"]], "group_parameters() (in module modelopt.torch.quantization.optim)": [[132, "modelopt.torch.quantization.optim.group_parameters"]], "match_parameters() (in module modelopt.torch.quantization.optim)": [[132, "modelopt.torch.quantization.optim.match_parameters"]], "modelopt.torch.quantization.optim": [[132, "module-modelopt.torch.quantization.optim"]], "quant_weight_inplace() (in module modelopt.torch.quantization.optim)": [[132, "modelopt.torch.quantization.optim.quant_weight_inplace"]], "modelopt.torch.quantization.plugins": [[133, "module-modelopt.torch.quantization.plugins"]], "modelopt.torch.quantization.qtensor": [[134, "module-modelopt.torch.quantization.qtensor"]], "basequantizedtensor (class in modelopt.torch.quantization.qtensor.base_qtensor)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor"]], "qtensorwrapper (class in modelopt.torch.quantization.qtensor.base_qtensor)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper"]], "__init__() (basequantizedtensor method)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.__init__"]], "__new__() (qtensorwrapper static method)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper.__new__"]], "dequantize() (basequantizedtensor method)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.dequantize"]], "modelopt.torch.quantization.qtensor.base_qtensor": [[135, "module-modelopt.torch.quantization.qtensor.base_qtensor"]], "original_meta_tensor (basequantizedtensor attribute)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.original_meta_tensor"]], "quantize() (basequantizedtensor class method)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.quantize"]], "quantized_data (basequantizedtensor attribute)": [[135, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.quantized_data"]], "int4qtensor (class in modelopt.torch.quantization.qtensor.int4_tensor)": [[136, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor"]], "dequantize() (int4qtensor method)": [[136, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.dequantize"]], "modelopt.torch.quantization.qtensor.int4_tensor": [[136, "module-modelopt.torch.quantization.qtensor.int4_tensor"]], "quantize() (int4qtensor class method)": [[136, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.quantize"]], "quantized_data (int4qtensor attribute)": [[136, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.quantized_data"]], "nf4qtensor (class in modelopt.torch.quantization.qtensor.nf4_tensor)": [[137, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor"]], "dequantize() (nf4qtensor method)": [[137, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.dequantize"]], "double_quantization() (nf4qtensor class method)": [[137, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.double_quantization"]], "modelopt.torch.quantization.qtensor.nf4_tensor": [[137, "module-modelopt.torch.quantization.qtensor.nf4_tensor"]], "quantize() (nf4qtensor class method)": [[137, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.quantize"]], "quantized_data (nf4qtensor attribute)": [[137, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.quantized_data"]], "deactivate() (in module modelopt.torch.quantization.quant_modules)": [[138, "modelopt.torch.quantization.quant_modules.deactivate"]], "enable_onnx_export() (in module modelopt.torch.quantization.quant_modules)": [[138, "modelopt.torch.quantization.quant_modules.enable_onnx_export"]], "initialize() (in module modelopt.torch.quantization.quant_modules)": [[138, "modelopt.torch.quantization.quant_modules.initialize"]], "modelopt.torch.quantization.quant_modules": [[138, "module-modelopt.torch.quantization.quant_modules"]], "fakeaffinetensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction"]], "faketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction"]], "legacyfaketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction"]], "scalede4m3function (class in modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function"]], "tensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction"]], "backward() (fakeaffinetensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.backward"]], "backward() (faketensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.backward"]], "backward() (legacyfaketensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.backward"]], "backward() (scalede4m3function static method)": [[139, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.backward"]], "backward() (tensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.backward"]], "fake_quant_impl() (in module modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.fake_quant_impl"]], "forward() (fakeaffinetensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.forward"]], "forward() (faketensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.forward"]], "forward() (legacyfaketensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.forward"]], "forward() (scalede4m3function static method)": [[139, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.forward"]], "forward() (tensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.forward"]], "modelopt.torch.quantization.tensor_quant": [[139, "module-modelopt.torch.quantization.tensor_quant"]], "quantize_op_abstract() (in module modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.quantize_op_abstract"]], "scaled_e4m3_impl() (in module modelopt.torch.quantization.tensor_quant)": [[139, "modelopt.torch.quantization.tensor_quant.scaled_e4m3_impl"]], "symbolic() (faketensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.symbolic"]], "symbolic() (scalede4m3function static method)": [[139, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.symbolic"]], "symbolic() (tensorquantfunction static method)": [[139, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.symbolic"]], "export_torch_mode() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.export_torch_mode"]], "get_parallel_state() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.get_parallel_state"]], "is_quantized() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.is_quantized"]], "is_quantized_column_parallel_linear() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.is_quantized_column_parallel_linear"]], "is_quantized_layer_with_weight() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.is_quantized_layer_with_weight"]], "is_quantized_row_parallel_linear() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.is_quantized_row_parallel_linear"]], "is_torch_library_supported() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.is_torch_library_supported"]], "modelopt.torch.quantization.utils": [[140, "module-modelopt.torch.quantization.utils"]], "reduce_amax() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.reduce_amax"]], "replace_function() (in module modelopt.torch.quantization.utils)": [[140, "modelopt.torch.quantization.utils.replace_function"]], "modelopt.torch.sparsity": [[141, "module-modelopt.torch.sparsity"]], "modelopt.torch.sparsity.config": [[142, "module-modelopt.torch.sparsity.config"]], "nn_conv2d (sparsegptconfig attribute)": [[142, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_conv2d"]], "nn_conv2d (sparsemagnitudeconfig attribute)": [[142, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_conv2d"]], "nn_linear (sparsegptconfig attribute)": [[142, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_linear"]], "nn_linear (sparsemagnitudeconfig attribute)": [[142, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_linear"]], "magnitudesearcher (class in modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.MagnitudeSearcher"]], "compute_valid_1d_patterns() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.compute_valid_1d_patterns"]], "create_asp_mask() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.create_asp_mask"]], "fill() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.fill"]], "get_nmprune_info() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.get_nmprune_info"]], "m4n2_1d() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.m4n2_1d"]], "mn_1d_best() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.mn_1d_best"]], "modelopt.torch.sparsity.magnitude": [[143, "module-modelopt.torch.sparsity.magnitude"]], "reshape_1d() (in module modelopt.torch.sparsity.magnitude)": [[143, "modelopt.torch.sparsity.magnitude.reshape_1d"]], "exportsparsemodedescriptor (class in modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor"]], "sparsegptmodedescriptor (class in modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor"]], "sparsemagnitudemodedescriptor (class in modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor"]], "config_class (exportsparsemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.config_class"]], "config_class (sparsegptmodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.config_class"]], "config_class (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.config_class"]], "convert (exportsparsemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.convert"]], "convert (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.convert"]], "convert_sparse_model() (in module modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.convert_sparse_model"]], "export_mode (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.export_mode"]], "export_sparse() (in module modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.export_sparse"]], "is_export_mode (exportsparsemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.is_export_mode"]], "modelopt.torch.sparsity.mode": [[144, "module-modelopt.torch.sparsity.mode"]], "name (exportsparsemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.name"]], "name (sparsegptmodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.name"]], "name (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.name"]], "next_modes (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.next_modes"]], "restore (exportsparsemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.restore"]], "restore (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.restore"]], "restore_export_sparse() (in module modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.restore_export_sparse"]], "restore_sparse_model() (in module modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.restore_sparse_model"]], "search_algorithm (sparsegptmodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.search_algorithm"]], "search_algorithm (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.search_algorithm"]], "update_for_new_mode (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_new_mode"]], "update_for_save (sparsemagnitudemodedescriptor property)": [[144, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_save"]], "update_sparse_metadata() (in module modelopt.torch.sparsity.mode)": [[144, "modelopt.torch.sparsity.mode.update_sparse_metadata"]], "sparsemodule (class in modelopt.torch.sparsity.module)": [[145, "modelopt.torch.sparsity.module.SparseModule"]], "modelopt.torch.sparsity.module": [[145, "module-modelopt.torch.sparsity.module"]], "modify() (sparsemodule method)": [[145, "modelopt.torch.sparsity.module.SparseModule.modify"]], "set_mask() (sparsemodule method)": [[145, "modelopt.torch.sparsity.module.SparseModule.set_mask"]], "modelopt.torch.sparsity.plugins": [[146, "module-modelopt.torch.sparsity.plugins"]], "basesparsesearcher (class in modelopt.torch.sparsity.searcher)": [[147, "modelopt.torch.sparsity.searcher.BaseSparseSearcher"]], "default_search_config (basesparsesearcher property)": [[147, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_search_config"]], "default_state_dict (basesparsesearcher property)": [[147, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_state_dict"]], "modelopt.torch.sparsity.searcher": [[147, "module-modelopt.torch.sparsity.searcher"]], "run_search() (basesparsesearcher method)": [[147, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.run_search"]], "sanitize_search_config() (basesparsesearcher method)": [[147, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.sanitize_search_config"]], "sparsegptsearcher (class in modelopt.torch.sparsity.sparsegpt)": [[148, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher"]], "after_search() (sparsegptsearcher method)": [[148, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.after_search"]], "before_search() (sparsegptsearcher method)": [[148, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.before_search"]], "create_sgpt_mask() (in module modelopt.torch.sparsity.sparsegpt)": [[148, "modelopt.torch.sparsity.sparsegpt.create_sgpt_mask"]], "default_search_config (sparsegptsearcher property)": [[148, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.default_search_config"]], "invert() (in module modelopt.torch.sparsity.sparsegpt)": [[148, "modelopt.torch.sparsity.sparsegpt.invert"]], "modelopt.torch.sparsity.sparsegpt": [[148, "module-modelopt.torch.sparsity.sparsegpt"]], "prepare() (in module modelopt.torch.sparsity.sparsegpt)": [[148, "modelopt.torch.sparsity.sparsegpt.prepare"]], "export() (in module modelopt.torch.sparsity.sparsification)": [[149, "modelopt.torch.sparsity.sparsification.export"]], "modelopt.torch.sparsity.sparsification": [[149, "module-modelopt.torch.sparsity.sparsification"]], "sparsify() (in module modelopt.torch.sparsity.sparsification)": [[149, "modelopt.torch.sparsity.sparsification.sparsify"]], "modelopt.torch.speculative": [[150, "module-modelopt.torch.speculative"]], "medusa_num_heads (medusaconfig attribute)": [[151, "modelopt.torch.speculative.config.MedusaConfig.medusa_num_heads"]], "medusa_num_layers (medusaconfig attribute)": [[151, "modelopt.torch.speculative.config.MedusaConfig.medusa_num_layers"]], "modelopt.torch.speculative.config": [[151, "module-modelopt.torch.speculative.config"]], "modelopt.torch.speculative.medusa": [[152, "module-modelopt.torch.speculative.medusa"]], "convert_to_medusa_model() (in module modelopt.torch.speculative.medusa.conversion)": [[153, "modelopt.torch.speculative.medusa.conversion.convert_to_medusa_model"]], "modelopt.torch.speculative.medusa.conversion": [[153, "module-modelopt.torch.speculative.medusa.conversion"]], "restore_medusa_model() (in module modelopt.torch.speculative.medusa.conversion)": [[153, "modelopt.torch.speculative.medusa.conversion.restore_medusa_model"]], "medusamodel (class in modelopt.torch.speculative.medusa.medusa_model)": [[154, "modelopt.torch.speculative.medusa.medusa_model.MedusaModel"]], "resblock (class in modelopt.torch.speculative.medusa.medusa_model)": [[154, "modelopt.torch.speculative.medusa.medusa_model.ResBlock"]], "__init__() (resblock method)": [[154, "modelopt.torch.speculative.medusa.medusa_model.ResBlock.__init__"]], "forward() (resblock method)": [[154, "modelopt.torch.speculative.medusa.medusa_model.ResBlock.forward"]], "modelopt.torch.speculative.medusa.medusa_model": [[154, "module-modelopt.torch.speculative.medusa.medusa_model"]], "modify() (medusamodel method)": [[154, "modelopt.torch.speculative.medusa.medusa_model.MedusaModel.modify"]], "medusamodedescriptor (class in modelopt.torch.speculative.mode)": [[155, "modelopt.torch.speculative.mode.MedusaModeDescriptor"]], "config_class (medusamodedescriptor property)": [[155, "modelopt.torch.speculative.mode.MedusaModeDescriptor.config_class"]], "convert (medusamodedescriptor property)": [[155, "modelopt.torch.speculative.mode.MedusaModeDescriptor.convert"]], "modelopt.torch.speculative.mode": [[155, "module-modelopt.torch.speculative.mode"]], "name (medusamodedescriptor property)": [[155, "modelopt.torch.speculative.mode.MedusaModeDescriptor.name"]], "restore (medusamodedescriptor property)": [[155, "modelopt.torch.speculative.mode.MedusaModeDescriptor.restore"]], "modelopt.torch.speculative.plugins": [[156, "module-modelopt.torch.speculative.plugins"]], "convert() (in module modelopt.torch.speculative.speculative_decoding)": [[157, "modelopt.torch.speculative.speculative_decoding.convert"]], "modelopt.torch.speculative.speculative_decoding": [[157, "module-modelopt.torch.speculative.speculative_decoding"]], "modelopt.torch.trace": [[158, "module-modelopt.torch.trace"]], "analyze_symbols() (in module modelopt.torch.trace.analyzer)": [[159, "modelopt.torch.trace.analyzer.analyze_symbols"]], "modelopt.torch.trace.analyzer": [[159, "module-modelopt.torch.trace.analyzer"]], "modelopt.torch.trace.modules": [[160, "module-modelopt.torch.trace.modules"]], "concatnodeprocessor (class in modelopt.torch.trace.modules.concat)": [[161, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor"]], "concatsymbol (class in modelopt.torch.trace.modules.concat)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol"]], "concatsymbol.input (class in modelopt.torch.trace.modules.concat)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input"]], "__init__() (concatnodeprocessor method)": [[161, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.__init__"]], "__init__() (concatsymbol method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.__init__"]], "__init__() (concatsymbol.input method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.__init__"]], "concat_sym (concatsymbol.input property)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.concat_sym"]], "convert() (concatsymbol.input static method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.convert"]], "create_linked_copy() (concatsymbol.input method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.create_linked_copy"]], "disable() (concatsymbol method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.disable"]], "input_syms (concatsymbol property)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.input_syms"]], "is_constant (concatsymbol property)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.is_constant"]], "is_searchable (concatsymbol property)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.is_searchable"]], "is_special_node() (concatnodeprocessor method)": [[161, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.is_special_node"]], "link_to() (concatsymbol method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.link_to"]], "link_to() (concatsymbol.input method)": [[161, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.link_to"]], "modelopt.torch.trace.modules.concat": [[161, "module-modelopt.torch.trace.modules.concat"]], "post_process() (concatnodeprocessor method)": [[161, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.post_process"]], "process() (concatnodeprocessor method)": [[161, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.process"]], "reset() (concatnodeprocessor method)": [[161, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.reset"]], "symdepth (class in modelopt.torch.trace.modules.nn)": [[162, "modelopt.torch.trace.modules.nn.SymDepth"]], "__init__() (symdepth method)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.__init__"]], "disable() (symdepth method)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.disable"]], "is_skippable() (symdepth method)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.is_skippable"]], "link_to() (symdepth method)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.link_to"]], "max_depth (symdepth property)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.max_depth"]], "min_depth (symdepth property)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.min_depth"]], "modelopt.torch.trace.modules.nn": [[162, "module-modelopt.torch.trace.modules.nn"]], "set_skippable() (symdepth method)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.set_skippable"]], "skippable_idxs (symdepth property)": [[162, "modelopt.torch.trace.modules.nn.SymDepth.skippable_idxs"]], "modelopt.torch.trace.plugins": [[163, "module-modelopt.torch.trace.plugins"]], "incoming (symbol.cltype attribute)": [[164, "modelopt.torch.trace.symbols.Symbol.CLType.INCOMING"]], "none (symbol.cltype attribute)": [[164, "modelopt.torch.trace.symbols.Symbol.CLType.NONE"]], "outgoing (symbol.cltype attribute)": [[164, "modelopt.torch.trace.symbols.Symbol.CLType.OUTGOING"]], "symdict (syminfo attribute)": [[164, "modelopt.torch.trace.symbols.SymInfo.SymDict"]], "syminfo (class in modelopt.torch.trace.symbols)": [[164, "modelopt.torch.trace.symbols.SymInfo"]], "symmap (class in modelopt.torch.trace.symbols)": [[164, "modelopt.torch.trace.symbols.SymMap"]], "symregisterfunc (symmap attribute)": [[164, "modelopt.torch.trace.symbols.SymMap.SymRegisterFunc"]], "symbol (class in modelopt.torch.trace.symbols)": [[164, "modelopt.torch.trace.symbols.Symbol"]], "symbol.cltype (class in modelopt.torch.trace.symbols)": [[164, "modelopt.torch.trace.symbols.Symbol.CLType"]], "__init__() (syminfo method)": [[164, "modelopt.torch.trace.symbols.SymInfo.__init__"]], "__init__() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.__init__"]], "__init__() (symbol method)": [[164, "modelopt.torch.trace.symbols.Symbol.__init__"]], "add_sym_info() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.add_sym_info"]], "cl_type (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.cl_type"]], "disable() (symbol method)": [[164, "modelopt.torch.trace.symbols.Symbol.disable"]], "elastic_dims (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.elastic_dims"]], "get_symbol() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.get_symbol"]], "is_constant (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_constant"]], "is_cross_layer (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_cross_layer"]], "is_dangling (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_dangling"]], "is_dynamic (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_dynamic"]], "is_free (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_free"]], "is_incoming (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_incoming"]], "is_outgoing (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_outgoing"]], "is_searchable (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_searchable"]], "is_shape_preserving (syminfo property)": [[164, "modelopt.torch.trace.symbols.SymInfo.is_shape_preserving"]], "is_shape_preserving() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.is_shape_preserving"]], "is_sortable (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.is_sortable"]], "items() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.items"]], "link_to() (symbol method)": [[164, "modelopt.torch.trace.symbols.Symbol.link_to"]], "modelopt.torch.trace.symbols": [[164, "module-modelopt.torch.trace.symbols"]], "named_modules() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.named_modules"]], "named_sym_dicts() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.named_sym_dicts"]], "named_symbols() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.named_symbols"]], "parent (symbol property)": [[164, "modelopt.torch.trace.symbols.Symbol.parent"]], "pop() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.pop"]], "prune() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.prune"]], "register() (symmap class method)": [[164, "modelopt.torch.trace.symbols.SymMap.register"]], "set_symbol() (symmap method)": [[164, "modelopt.torch.trace.symbols.SymMap.set_symbol"]], "unregister() (symmap class method)": [[164, "modelopt.torch.trace.symbols.SymMap.unregister"]], "graphcollection (class in modelopt.torch.trace.tracer)": [[165, "modelopt.torch.trace.tracer.GraphCollection"]], "robusttracer (class in modelopt.torch.trace.tracer)": [[165, "modelopt.torch.trace.tracer.RobustTracer"]], "__init__() (graphcollection method)": [[165, "modelopt.torch.trace.tracer.GraphCollection.__init__"]], "__init__() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.__init__"]], "failure_msg() (graphcollection method)": [[165, "modelopt.torch.trace.tracer.GraphCollection.failure_msg"]], "failure_msg() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.failure_msg"]], "is_failed() (graphcollection method)": [[165, "modelopt.torch.trace.tracer.GraphCollection.is_failed"]], "is_failed() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.is_failed"]], "is_leaf_module() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.is_leaf_module"]], "is_registered_leaf() (robusttracer class method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.is_registered_leaf"]], "is_unvisited() (graphcollection method)": [[165, "modelopt.torch.trace.tracer.GraphCollection.is_unvisited"]], "is_unvisited() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.is_unvisited"]], "modelopt.torch.trace.tracer": [[165, "module-modelopt.torch.trace.tracer"]], "record_call_module() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.record_call_module"]], "recursive_trace() (graphcollection method)": [[165, "modelopt.torch.trace.tracer.GraphCollection.recursive_trace"]], "recursive_trace() (in module modelopt.torch.trace.tracer)": [[165, "modelopt.torch.trace.tracer.recursive_trace"]], "register_leaf() (robusttracer class method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.register_leaf"]], "trace() (robusttracer method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.trace"]], "unregister_leaf() (robusttracer class method)": [[165, "modelopt.torch.trace.tracer.RobustTracer.unregister_leaf"]], "modelopt.torch.utils": [[166, "module-modelopt.torch.utils"]], "load_cpp_extension() (in module modelopt.torch.utils.cpp_extension)": [[167, "modelopt.torch.utils.cpp_extension.load_cpp_extension"]], "modelopt.torch.utils.cpp_extension": [[167, "module-modelopt.torch.utils.cpp_extension"]], "create_forward_loop() (in module modelopt.torch.utils.dataset_utils)": [[168, "modelopt.torch.utils.dataset_utils.create_forward_loop"]], "get_dataset_dataloader() (in module modelopt.torch.utils.dataset_utils)": [[168, "modelopt.torch.utils.dataset_utils.get_dataset_dataloader"]], "modelopt.torch.utils.dataset_utils": [[168, "module-modelopt.torch.utils.dataset_utils"]], "backend() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.backend"]], "barrier() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.barrier"]], "get_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.get_data_parallel_group"]], "get_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.get_tensor_parallel_group"]], "is_available() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.is_available"]], "is_initialized() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.is_initialized"]], "is_master() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.is_master"]], "modelopt.torch.utils.distributed": [[169, "module-modelopt.torch.utils.distributed"]], "rank() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.rank"]], "set_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.set_data_parallel_group"]], "set_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.set_tensor_parallel_group"]], "size() (in module modelopt.torch.utils.distributed)": [[169, "modelopt.torch.utils.distributed.size"]], "match() (in module modelopt.torch.utils.graph)": [[170, "modelopt.torch.utils.graph.match"]], "modelopt.torch.utils.graph": [[170, "module-modelopt.torch.utils.graph"]], "list_closest_to_median() (in module modelopt.torch.utils.list)": [[171, "modelopt.torch.utils.list.list_closest_to_median"]], "modelopt.torch.utils.list": [[171, "module-modelopt.torch.utils.list"]], "stats() (in module modelopt.torch.utils.list)": [[171, "modelopt.torch.utils.list.stats"]], "val2list() (in module modelopt.torch.utils.list)": [[171, "modelopt.torch.utils.list.val2list"]], "val2tuple() (in module modelopt.torch.utils.list)": [[171, "modelopt.torch.utils.list.val2tuple"]], "deprecatederror": [[172, "modelopt.torch.utils.logging.DeprecatedError"]], "modelopt.torch.utils.logging": [[172, "module-modelopt.torch.utils.logging"]], "no_stdout() (in module modelopt.torch.utils.logging)": [[172, "modelopt.torch.utils.logging.no_stdout"]], "num2hrb() (in module modelopt.torch.utils.logging)": [[172, "modelopt.torch.utils.logging.num2hrb"]], "print_rank_0() (in module modelopt.torch.utils.logging)": [[172, "modelopt.torch.utils.logging.print_rank_0"]], "compare_dict() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.compare_dict"]], "create_param_grad_clear_hook() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.create_param_grad_clear_hook"]], "get_model_attributes() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.get_model_attributes"]], "get_module_device() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.get_module_device"]], "get_same_padding() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.get_same_padding"]], "get_unwrapped_name() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.get_unwrapped_name"]], "init_model_from_model_like() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.init_model_from_model_like"]], "is_channels_last() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.is_channels_last"]], "is_parallel() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.is_parallel"]], "make_divisible() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.make_divisible"]], "model_to() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.model_to"]], "modelopt.torch.utils.network": [[173, "module-modelopt.torch.utils.network"]], "param_num() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.param_num"]], "param_num_from_forward() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.param_num_from_forward"]], "remove_bn() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.remove_bn"]], "run_forward_loop() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.run_forward_loop"]], "set_submodule() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.set_submodule"]], "standardize_constructor_args() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.standardize_constructor_args"]], "standardize_model_args() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.standardize_model_args"]], "standardize_model_like_tuple() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.standardize_model_like_tuple"]], "standardize_named_model_args() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.standardize_named_model_args"]], "unwrap_model() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.unwrap_model"]], "zero_grad() (in module modelopt.torch.utils.network)": [[173, "modelopt.torch.utils.network.zero_grad"]], "timer (class in modelopt.torch.utils.perf)": [[174, "modelopt.torch.utils.perf.Timer"]], "__init__() (timer method)": [[174, "modelopt.torch.utils.perf.Timer.__init__"]], "clear_cuda_cache() (in module modelopt.torch.utils.perf)": [[174, "modelopt.torch.utils.perf.clear_cuda_cache"]], "get_cuda_memory_stats() (in module modelopt.torch.utils.perf)": [[174, "modelopt.torch.utils.perf.get_cuda_memory_stats"]], "modelopt.torch.utils.perf": [[174, "module-modelopt.torch.utils.perf"]], "report_memory() (in module modelopt.torch.utils.perf)": [[174, "modelopt.torch.utils.perf.report_memory"]], "start() (timer method)": [[174, "modelopt.torch.utils.perf.Timer.start"]], "stop() (timer method)": [[174, "modelopt.torch.utils.perf.Timer.stop"]], "centroid() (in module modelopt.torch.utils.random)": [[175, "modelopt.torch.utils.random.centroid"]], "choice() (in module modelopt.torch.utils.random)": [[175, "modelopt.torch.utils.random.choice"]], "modelopt.torch.utils.random": [[175, "module-modelopt.torch.utils.random"]], "original() (in module modelopt.torch.utils.random)": [[175, "modelopt.torch.utils.random.original"]], "random() (in module modelopt.torch.utils.random)": [[175, "modelopt.torch.utils.random.random"]], "sample() (in module modelopt.torch.utils.random)": [[175, "modelopt.torch.utils.random.sample"]], "shuffle() (in module modelopt.torch.utils.random)": [[175, "modelopt.torch.utils.random.shuffle"]], "modelopt.torch.utils.tensor": [[176, "module-modelopt.torch.utils.tensor"]], "numpy_to_torch() (in module modelopt.torch.utils.tensor)": [[176, "modelopt.torch.utils.tensor.numpy_to_torch"]], "torch_detach() (in module modelopt.torch.utils.tensor)": [[176, "modelopt.torch.utils.tensor.torch_detach"]], "torch_to() (in module modelopt.torch.utils.tensor)": [[176, "modelopt.torch.utils.tensor.torch_to"]], "torch_to_numpy() (in module modelopt.torch.utils.tensor)": [[176, "modelopt.torch.utils.tensor.torch_to_numpy"]]}})