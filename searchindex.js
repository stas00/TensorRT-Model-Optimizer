Search.setIndex({"docnames": ["deployment/1_tensorrt_llm_deployment", "examples/0_all_examples", "getting_started/1_overview", "getting_started/2_installation", "getting_started/3_quantization", "getting_started/5_distillation", "getting_started/6_sparsity", "guides/1_quantization", "guides/4_distillation", "guides/5_sparsity", "guides/_basic_quantization", "guides/_choosing_quant_methods", "guides/_onnx_quantization", "guides/_pytorch_quantization", "index", "reference/0_versions", "reference/1_modelopt_api", "reference/generated/modelopt.deploy", "reference/generated/modelopt.deploy.llm", "reference/generated/modelopt.deploy.llm.generate", "reference/generated/modelopt.deploy.llm.nemo_utils", "reference/generated/modelopt.onnx", "reference/generated/modelopt.onnx.op_types", "reference/generated/modelopt.onnx.quantization", "reference/generated/modelopt.onnx.quantization.calib_utils", "reference/generated/modelopt.onnx.quantization.extensions", "reference/generated/modelopt.onnx.quantization.fp8", "reference/generated/modelopt.onnx.quantization.graph_utils", "reference/generated/modelopt.onnx.quantization.gs_patching", "reference/generated/modelopt.onnx.quantization.int4", "reference/generated/modelopt.onnx.quantization.int8", "reference/generated/modelopt.onnx.quantization.operators", "reference/generated/modelopt.onnx.quantization.ort_patching", "reference/generated/modelopt.onnx.quantization.ort_utils", "reference/generated/modelopt.onnx.quantization.partitioning", "reference/generated/modelopt.onnx.quantization.qdq_utils", "reference/generated/modelopt.onnx.quantization.quant_utils", "reference/generated/modelopt.onnx.quantization.quantize", "reference/generated/modelopt.onnx.utils", "reference/generated/modelopt.torch", "reference/generated/modelopt.torch.distill", "reference/generated/modelopt.torch.distill.config", "reference/generated/modelopt.torch.distill.distillation", "reference/generated/modelopt.torch.distill.distillation_model", "reference/generated/modelopt.torch.distill.loss_balancers", "reference/generated/modelopt.torch.distill.losses", "reference/generated/modelopt.torch.distill.mode", "reference/generated/modelopt.torch.distill.registry", "reference/generated/modelopt.torch.export", "reference/generated/modelopt.torch.export.distribute", "reference/generated/modelopt.torch.export.hf_config_map", "reference/generated/modelopt.torch.export.layer_utils", "reference/generated/modelopt.torch.export.model_config", "reference/generated/modelopt.torch.export.model_config_export", "reference/generated/modelopt.torch.export.model_config_utils", "reference/generated/modelopt.torch.export.postprocess", "reference/generated/modelopt.torch.export.scaling_factor_utils", "reference/generated/modelopt.torch.export.tensorrt_llm_utils", "reference/generated/modelopt.torch.export.transformer_engine", "reference/generated/modelopt.torch.export.vllm", "reference/generated/modelopt.torch.opt", "reference/generated/modelopt.torch.opt.config", "reference/generated/modelopt.torch.opt.conversion", "reference/generated/modelopt.torch.opt.dynamic", "reference/generated/modelopt.torch.opt.hparam", "reference/generated/modelopt.torch.opt.mode", "reference/generated/modelopt.torch.opt.plugins", "reference/generated/modelopt.torch.opt.searcher", "reference/generated/modelopt.torch.opt.utils", "reference/generated/modelopt.torch.quantization", "reference/generated/modelopt.torch.quantization.algorithms", "reference/generated/modelopt.torch.quantization.calib", "reference/generated/modelopt.torch.quantization.calib.calibrator", "reference/generated/modelopt.torch.quantization.calib.histogram", "reference/generated/modelopt.torch.quantization.calib.max", "reference/generated/modelopt.torch.quantization.config", "reference/generated/modelopt.torch.quantization.conversion", "reference/generated/modelopt.torch.quantization.extensions", "reference/generated/modelopt.torch.quantization.mode", "reference/generated/modelopt.torch.quantization.model_calib", "reference/generated/modelopt.torch.quantization.model_quant", "reference/generated/modelopt.torch.quantization.nn", "reference/generated/modelopt.torch.quantization.nn.functional", "reference/generated/modelopt.torch.quantization.nn.modules", "reference/generated/modelopt.torch.quantization.nn.modules.clip", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling", "reference/generated/modelopt.torch.quantization.nn.modules.quant_rnn", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer", "reference/generated/modelopt.torch.quantization.optim", "reference/generated/modelopt.torch.quantization.plugins", "reference/generated/modelopt.torch.quantization.qtensor", "reference/generated/modelopt.torch.quantization.qtensor.base_qtensor", "reference/generated/modelopt.torch.quantization.qtensor.int4_tensor", "reference/generated/modelopt.torch.quantization.qtensor.nf4_tensor", "reference/generated/modelopt.torch.quantization.quant_modules", "reference/generated/modelopt.torch.quantization.tensor_quant", "reference/generated/modelopt.torch.quantization.utils", "reference/generated/modelopt.torch.sparsity", "reference/generated/modelopt.torch.sparsity.config", "reference/generated/modelopt.torch.sparsity.magnitude", "reference/generated/modelopt.torch.sparsity.mode", "reference/generated/modelopt.torch.sparsity.module", "reference/generated/modelopt.torch.sparsity.plugins", "reference/generated/modelopt.torch.sparsity.searcher", "reference/generated/modelopt.torch.sparsity.sparsegpt", "reference/generated/modelopt.torch.sparsity.sparsification", "reference/generated/modelopt.torch.utils", "reference/generated/modelopt.torch.utils.cpp_extension", "reference/generated/modelopt.torch.utils.dataset_utils", "reference/generated/modelopt.torch.utils.distributed", "reference/generated/modelopt.torch.utils.graph", "reference/generated/modelopt.torch.utils.list", "reference/generated/modelopt.torch.utils.logging", "reference/generated/modelopt.torch.utils.network", "reference/generated/modelopt.torch.utils.perf", "reference/generated/modelopt.torch.utils.random", "reference/generated/modelopt.torch.utils.tensor", "support/1_contact", "support/2_faqs"], "filenames": ["deployment/1_tensorrt_llm_deployment.rst", "examples/0_all_examples.rst", "getting_started/1_overview.rst", "getting_started/2_installation.rst", "getting_started/3_quantization.rst", "getting_started/5_distillation.rst", "getting_started/6_sparsity.rst", "guides/1_quantization.rst", "guides/4_distillation.rst", "guides/5_sparsity.rst", "guides/_basic_quantization.rst", "guides/_choosing_quant_methods.rst", "guides/_onnx_quantization.rst", "guides/_pytorch_quantization.rst", "index.rst", "reference/0_versions.rst", "reference/1_modelopt_api.rst", "reference/generated/modelopt.deploy.rst", "reference/generated/modelopt.deploy.llm.rst", "reference/generated/modelopt.deploy.llm.generate.rst", "reference/generated/modelopt.deploy.llm.nemo_utils.rst", "reference/generated/modelopt.onnx.rst", "reference/generated/modelopt.onnx.op_types.rst", "reference/generated/modelopt.onnx.quantization.rst", "reference/generated/modelopt.onnx.quantization.calib_utils.rst", "reference/generated/modelopt.onnx.quantization.extensions.rst", "reference/generated/modelopt.onnx.quantization.fp8.rst", "reference/generated/modelopt.onnx.quantization.graph_utils.rst", "reference/generated/modelopt.onnx.quantization.gs_patching.rst", "reference/generated/modelopt.onnx.quantization.int4.rst", "reference/generated/modelopt.onnx.quantization.int8.rst", "reference/generated/modelopt.onnx.quantization.operators.rst", "reference/generated/modelopt.onnx.quantization.ort_patching.rst", "reference/generated/modelopt.onnx.quantization.ort_utils.rst", "reference/generated/modelopt.onnx.quantization.partitioning.rst", "reference/generated/modelopt.onnx.quantization.qdq_utils.rst", "reference/generated/modelopt.onnx.quantization.quant_utils.rst", "reference/generated/modelopt.onnx.quantization.quantize.rst", "reference/generated/modelopt.onnx.utils.rst", "reference/generated/modelopt.torch.rst", "reference/generated/modelopt.torch.distill.rst", "reference/generated/modelopt.torch.distill.config.rst", "reference/generated/modelopt.torch.distill.distillation.rst", "reference/generated/modelopt.torch.distill.distillation_model.rst", "reference/generated/modelopt.torch.distill.loss_balancers.rst", "reference/generated/modelopt.torch.distill.losses.rst", "reference/generated/modelopt.torch.distill.mode.rst", "reference/generated/modelopt.torch.distill.registry.rst", "reference/generated/modelopt.torch.export.rst", "reference/generated/modelopt.torch.export.distribute.rst", "reference/generated/modelopt.torch.export.hf_config_map.rst", "reference/generated/modelopt.torch.export.layer_utils.rst", "reference/generated/modelopt.torch.export.model_config.rst", "reference/generated/modelopt.torch.export.model_config_export.rst", "reference/generated/modelopt.torch.export.model_config_utils.rst", "reference/generated/modelopt.torch.export.postprocess.rst", "reference/generated/modelopt.torch.export.scaling_factor_utils.rst", "reference/generated/modelopt.torch.export.tensorrt_llm_utils.rst", "reference/generated/modelopt.torch.export.transformer_engine.rst", "reference/generated/modelopt.torch.export.vllm.rst", "reference/generated/modelopt.torch.opt.rst", "reference/generated/modelopt.torch.opt.config.rst", "reference/generated/modelopt.torch.opt.conversion.rst", "reference/generated/modelopt.torch.opt.dynamic.rst", "reference/generated/modelopt.torch.opt.hparam.rst", "reference/generated/modelopt.torch.opt.mode.rst", "reference/generated/modelopt.torch.opt.plugins.rst", "reference/generated/modelopt.torch.opt.searcher.rst", "reference/generated/modelopt.torch.opt.utils.rst", "reference/generated/modelopt.torch.quantization.rst", "reference/generated/modelopt.torch.quantization.algorithms.rst", "reference/generated/modelopt.torch.quantization.calib.rst", "reference/generated/modelopt.torch.quantization.calib.calibrator.rst", "reference/generated/modelopt.torch.quantization.calib.histogram.rst", "reference/generated/modelopt.torch.quantization.calib.max.rst", "reference/generated/modelopt.torch.quantization.config.rst", "reference/generated/modelopt.torch.quantization.conversion.rst", "reference/generated/modelopt.torch.quantization.extensions.rst", "reference/generated/modelopt.torch.quantization.mode.rst", "reference/generated/modelopt.torch.quantization.model_calib.rst", "reference/generated/modelopt.torch.quantization.model_quant.rst", "reference/generated/modelopt.torch.quantization.nn.rst", "reference/generated/modelopt.torch.quantization.nn.functional.rst", "reference/generated/modelopt.torch.quantization.nn.modules.rst", "reference/generated/modelopt.torch.quantization.nn.modules.clip.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_rnn.rst", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer.rst", "reference/generated/modelopt.torch.quantization.optim.rst", "reference/generated/modelopt.torch.quantization.plugins.rst", "reference/generated/modelopt.torch.quantization.qtensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.base_qtensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.int4_tensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.nf4_tensor.rst", "reference/generated/modelopt.torch.quantization.quant_modules.rst", "reference/generated/modelopt.torch.quantization.tensor_quant.rst", "reference/generated/modelopt.torch.quantization.utils.rst", "reference/generated/modelopt.torch.sparsity.rst", "reference/generated/modelopt.torch.sparsity.config.rst", "reference/generated/modelopt.torch.sparsity.magnitude.rst", "reference/generated/modelopt.torch.sparsity.mode.rst", "reference/generated/modelopt.torch.sparsity.module.rst", "reference/generated/modelopt.torch.sparsity.plugins.rst", "reference/generated/modelopt.torch.sparsity.searcher.rst", "reference/generated/modelopt.torch.sparsity.sparsegpt.rst", "reference/generated/modelopt.torch.sparsity.sparsification.rst", "reference/generated/modelopt.torch.utils.rst", "reference/generated/modelopt.torch.utils.cpp_extension.rst", "reference/generated/modelopt.torch.utils.dataset_utils.rst", "reference/generated/modelopt.torch.utils.distributed.rst", "reference/generated/modelopt.torch.utils.graph.rst", "reference/generated/modelopt.torch.utils.list.rst", "reference/generated/modelopt.torch.utils.logging.rst", "reference/generated/modelopt.torch.utils.network.rst", "reference/generated/modelopt.torch.utils.perf.rst", "reference/generated/modelopt.torch.utils.random.rst", "reference/generated/modelopt.torch.utils.tensor.rst", "support/1_contact.rst", "support/2_faqs.rst"], "titles": ["TensorRT-LLM Deployment", "GitHub Examples", "Overview", "Installation", "Quick Start: Quantization", "Quick Start: Distillation", "Quick Start: Sparsity", "Quantization", "Distillation", "Sparsity", "Basic Concepts", "Best practices to choose the right quantization methods", "ONNX Quantization (Beta)", "PyTorch Quantization", "Welcome to Model Optimizer (ModelOpt) documentation!", "Changelog", "modelopt API", "deploy", "llm", "generate", "nemo_utils", "onnx", "op_types", "quantization", "calib_utils", "extensions", "fp8", "graph_utils", "gs_patching", "int4", "int8", "operators", "ort_patching", "ort_utils", "partitioning", "qdq_utils", "quant_utils", "modelopt.onnx.quantization.quantize", "utils", "torch", "distill", "config", "distillation", "distillation_model", "loss_balancers", "losses", "mode", "registry", "export", "distribute", "hf_config_map", "layer_utils", "model_config", "model_config_export", "model_config_utils", "postprocess", "scaling_factor_utils", "tensorrt_llm_utils", "transformer_engine", "vllm", "opt", "config", "conversion", "dynamic", "hparam", "mode", "plugins", "searcher", "utils", "quantization", "algorithms", "calib", "calibrator", "histogram", "max", "config", "conversion", "extensions", "mode", "model_calib", "model_quant", "nn", "functional", "modules", "clip", "quant_activations", "quant_batchnorm", "quant_conv", "quant_instancenorm", "quant_linear", "quant_module", "quant_pooling", "quant_rnn", "tensor_quantizer", "optim", "plugins", "qtensor", "base_qtensor", "int4_tensor", "nf4_tensor", "quant_modules", "tensor_quant", "utils", "sparsity", "config", "magnitude", "mode", "module", "plugins", "searcher", "sparsegpt", "sparsification", "utils", "cpp_extension", "dataset_utils", "distributed", "graph", "list", "logging", "network", "perf", "random", "tensor", "Contact us", "FAQs"], "terms": {"pleas": [0, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 19, 60, 62, 75, 80, 95, 111, 124], "read": [0, 24, 49], "workflow": [0, 2, 65, 67], "first": [0, 3, 5, 9, 11, 13, 27, 29, 38, 49, 80, 113, 119], "befor": [0, 3, 10, 27, 45, 63, 67, 75, 78, 90, 92, 121], "go": 0, "through": [0, 5, 6, 10, 13, 79, 80, 101], "thi": [0, 3, 5, 6, 8, 9, 11, 12, 13, 15, 20, 22, 27, 29, 31, 32, 33, 34, 36, 37, 38, 41, 43, 44, 45, 46, 49, 51, 52, 54, 55, 57, 61, 62, 63, 64, 67, 70, 73, 75, 76, 78, 79, 80, 82, 92, 93, 95, 97, 99, 100, 101, 102, 105, 106, 107, 111, 114, 119, 121, 124], "section": [0, 8, 9], "modelopt": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 27, 33, 42, 50, 52, 60, 61, 62, 65, 71, 75, 76, 80, 114, 121, 124], "toolkit": [0, 7], "automat": [0, 2, 9, 13, 63, 105, 111], "convers": [0, 8, 11, 22, 37, 42, 63, 121], "engin": [0, 12, 15, 19, 52, 53], "acceler": [0, 2, 4, 6, 9], "inferenc": 0, "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19, 20, 22, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 61, 62, 63, 64, 65, 67, 68, 70, 73, 74, 75, 76, 78, 79, 80, 82, 90, 92, 93, 97, 100, 101, 102, 104, 105, 106, 107, 111, 114, 115, 119, 121, 124], "achiev": [0, 5, 7, 9, 13, 63], "huggingfac": [0, 3, 4, 5, 13, 19, 20, 48, 52, 95], "nemo": [0, 2, 4, 13, 15, 20, 48, 52, 95], "build": [0, 3, 12, 15, 20, 27, 51, 52, 53, 111], "from": [0, 1, 2, 4, 5, 8, 9, 10, 11, 15, 19, 20, 24, 27, 32, 33, 34, 35, 37, 38, 41, 43, 51, 52, 54, 56, 60, 61, 62, 63, 64, 67, 73, 75, 76, 80, 93, 101, 105, 110, 111, 114, 117, 119, 121, 122], "after": [0, 6, 8, 9, 10, 12, 13, 15, 27, 33, 44, 49, 60, 62, 63, 65, 67, 75, 79, 111, 119], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 22, 27, 36, 37, 46, 52, 53, 60, 61, 62, 63, 65, 67, 70, 75, 78, 80, 93, 95, 101, 104, 106, 114, 119, 120, 121], "format": [0, 2, 4, 7, 9, 11, 12, 13, 15, 24, 37, 41, 49, 51, 52, 53, 54, 67, 70, 80, 93, 98, 99, 114, 119], "store": [0, 9, 37, 41, 53, 62, 63, 64, 67, 98, 99, 101], "A": [0, 8, 9, 10, 11, 13, 19, 34, 35, 37, 41, 42, 43, 45, 47, 49, 51, 53, 54, 61, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 79, 80, 84, 92, 93, 97, 101, 102, 109, 111, 114, 119, 120], "singl": [0, 8, 10, 12, 27, 36, 41, 43, 54, 55, 56, 64, 65, 80, 92, 93, 119], "json": [0, 41, 49, 53, 54, 61, 75, 104], "file": [0, 12, 15, 26, 29, 30, 36, 37, 38, 49, 51, 53, 57, 61, 62, 113], "record": [0, 62, 65], "structur": 0, "metadata": [0, 9, 62, 75, 106], "config": [0, 4, 6, 8, 9, 15, 19, 20, 42, 46, 49, 50, 51, 52, 53, 54, 55, 57, 62, 63, 67, 70, 78, 80, 98, 99, 106, 109, 110, 111, 121], "group": [0, 11, 15, 49, 56, 75, 80, 93, 115], "safetensor": [0, 53], "each": [0, 9, 10, 13, 15, 29, 37, 41, 43, 44, 49, 53, 56, 57, 60, 62, 63, 64, 65, 70, 75, 76, 98, 99, 102, 104, 111, 121], "local": [0, 49], "calibr": [0, 4, 6, 9, 11, 13, 15, 24, 29, 35, 37, 53, 70, 71, 73, 74, 75, 79, 80, 87, 89, 90, 92, 93, 111, 114], "gpu": [0, 2, 9, 11, 15, 53, 73, 120, 121], "rank": [0, 49, 52, 53, 55, 56, 75, 80, 93, 102, 115, 120], "weight": [0, 2, 6, 9, 10, 11, 13, 15, 20, 29, 35, 37, 38, 43, 44, 49, 51, 52, 53, 54, 55, 56, 57, 62, 63, 73, 75, 76, 79, 80, 90, 92, 101, 102, 105, 107, 111], "scale": [0, 12, 15, 24, 29, 35, 51, 52, 53, 54, 56, 75, 79, 93, 97, 98, 99, 101], "factor": [0, 11, 29, 35, 51, 52, 53, 54, 56, 70, 75, 79, 101], "per": [0, 8, 10, 11, 15, 36, 42, 53, 70, 75, 80, 93, 97, 101, 111], "The": [0, 2, 4, 5, 8, 9, 10, 11, 12, 13, 15, 19, 20, 27, 29, 35, 36, 37, 41, 42, 43, 44, 46, 49, 51, 52, 53, 54, 55, 61, 62, 63, 67, 70, 75, 76, 78, 79, 80, 82, 93, 97, 98, 99, 101, 102, 105, 106, 111, 114, 116, 119, 121], "api": [0, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 19, 20, 40, 42, 53, 79, 80, 100, 103, 111], "export_tensorrt_llm_checkpoint": [0, 53], "us": [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 22, 27, 29, 30, 36, 37, 41, 42, 43, 45, 46, 49, 53, 56, 59, 60, 61, 62, 63, 67, 70, 73, 74, 75, 78, 79, 80, 82, 84, 92, 93, 100, 101, 104, 105, 107, 111, 113, 114, 115, 119, 120, 121, 124], "follow": [0, 3, 8, 9, 10, 11, 12, 13, 15, 27, 42, 46, 51, 62, 67, 75, 78, 80, 101, 111], "torch": [0, 2, 3, 4, 5, 6, 8, 9, 13, 15, 33, 40, 42, 44, 49, 51, 53, 54, 59, 60, 62, 63, 67, 71, 73, 75, 76, 80, 92, 93, 97, 98, 99, 101, 113, 114, 115, 119, 121, 122], "import": [0, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 61, 62, 64, 70, 75, 76, 80, 114, 119, 121], "inference_mod": 0, "decoder_typ": [0, 51, 52, 53], "type": [0, 8, 9, 19, 20, 22, 24, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 61, 62, 63, 64, 65, 67, 68, 70, 73, 75, 76, 78, 79, 80, 87, 89, 90, 92, 93, 97, 98, 99, 101, 105, 106, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122], "str": [0, 19, 20, 22, 24, 26, 27, 29, 30, 33, 34, 35, 37, 38, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63, 67, 68, 70, 73, 75, 76, 78, 79, 80, 92, 93, 104, 105, 106, 109, 110, 111, 113, 114, 115, 117, 118, 119], "e": [0, 5, 6, 8, 9, 10, 11, 13, 15, 29, 37, 45, 53, 63, 65, 67, 75, 80, 92, 101, 113, 119], "g": [0, 6, 9, 10, 13, 15, 53, 63, 65, 75, 101, 113, 119], "gptj": [0, 53], "llama": [0, 53], "gptnext": [0, 53], "dtype": [0, 28, 35, 37, 51, 52, 53, 93, 97, 98, 99, 101, 119], "data": [0, 4, 5, 6, 9, 11, 12, 13, 15, 24, 36, 37, 38, 53, 71, 73, 75, 79, 80, 93, 97, 98, 99, 111, 114, 115, 119, 122], "unquant": [0, 10, 53], "layer": [0, 8, 9, 13, 15, 27, 34, 37, 41, 43, 49, 51, 52, 53, 56, 57, 64, 70, 75, 80, 92, 104, 111, 119], "export_dir": [0, 53, 57, 59], "directori": [0, 12, 19, 37, 38, 49, 53, 57], "where": [0, 9, 10, 13, 29, 37, 43, 67, 70, 75, 80, 90, 119], "inference_tensor_parallel": [0, 15, 53, 55], "number": [0, 29, 45, 56, 63, 64, 73, 74, 75, 80, 84, 114, 115, 118, 119, 121], "infer": [0, 2, 4, 6, 9, 11, 33, 52, 53, 55, 62, 67, 114], "time": [0, 3, 11, 15, 53, 80, 111, 113, 117], "tensor": [0, 5, 8, 9, 10, 11, 13, 15, 24, 27, 29, 35, 37, 38, 43, 44, 45, 49, 51, 52, 53, 54, 55, 56, 63, 64, 70, 73, 74, 75, 80, 82, 84, 92, 93, 96, 97, 98, 99, 101, 102, 105, 110, 115, 119], "parallel": [0, 9, 15, 51, 53, 55, 102, 115, 119], "inference_pipeline_parallel": [0, 53, 55], "pipelin": [0, 5, 8, 9, 13, 53, 80], "If": [0, 3, 8, 9, 11, 12, 13, 24, 37, 41, 42, 43, 44, 49, 51, 52, 55, 56, 62, 63, 64, 73, 74, 75, 76, 79, 80, 84, 93, 102, 104, 111, 114, 119], "call": [0, 3, 8, 9, 13, 33, 36, 43, 61, 63, 76, 90, 92, 93, 107, 111, 114], "success": [0, 3], "save": [0, 6, 7, 8, 12, 13, 37, 38, 43, 49, 52, 53, 59, 60, 62, 67, 74, 78, 93, 101], "otherwis": [0, 37, 49, 51, 76, 101, 116], "state_dict": [0, 9, 13, 41, 43, 49, 62, 67, 80], "instead": [0, 15, 36, 49, 63, 64, 65, 70, 73, 100, 101, 104], "fp16": [0, 11, 12, 27, 37, 93], "bf16": [0, 11], "fp8": [0, 2, 10, 11, 13, 15, 27, 37, 51, 52, 53, 75, 93], "int8_sq": [0, 52], "int4_awq": [0, 15], "gpt2": [0, 53], "ye": 0, "No": 0, "2": [0, 2, 6, 9, 15, 24, 27, 29, 36, 70, 80, 101, 105], "3": [0, 3, 15, 51, 70, 75, 80, 101], "mistral": 0, "mixtral": [0, 15], "8x7b": 0, "falcon": 0, "40b": 0, "180b": 0, "7b": 0, "mpt": 0, "30b": 0, "baichuan": 0, "1": [0, 3, 13, 15, 19, 24, 29, 44, 45, 51, 52, 53, 54, 55, 70, 73, 75, 80, 101, 102, 114, 117, 119, 121], "chatglm2": 0, "6b": [0, 9], "bloom": 0, "phi": [0, 57], "nemotron": 0, "8": [0, 2, 3, 11, 12, 29, 51, 57, 73, 74, 75, 87, 89, 90, 92, 101, 113, 119], "gemma": [0, 15], "2b": 0, "recurr": [0, 22, 51, 52], "starcod": [0, 15], "qwen": [0, 15], "5": [0, 29, 34, 44, 75], "onc": [0, 33, 73], "avail": [0, 2, 3, 4, 8, 10, 15, 24, 42, 47, 64, 111, 115], "deploi": [0, 3, 11, 15], "all": [1, 2, 3, 9, 15, 32, 34, 35, 37, 38, 49, 51, 52, 53, 55, 61, 62, 63, 68, 73, 74, 76, 80, 92, 93, 102, 104, 105, 107, 115, 119, 121], "access": [1, 9, 22, 49, 61, 63, 75], "repositori": [1, 2, 7], "com": [1, 3, 19, 20, 22, 53, 101, 119], "nvidia": [1, 3, 6, 7, 9, 13, 15, 19, 20, 53, 75, 105], "tensorrt": [1, 3, 4, 7, 11, 12, 13, 14, 15, 19, 24, 27, 30, 37, 51, 52, 53, 57, 80], "model": [1, 7, 8, 10, 11, 17, 19, 20, 21, 23, 24, 26, 27, 29, 30, 34, 37, 38, 39, 41, 42, 43, 46, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 65, 67, 68, 70, 73, 75, 76, 78, 79, 80, 93, 100, 106, 111, 114, 119, 121, 124], "optim": [1, 4, 7, 8, 9, 13, 17, 21, 23, 36, 39, 42, 53, 58, 59, 60, 62, 65, 67, 68, 70, 75, 92, 111], "minim": [2, 8, 10, 15, 67, 70, 75], "cost": [2, 10], "present": [2, 5, 8, 38], "signific": 2, "challeng": 2, "gener": [2, 10, 12, 22, 37, 38, 45, 52, 54, 60, 61, 62, 63, 64, 68, 75, 105, 109, 121], "ai": 2, "continu": [2, 9, 111], "grow": 2, "complex": 2, "size": [2, 8, 10, 11, 15, 36, 38, 41, 49, 51, 52, 56, 63, 68, 75, 80, 93, 98, 99, 105, 114, 115, 119], "refer": [2, 4, 7, 8, 9, 12, 13, 15, 19, 20, 22, 27, 60, 64, 92, 93, 111, 119], "librari": [2, 37], "compris": [2, 11], "state": [2, 8, 13, 43, 46, 49, 62, 65, 67, 70, 78, 90, 93, 109, 119], "art": 2, "includ": [2, 3, 8, 10, 15, 19, 52, 63, 75, 114], "compress": [2, 8, 9, 11, 70, 80], "It": [2, 8, 13, 49, 65, 75, 78, 80, 92, 93, 97, 101, 105, 111, 119], "accept": [2, 8, 15, 92, 101], "onnx": [2, 3, 4, 7, 11, 13, 15, 22, 23, 24, 26, 27, 29, 30, 33, 34, 35, 36, 38, 67, 75, 100, 101, 119], "input": [2, 4, 5, 6, 9, 12, 13, 15, 19, 24, 27, 31, 34, 35, 36, 37, 38, 43, 63, 73, 75, 76, 80, 82, 84, 88, 90, 92, 93, 97, 98, 99, 101, 102, 111, 114, 119, 122], "provid": [2, 6, 8, 9, 10, 12, 13, 24, 27, 33, 36, 44, 49, 56, 60, 61, 62, 63, 67, 71, 80, 97, 104, 111, 114, 119], "python": [2, 3, 12, 15, 22, 54, 92, 121], "user": [2, 4, 5, 8, 9, 11, 12, 13, 15, 22, 27, 33, 37, 49, 60, 62, 63, 64, 75, 80], "easili": [2, 5], "stack": [2, 7, 78], "differ": [2, 7, 8, 10, 11, 22, 42, 44, 45, 63, 75, 92, 111, 114], "produc": [2, 27, 38], "checkpoint": [2, 6, 8, 9, 15, 41, 43, 52, 53, 57, 59, 60, 62, 67, 93], "seamlessli": [2, 8], "integr": [2, 5], "within": [2, 8, 12, 65, 75, 101, 102, 118], "softwar": [2, 7], "ecosystem": 2, "readi": [2, 4, 42], "deploy": [2, 5, 7, 11, 13, 15, 17, 18, 39, 53, 67, 80], "downstream": 2, "framework": [2, 7, 13, 15], "like": [2, 4, 7, 9, 10, 12, 13, 15, 24, 34, 37, 44, 62, 63, 67, 74, 93, 119], "llm": [2, 3, 4, 7, 11, 13, 14, 15, 19, 48, 51, 52, 53, 57, 75, 80], "further": [2, 5, 99], "ar": [2, 3, 5, 8, 9, 10, 11, 13, 15, 20, 27, 29, 30, 34, 37, 38, 41, 42, 44, 51, 52, 53, 54, 55, 57, 61, 62, 63, 67, 75, 76, 79, 80, 90, 92, 93, 101, 102, 104, 111, 113, 119], "plan": 2, "megatron": [2, 15, 95, 108], "lm": 2, "train": [2, 4, 8, 15, 42, 55, 92, 111, 124], "loop": [2, 4, 5, 6, 13, 36, 67, 111, 114], "For": [2, 3, 9, 10, 11, 12, 13, 19, 37, 44, 53, 55, 61, 62, 63, 64, 65, 75, 79, 80, 101, 104, 119], "enterpris": 2, "bit": [2, 10, 11, 36, 73, 74, 75, 101], "stabl": 2, "diffus": [2, 95], "also": [2, 4, 5, 8, 9, 13, 54, 63, 65, 70, 73, 75, 76, 80, 82, 119, 121], "nim": 2, "free": 2, "develop": 2, "pypi": [2, 3], "visit": 2, "github": [2, 4, 6, 7, 14, 19, 20, 22, 53, 101, 119, 123], "end": [2, 4, 6, 8, 27, 75, 80, 119, 120], "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 19, 20, 37, 44, 61, 62, 64, 65, 76, 79, 80, 95, 104, 114, 121], "script": [2, 8, 20], "recip": [2, 70], "an": [2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 26, 27, 29, 30, 33, 36, 38, 41, 42, 46, 49, 51, 53, 55, 62, 63, 64, 65, 70, 73, 74, 75, 76, 78, 79, 80, 82, 93, 101, 104, 106, 111, 119, 121], "effect": [2, 4, 6, 8, 10, 13, 101], "larg": [2, 11, 36], "2x": [2, 9], "4x": 2, "speed": [2, 4, 6, 9], "up": [2, 3, 4, 9, 11, 42, 49, 60, 63, 67, 93, 111], "while": [2, 5, 10, 13, 15, 63, 67, 70, 100], "preserv": [2, 10, 62], "qualiti": [2, 8, 13], "enabl": [2, 4, 8, 9, 13, 15, 43, 64, 70, 75, 80, 87, 89, 90, 92, 93, 102, 113], "highli": [2, 9, 13], "perform": [2, 4, 5, 6, 8, 11, 13, 19, 26, 29, 30, 49, 54, 73, 75, 79, 80, 93, 99, 101, 120], "int8": [2, 4, 11, 12, 37, 51, 75, 93, 99], "int4": [2, 11, 12, 13, 37, 75, 93, 98], "etc": [2, 12, 13, 27, 29, 37, 70, 75, 80, 93], "support": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 15, 20, 26, 28, 29, 30, 33, 35, 37, 43, 48, 51, 52, 62, 63, 67, 73, 75, 76, 78, 79, 80, 81, 82, 83, 95, 100, 102, 108, 111, 119], "advanc": [2, 4, 6, 10, 70], "algorithm": [2, 4, 11, 12, 13, 15, 29, 42, 60, 61, 62, 65, 67, 75, 79, 80, 103, 106, 109, 110, 111], "smoothquant": [2, 4, 10, 11, 13, 70, 75, 79, 93], "awq": [2, 4, 10, 11, 13, 29, 52, 55, 70, 75, 98], "doubl": [2, 75, 99], "easi": [2, 6, 9, 12], "both": [2, 4, 5, 8, 9, 10, 11, 15, 29, 42, 63, 90], "post": [2, 4, 10, 15, 67, 119], "ptq": [2, 10, 15, 27], "awar": [2, 4, 15, 29], "qat": [2, 4, 15], "page": 2, "list": [2, 3, 10, 13, 19, 26, 27, 30, 33, 34, 37, 38, 42, 43, 44, 49, 51, 52, 53, 55, 56, 57, 62, 70, 74, 75, 76, 80, 92, 93, 111, 113, 122], "reduc": [2, 4, 6, 8, 9, 10, 41, 43, 44, 45, 75, 80, 92, 99, 102, 111, 121], "memori": [2, 4, 6, 7, 9, 11, 13, 15, 38, 53, 55, 75, 99, 119, 120], "footprint": [2, 4, 6, 9], "deep": [2, 4, 6, 10], "learn": [2, 4, 5, 6, 8, 10, 13, 43, 46, 60, 75, 80, 84, 93, 102], "mt": [2, 6, 9], "sparsifi": [2, 6, 9, 15, 111], "appli": [2, 6, 8, 9, 11, 15, 26, 29, 30, 43, 44, 62, 75, 80, 88, 93, 101, 105, 114], "given": [2, 5, 6, 22, 27, 35, 37, 38, 56, 61, 63, 67, 68, 75, 76, 80, 93, 102, 105, 110, 111, 114, 119, 121], "4": [2, 6, 9, 10, 11, 13, 24, 36, 51, 75, 101, 105], "pattern": [2, 6, 9, 27, 34, 37, 75, 80, 104, 105, 111, 116], "variou": [2, 6, 35, 60, 62, 76, 93, 111], "sparsif": [2, 15, 103, 106], "method": [2, 5, 6, 7, 9, 13, 20, 27, 36, 37, 61, 62, 63, 67, 73, 75, 76, 79, 80, 90, 92, 93, 97, 99, 101, 119], "asp": [2, 6, 9, 105], "sparsegpt": [2, 6, 9, 106, 111], "pt": [2, 13, 62], "sat": [2, 15], "latter": 2, "recommend": [2, 3, 11, 13, 75, 101, 111], "accuraci": [2, 5, 7, 8, 9, 10, 11], "degrad": [2, 11, 13], "current": [3, 7, 9, 12, 15, 26, 29, 61, 62, 63, 64, 70, 80, 92, 95, 106, 108, 111, 113, 115], "ha": [3, 5, 8, 11, 13, 24, 27, 38, 49, 62, 63, 64, 67, 80, 84, 102], "o": 3, "linux": 3, "architectur": [3, 8, 9, 53, 62, 63, 121], "x86_64": 3, "13": 3, "cuda": [3, 75, 77, 92, 101, 113, 120], "11": [3, 113], "pytorch": [3, 7, 9, 11, 15, 45, 60, 63, 75, 76, 79, 80, 82, 84, 101, 102, 114, 119, 122], "option": [3, 9, 15, 27, 34, 37, 51, 56, 62, 63, 64, 67, 76, 111, 121], "0": [3, 12, 19, 29, 38, 44, 45, 52, 53, 57, 73, 75, 80, 87, 89, 92, 93, 101, 114, 119, 120, 121], "its": [3, 5, 8, 9, 15, 42, 57, 62, 63, 67, 70, 75, 76, 80, 93, 111, 119], "depend": [3, 15, 27, 63, 64], "via": [3, 8, 9, 11, 29, 46, 62, 63, 67, 78, 106, 107, 119, 121], "pip": [3, 15], "review": 3, "licens": 3, "term": [3, 8, 9], "ani": [3, 5, 8, 15, 27, 37, 41, 42, 43, 44, 46, 49, 53, 54, 57, 61, 62, 63, 64, 67, 70, 75, 78, 80, 93, 102, 104, 106, 107, 109, 110, 111, 113, 116, 117, 119, 121], "quick": [3, 14], "detail": [3, 4, 5, 7, 10, 11, 12, 13, 37, 41, 67, 75, 76, 80, 93, 101, 104, 111], "instruct": 3, "set": [3, 4, 9, 13, 15, 19, 28, 33, 34, 35, 41, 42, 43, 44, 46, 51, 53, 57, 60, 61, 62, 63, 64, 67, 70, 73, 75, 76, 78, 80, 93, 106, 107, 111, 115, 119], "virtual": 3, "environ": 3, "we": [3, 4, 8, 9, 10, 11, 13, 27, 29, 51, 52, 53, 55, 61, 62, 63, 64, 65, 67, 70, 73, 78, 80, 92, 95, 101, 107, 108, 111, 114, 119, 121], "you": [3, 6, 7, 8, 9, 11, 12, 13, 15, 61, 62, 75, 80, 95, 100, 104, 111, 119], "don": [3, 37, 67, 78], "t": [3, 34, 37, 67, 73, 78, 82, 92, 102, 121], "have": [3, 9, 10, 11, 13, 15, 24, 37, 44, 49, 61, 63, 75, 76, 80, 119], "one": [3, 5, 8, 10, 51, 52, 55, 62, 63, 73, 76, 95, 102, 105], "alreadi": [3, 8, 34, 41, 62], "run": [3, 8, 12, 13, 20, 27, 67, 73, 80, 111, 119], "command": [3, 12], "activ": [3, 8, 10, 11, 29, 37, 51, 52, 63, 64, 70, 75, 80, 85, 101, 107, 119], "conda": 3, "name": [3, 12, 15, 27, 34, 35, 37, 38, 43, 44, 46, 51, 53, 61, 63, 67, 68, 70, 75, 76, 78, 80, 102, 104, 106, 113, 114, 119, 120], "12": [3, 15, 113], "creat": [3, 8, 9, 12, 13, 27, 33, 35, 49, 53, 62, 73, 75, 93, 97, 105, 110, 114, 119], "n": [3, 105], "desir": [3, 4, 8, 35, 42, 62, 111], "version": [3, 13, 22, 36, 45, 52, 57, 63, 89, 91, 101, 102, 113], "By": [3, 12, 15, 31, 75], "default": [3, 5, 12, 13, 15, 22, 31, 33, 37, 41, 45, 51, 53, 61, 63, 64, 67, 70, 73, 75, 76, 84, 93, 101, 102, 104, 105, 109, 110, 111, 119, 121], "latest": 3, "want": [3, 9, 13, 49, 62, 63, 67, 75, 78, 101, 104, 111, 121], "specif": [3, 8, 9, 11, 27, 46, 63, 65, 70, 75, 76, 97, 104, 114], "your": [3, 8, 9, 11, 13, 15, 45, 75, 80, 95, 111], "extra": [3, 15, 20, 93, 119], "index": [3, 93], "url": 3, "http": [3, 19, 20, 22, 45, 53, 82, 101, 119], "download": [3, 12], "org": [3, 45, 82], "whl": 3, "cu118": 3, "identifi": [3, 34], "correct": [3, 70, 76, 80, 90], "partial": [3, 27], "note": [3, 5, 13, 20, 22, 27, 31, 33, 34, 38, 41, 43, 49, 62, 63, 64, 78, 92, 104, 107], "when": [3, 8, 9, 11, 15, 27, 37, 41, 43, 49, 61, 62, 63, 64, 73, 75, 92, 93, 107, 114, 124], "without": [3, 5, 9, 43, 53, 63, 119], "onli": [3, 5, 6, 8, 9, 10, 11, 13, 15, 22, 26, 27, 29, 31, 34, 35, 37, 41, 42, 48, 51, 52, 54, 57, 61, 63, 73, 75, 79, 80, 82, 84, 92, 101, 107, 118, 119], "barebon": 3, "none": [3, 20, 26, 27, 29, 30, 33, 37, 38, 41, 43, 44, 45, 46, 49, 51, 52, 53, 55, 56, 57, 61, 62, 63, 64, 67, 68, 70, 73, 74, 75, 76, 78, 79, 80, 87, 89, 90, 92, 93, 101, 102, 104, 106, 107, 109, 111, 113, 114, 115, 119, 120, 121], "modul": [3, 5, 8, 9, 15, 17, 18, 20, 21, 23, 25, 28, 29, 31, 32, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 100, 102, 103, 104, 106, 108, 111, 112, 113, 114, 116, 119], "work": [3, 8, 10, 12, 27, 49, 95, 119], "appropri": [3, 4, 6, 64, 75, 93], "below": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 63, 75, 80, 119], "need": [3, 5, 8, 10, 13, 15, 44, 49, 51, 52, 57, 62, 63, 64, 75, 80, 100, 101, 119], "correctli": [3, 9, 13, 61, 93, 95], "correspond": [3, 41, 44, 46, 62, 63, 64, 75, 78, 80, 106, 119, 121], "_deploi": [3, 15], "addition": [3, 27, 62, 80], "3rd": 3, "parti": [3, 66, 95, 108], "plugin": [3, 37], "third": [3, 27, 66, 95, 108], "packag": [3, 15, 17, 48, 69, 92, 102, 115], "transform": [3, 9, 12, 51, 52, 54, 80], "hf": [3, 15, 20, 50, 53], "replac": [3, 8, 12, 13, 33, 35, 63, 75, 76, 80, 92, 93, 102], "": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 27, 29, 33, 37, 41, 42, 43, 45, 46, 49, 51, 61, 62, 63, 65, 74, 75, 78, 82, 92, 106, 111, 114, 117, 119], "quantiz": [3, 14, 15, 22, 26, 27, 29, 30, 31, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 58, 59, 65, 70, 71, 73, 74, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 114], "compil": [3, 12, 34, 37, 113], "fast": [3, 80], "kernel": [3, 11, 27, 34, 119], "mai": [3, 5, 8, 9, 10, 13, 62, 63, 80, 101, 111, 113], "take": [3, 9, 13, 61, 64, 73, 75, 76, 79, 80, 93, 101, 111, 113, 119], "few": [3, 8, 80, 113], "minut": [3, 11], "subsequ": [3, 9, 67, 113], "much": [3, 8, 13, 75], "faster": [3, 5, 8, 36, 64], "To": [3, 5, 7, 8, 9, 13, 15, 75, 80, 104], "invok": [3, 8, 37, 118], "pre": [3, 8, 9, 13, 34, 37, 56, 67, 92], "docker": 3, "c": [3, 8, 25, 36, 77, 113], "extens": [3, 20, 101, 113], "ext": 3, "print": [3, 13, 27, 37, 80, 111, 118], "cuda_ext": 3, "cuda_ext_fp8": 3, "techniqu": [4, 6, 9, 10, 13, 15], "mtq": [4, 13, 15, 75, 76, 100, 114], "more": [4, 5, 6, 7, 8, 9, 11, 13, 46, 60, 61, 63, 75, 76, 80, 82, 93, 98, 99, 101, 111, 119], "case": [4, 6, 8, 9, 11, 13, 44, 55, 63, 75], "requir": [4, 6, 8, 9, 11, 13, 15, 37, 52, 75, 78, 79, 80, 93, 113], "configur": [4, 6, 8, 9, 13, 15, 33, 41, 42, 61, 63, 64, 65, 67, 68, 70, 76, 80, 97, 104, 111, 114, 121], "forward": [4, 5, 6, 10, 13, 27, 43, 44, 45, 57, 67, 76, 79, 80, 82, 84, 90, 92, 93, 101, 110, 111, 114, 119], "here": [4, 6, 13, 34, 36, 44, 63, 64, 75, 76, 80, 92, 119], "setup": [4, 5, 6, 13, 76], "get_model": [4, 6, 13], "show": [4, 5, 13, 41, 61, 75, 104], "rough": 4, "how": [4, 5, 8, 11, 20, 45, 60, 64, 75, 95, 101, 119], "loader": [4, 5, 6, 13, 80, 111, 119], "calib_s": [4, 6, 13], "data_load": [4, 6, 9, 13, 80, 111, 119], "get_dataload": [4, 13], "num_sampl": [4, 6, 13, 114], "defin": [4, 5, 6, 8, 9, 10, 13, 34, 50, 52, 60, 65, 67, 75, 76, 80, 82, 93, 106, 121], "forward_loop": [4, 6, 13, 67, 75, 79, 80, 111, 114], "function": [4, 5, 8, 13, 20, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 49, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 67, 68, 70, 73, 75, 76, 77, 79, 80, 84, 92, 93, 94, 99, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122], "should": [4, 8, 12, 13, 15, 24, 27, 33, 34, 36, 37, 42, 44, 51, 52, 61, 62, 63, 64, 75, 76, 79, 80, 97, 111, 119], "wrap": [4, 5, 8, 13, 41, 61, 62, 97, 119], "insid": [4, 51, 111], "def": [4, 5, 13, 76, 80], "batch": [4, 11, 13, 19, 29, 38, 63, 75, 80, 86, 111, 114, 119], "int8_smoothquant_cfg": [4, 13, 75], "just": [4, 52, 78, 119], "regular": [4, 9, 10, 13, 37, 60, 63, 64, 106, 111], "evalu": [4, 20, 67, 80], "export": [4, 7, 8, 9, 13, 15, 42, 46, 51, 53, 55, 57, 59, 60, 63, 65, 67, 75, 78, 93, 100, 102, 106, 111, 119], "see": [4, 5, 8, 11, 12, 13, 20, 63, 73, 74, 75, 76, 80, 101, 111, 119], "guid": [4, 5, 6, 13], "next": [4, 5, 6, 15, 24, 27, 106], "step": [4, 5, 6, 8, 9, 12, 62, 65, 67, 75, 93], "about": [4, 5, 6, 8, 9, 46, 47, 60, 75, 80, 93], "usag": [4, 5, 6, 8, 9, 13, 61, 80, 99, 114, 120], "checkout": [4, 6], "out": [4, 5, 6, 8, 9, 36, 42, 44, 46, 75, 95], "wrapper": [5, 19, 43, 62, 97, 119], "util": [5, 8, 9, 15, 18, 20, 22, 24, 27, 33, 34, 35, 36, 49, 51, 54, 55, 56, 57, 59, 62, 65, 76, 79, 110, 113, 114, 115, 116, 117, 118, 119, 120, 122], "knowledg": [5, 41, 43, 44, 46], "among": [5, 8, 64], "teacher": [5, 41, 42, 43, 45], "student": [5, 41, 42, 43, 44, 45], "pretrain": 5, "potenti": [5, 8, 10, 43], "smaller": [5, 8, 9], "higher": [5, 9, 80], "than": [5, 8, 9, 13, 20, 63, 75], "could": [5, 8, 11, 13, 19, 63, 64, 75, 76, 80], "own": [5, 8, 13, 45, 55, 63, 75, 95], "necessari": [5, 8, 92, 93, 97, 107], "obtain": [5, 8, 9, 44], "act": 5, "usuali": 5, "serv": [5, 8, 11], "torchvis": [5, 8], "resnet50": [5, 8], "resnet18": 5, "student_model": [5, 8], "callabl": [5, 8, 13, 41, 43, 44, 46, 62, 64, 67, 75, 76, 78, 79, 80, 92, 106, 111, 114, 119], "which": [5, 8, 10, 13, 15, 27, 34, 36, 43, 60, 61, 62, 64, 67, 70, 73, 75, 76, 79, 80, 82, 90, 92, 93, 102, 104, 105, 119, 121], "return": [5, 8, 9, 13, 19, 20, 22, 24, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 61, 62, 63, 64, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 93, 97, 98, 99, 101, 102, 105, 106, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122], "teacher_factori": 5, "teacher_model": [5, 8, 41, 43], "load_state_dict": [5, 13, 43, 62], "pretrained_weight": 5, "As": [5, 8, 101], "involv": [5, 8, 49], "least": [5, 34, 61], "two": [5, 8, 9, 27, 36, 38, 51, 53, 76, 119], "simplifi": 5, "process": [5, 8, 9, 10, 12, 37, 42, 46, 49, 53, 55, 62, 63, 67, 104, 111, 114, 115, 118, 119, 121], "assum": [5, 27, 45, 51, 80, 119], "output": [5, 8, 12, 13, 19, 27, 34, 35, 37, 38, 41, 43, 45, 51, 63, 70, 75, 80, 93, 101, 119], "logit": [5, 8, 45], "mtd": [5, 8, 44], "distillation_config": [5, 8], "initi": [5, 9, 13, 19, 24, 27, 29, 35, 41, 62, 63, 64, 70, 73, 74, 76, 84, 90, 93, 97, 100, 107, 114, 115, 119, 120], "criterion": [5, 8, 41, 43, 44], "logitsdistillationloss": [5, 8, 45], "receiv": 5, "order": [5, 8, 13, 20, 44, 62, 63, 64, 75, 104, 119], "loss_balanc": [5, 8, 41, 43], "staticlossbalanc": [5, 8, 44], "combin": [5, 8], "multipl": [5, 8, 15, 37, 43, 55, 56, 62, 63, 70, 75, 93, 119], "loss": [5, 10, 29, 41, 43, 44, 70, 80, 111], "omit": [5, 8], "distillation_model": [5, 8], "convert": [5, 9, 13, 15, 36, 37, 42, 44, 46, 51, 52, 53, 54, 57, 58, 59, 62, 63, 67, 78, 97, 98, 99, 104, 106, 111, 118, 119, 121, 122, 124], "mode": [5, 6, 8, 15, 37, 41, 42, 61, 62, 67, 75, 92, 93, 102, 104, 111], "kd_loss": [5, 8, 42], "either": [5, 8, 9, 33, 37, 63, 119], "nn": [5, 13, 41, 44, 51, 62, 63, 67, 73, 75, 76, 89, 91, 93, 97, 104, 119], "tupl": [5, 8, 27, 34, 38, 41, 42, 43, 46, 49, 51, 53, 62, 63, 64, 67, 68, 70, 73, 74, 75, 78, 80, 92, 93, 98, 99, 102, 105, 106, 110, 111, 117, 119], "model_cl": [5, 62], "arg": [5, 8, 15, 20, 41, 43, 62, 63, 67, 90, 92, 93, 94, 100, 107, 118, 119, 121, 122], "kwarg": [5, 8, 20, 41, 43, 61, 62, 63, 79, 90, 92, 93, 94, 97, 98, 99, 100, 107, 118, 119, 121, 122], "between": [5, 7, 8, 41, 43, 50, 73], "determin": [5, 8, 71, 114, 121], "origin": [5, 7, 8, 9, 10, 11, 12, 13, 15, 37, 42, 43, 44, 53, 54, 62, 63, 64, 70, 75, 76, 80, 90, 92, 97, 119, 121], "info": [5, 27, 61, 119], "simpli": [5, 13, 63], "usual": [5, 8, 9, 62, 63, 67], "compute_kd_loss": [5, 8, 43, 44], "comput": [5, 8, 10, 11, 13, 29, 41, 43, 44, 45, 64, 73, 75, 93, 98, 99, 102, 105, 111, 116, 117, 122], "addit": [5, 8, 31, 51, 61, 62, 63, 67, 70, 75, 76, 80, 111], "train_load": [5, 13], "get_train_load": 5, "loss_fn": 5, "get_user_loss_fn": 5, "label": [5, 45, 114, 119], "train_dataload": 5, "zero_grad": [5, 119], "same": [5, 8, 10, 15, 37, 38, 49, 52, 62, 63, 70, 80, 92, 93, 101, 104, 111, 119, 121], "loss_tot": 5, "student_loss": [5, 43, 44], "backward": [5, 10, 15, 27, 53, 57, 80, 82, 101, 119], "dataparallel": 5, "break": [5, 15], "featur": [5, 6, 8, 9, 15, 45, 64, 67], "trainer": [5, 13], "revert": [5, 63], "class": [5, 8, 13, 15, 19, 20, 24, 29, 31, 41, 43, 44, 45, 46, 49, 52, 61, 62, 63, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 78, 82, 84, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 101, 105, 106, 107, 109, 110, 119, 120], "modif": [5, 8, 15, 60, 62], "attach": 5, "document": [5, 7, 75, 111], "inform": [5, 8, 47, 52, 62, 70, 75, 92, 93, 105, 111], "get_train_dataload": 6, "sparsity_config": [6, 9], "collect_func": [6, 9, 80, 111, 119], "lambda": [6, 8, 9], "x": [6, 9, 13, 29, 73, 74, 105, 117, 119], "driven": [6, 9], "sparse_magnitud": [6, 9, 104, 111], "doe": [6, 9, 11, 15, 31, 37, 62, 63, 64, 75, 78, 80], "pure": [6, 8, 61], "base": [6, 7, 9, 11, 15, 19, 20, 24, 29, 31, 37, 41, 42, 43, 44, 45, 46, 49, 52, 61, 62, 63, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 80, 82, 84, 87, 88, 89, 90, 91, 92, 93, 97, 98, 99, 101, 104, 105, 106, 107, 109, 110, 118, 119, 120], "substitut": [6, 70], "iter": [6, 19, 24, 43, 53, 62, 63, 80, 92, 93, 111, 114, 119], "dataset": [6, 80, 114], "fine": [6, 8, 9, 10, 13, 67, 111], "tune": [6, 8, 9, 10, 13, 67, 111], "check": [6, 12, 13, 20, 27, 38, 46, 55, 61, 62, 63, 67, 68, 92, 95, 102, 116, 119], "hardwar": [7, 9], "simul": [7, 13, 93], "precis": [7, 11, 12, 13, 37, 75, 93], "test": 7, "best": [7, 12, 15, 19, 67, 70, 80, 105], "trade": 7, "off": 7, "low": [7, 10, 11, 13, 15, 75], "actual": [7, 8, 11, 27, 62, 63, 64, 67, 119], "speedup": [7, 12, 13], "find": [7, 8, 9, 13, 27, 29, 34, 38, 70, 105], "basic": [7, 8, 9, 24, 33, 36, 44, 63, 67, 80, 101], "concept": [7, 60, 75], "practic": [7, 19], "choos": [7, 75, 111, 121], "right": [7, 75, 78], "beta": 7, "allow": [8, 9, 12, 13, 15, 43, 63, 67], "describ": [8, 9, 13, 42, 46, 62, 63, 78, 80, 93, 106, 111], "direct": [8, 13, 92], "transfer": [8, 62, 73], "power": 8, "larger": [8, 75], "meta": [8, 42, 43, 93, 97, 106], "abstract": [8, 44, 67, 72, 101], "awai": 8, "interact": 8, "place": [8, 13, 34, 51, 61, 62, 63, 80, 111, 121], "orign": 8, "line": [8, 12], "code": [8, 13, 36, 46, 53, 78, 95, 106, 121], "calcul": [8, 10, 37, 56, 67, 101, 102, 105], "re": [8, 9, 41, 63], "load": [8, 9, 11, 12, 20, 25, 38, 43, 49, 54, 55, 62, 67, 77, 93, 113, 114], "mto": [8, 9, 13, 62], "restor": [8, 13, 41, 46, 54, 60, 62, 76, 78, 106], "relat": [8, 9, 27, 34, 38, 47], "distillationmodel": [8, 42, 43, 44], "must": [8, 10, 13, 29, 46, 62, 63, 64, 75, 78, 92, 102, 119], "form": [8, 62, 119], "model_cls_or_cal": [8, 119], "model_export": 8, "non": [8, 12, 20, 22, 27, 34, 41, 43, 62, 63, 105, 119], "itself": [8, 93], "avoid": [8, 13, 41, 43, 75, 124], "dict": [8, 12, 19, 24, 27, 34, 35, 37, 38, 41, 42, 43, 44, 46, 49, 53, 54, 57, 61, 62, 63, 65, 67, 70, 75, 76, 78, 80, 93, 104, 106, 109, 110, 111, 117, 119], "upon": [8, 13, 63], "thu": [8, 111], "namespac": 8, "anymor": [8, 63], "expect": [8, 34, 57], "though": [8, 101], "isinst": 8, "still": [8, 63, 70], "dynam": [8, 15, 28, 31, 47, 61, 68, 75, 107, 111, 119], "becom": [8, 11], "subclass": [8, 13, 63, 70, 75, 97], "well": [8, 9, 11, 13, 63, 104, 119, 120], "terminologi": [8, 9], "learnabl": 8, "start": [8, 27, 54, 120], "scratch": 8, "fix": [8, 10, 15, 34, 65, 93, 111], "separ": [8, 10, 13, 37, 62, 73], "task": [8, 40, 44, 62, 67, 80], "implement": [8, 9, 10, 34, 36, 43, 45, 46, 49, 51, 60, 63, 67, 82, 84, 92, 97, 98, 99, 101], "scalar": [8, 43, 45, 80, 82, 93], "broader": 8, "sort": [8, 64], "auxilliari": 8, "hope": 8, "make": [8, 20, 36, 55, 63, 97, 102], "map": [8, 10, 27, 34, 35, 43, 45, 50, 53, 57, 75, 76, 80], "master": [8, 101, 115, 118, 119], "purpos": [8, 47, 60, 101], "reduct": [8, 22, 44, 45], "effici": [8, 9, 92, 98, 99], "prune": [8, 65], "reach": 8, "exceed": 8, "slower": 8, "lotteri": 8, "ticket": 8, "hypothesi": 8, "reason": [8, 101], "behind": [8, 10], "b": 8, "altern": [8, 12], "exist": [8, 9, 49, 51, 62, 63, 92], "often": [8, 11, 13, 34], "One": [8, 37, 73], "whole": [8, 10, 65], "wish": 8, "ideal": [8, 73], "meet": [8, 11, 70, 102], "untrain": 8, "boost": 8, "possess": 8, "satisfactori": 8, "add": [8, 27, 30, 34, 37, 62, 80, 119], "object": [8, 29, 35, 49, 52, 62, 63, 64, 70, 92, 93, 97, 101, 119], "simpl": [8, 9, 12, 13, 84, 120], "enact": 8, "mse": [8, 73], "assumpt": 8, "high": [8, 10, 11, 19, 37, 111], "imit": 8, "possibl": [8, 61, 63, 80, 105], "specifi": [8, 9, 13, 37, 38, 41, 42, 44, 46, 62, 63, 65, 70, 73, 75, 76, 78, 79, 80, 102, 104, 105, 106, 111, 113, 114, 120, 122], "pair": [8, 41, 43, 79], "kei": [8, 12, 13, 42, 44, 54, 61, 62, 63, 75, 76, 79, 80, 104, 111, 119], "dictionari": [8, 9, 12, 13, 15, 24, 27, 29, 38, 41, 42, 43, 61, 62, 63, 67, 75, 76, 79, 80, 104, 111, 119], "respect": [8, 9, 10, 61, 75, 80], "pairwis": 8, "Will": 8, "classifi": 8, "18": 8, "atd": 8, "intermedi": [8, 37, 80], "captur": [8, 80], "pass": [8, 10, 13, 43, 44, 45, 49, 63, 75, 79, 80, 82, 93, 101, 102, 119], "argument": [8, 9, 22, 42, 43, 44, 62, 63, 64, 67, 73, 75, 79, 80, 101, 111, 113, 114, 119], "write": [8, 37, 49, 95], "custom": [8, 12, 20, 35, 37, 61, 63, 75, 76, 97], "especi": 8, "handl": [8, 13, 15, 62, 63, 66, 95, 97, 108], "sever": [8, 63], "valu": [8, 10, 12, 13, 35, 36, 38, 41, 42, 43, 44, 45, 46, 52, 56, 61, 63, 64, 70, 74, 75, 78, 79, 80, 90, 93, 101, 102, 106, 107, 111, 119], "backpropag": [8, 43], "whose": 8, "interfac": [8, 44, 62, 65, 67, 109], "distillationlossbalanc": [8, 43, 44], "fill": [8, 105], "aforement": 8, "ones": [8, 105], "scenario": [8, 10, 11], "classif": 8, "known": 8, "In": [8, 11, 63, 70, 75, 76, 80, 119], "even": [8, 13, 29], "altogeth": 8, "prefer": [8, 12], "over": [8, 19, 29, 38, 61, 63, 67, 80, 88, 114], "whatev": 8, "ground": 8, "truth": 8, "dens": [9, 52], "retrain": 9, "simplest": [9, 10, 13], "wai": [9, 10, 13, 63, 119], "dataload": [9, 13, 114], "magnitud": [9, 106, 111], "automodelforcausallm": 9, "from_pretrain": [9, 13], "eleutherai": 9, "gpt": [9, 70], "j": 9, "calib_dataload": 9, "sparse_model": 9, "threshold": 9, "futur": [9, 13, 111], "modelopt_sparse_model": 9, "pth": 9, "along": [9, 10, 75, 97, 102], "mask": [9, 43, 45, 105, 107, 109, 110, 111], "later": [9, 11, 13, 93, 104], "opt": [9, 11, 13, 15, 62], "unmodifi": [9, 62, 63], "plain": 9, "enforc": [9, 61, 62, 63, 64, 111], "remov": [9, 27, 38, 49, 63, 105, 110, 119], "longer": [9, 13, 55, 63, 75, 100, 111], "dure": [9, 10, 13, 37, 43, 46, 62, 75, 93, 99, 111, 124], "do": [9, 34, 44, 49, 63, 75, 78, 101], "overview": [9, 10, 14], "fraction": 9, "zero": [9, 35, 73, 101, 105], "broadli": 9, "categor": [9, 22], "randomli": 9, "distribut": [9, 15, 26], "across": [9, 10, 49, 52, 55, 63, 93, 121], "matrix": [9, 105, 110], "flexibl": 9, "lead": 9, "poor": 9, "other": [9, 10, 15, 20, 49, 55, 63, 70, 75, 76, 79], "hand": 9, "exploit": 9, "math": [9, 10], "throughput": [9, 11, 12], "special": [9, 13, 44, 63, 75, 76], "grain": [9, 10], "block": [9, 11, 13, 29, 51, 56, 63, 75, 93, 98, 99, 111, 121], "contigu": [9, 54, 55], "element": [9, 27, 36, 105, 117, 119, 121], "most": [9, 10, 11], "nonzero": 9, "due": [9, 13, 70], "benefit": 9, "bandwidth": [9, 10, 11], "core": [9, 15, 92], "deliv": 9, "multipli": [9, 45], "oper": [9, 10, 11, 15, 22, 37, 117, 119], "On": 9, "amper": [9, 11], "four": 9, "There": [9, 101], "mani": [9, 101], "commonli": [9, 10], "approach": 9, "largest": 9, "retain": [9, 102], "rest": 9, "brain": 9, "surgeon": 9, "better": [9, 12], "consist": [10, 20, 61, 63, 92], "found": [10, 27, 45, 61, 63], "topic": 10, "width": [10, 19], "integ": [10, 11, 29, 73, 74, 75, 93, 101], "sign": [10, 36, 93, 101], "mantissa": [10, 75], "float": [10, 19, 29, 35, 36, 44, 45, 51, 52, 64, 67, 70, 73, 75, 80, 87, 89, 90, 92, 99, 101, 110, 117, 118, 119, 120, 121], "point": [10, 11, 13, 35, 75], "expon": [10, 75], "explan": 10, "unscal": 10, "rang": [10, 37, 64, 75, 82, 93, 101, 102], "share": [10, 37, 38, 49, 53, 70, 80], "divid": 10, "common": [10, 13, 20, 34, 36, 38, 54], "global": [10, 35, 74, 80], "channel": [10, 11, 12, 45, 63, 73, 75, 93, 102, 119], "dimens": [10, 29, 36, 38, 45, 75, 102], "typic": [10, 11, 12, 13], "gptq": 10, "stai": 10, "help": [10, 31, 119], "constrain": 10, "adjust": [10, 13, 56, 76, 79], "maxim": [10, 67, 105], "max": [10, 11, 13, 19, 29, 52, 64, 75, 79, 80, 82, 84, 87, 89, 90, 92, 101, 117], "maximum": [10, 74, 102, 114], "unchang": [10, 63], "round": [10, 29, 52], "nearest": [10, 29], "entropi": [10, 30, 37, 73], "view": 10, "updat": [10, 13, 29, 38, 46, 51, 57, 61, 62, 63, 76, 78, 93, 106, 111], "compar": [10, 75, 92, 119], "straight": [10, 101], "estim": [10, 15, 64, 75, 80, 101], "ste": 10, "clip": [10, 30, 75, 82, 93, 101], "explicit": [10, 12], "graph": [10, 15, 27, 34, 35, 38, 122], "represent": [10, 46, 53, 75, 78, 106], "qdq": [10, 12, 27, 31, 34, 35, 75], "node": [10, 12, 13, 15, 27, 34, 35, 37, 38, 53], "network": [10, 49, 110], "three": [11, 27, 80], "primari": 11, "compon": [11, 44], "context": [11, 43, 52, 63, 90, 92, 100, 101, 102, 118], "small": [11, 13], "bound": [11, 44, 67, 84], "limit": 11, "cach": [11, 13, 15, 19, 24, 35, 37, 120], "regim": 11, "give": [11, 119], "superior": 11, "improv": 11, "16": [11, 24, 64], "densiti": 11, "crucial": 11, "consequ": [11, 63], "lower": [11, 61, 84], "choic": [11, 37, 63, 64, 70, 80, 121], "suggest": [11, 80], "priorit": [11, 61], "caus": [11, 34], "veri": 11, "littl": 11, "strong": 11, "try": [11, 122], "earlier": [11, 104], "sq": 11, "might": [11, 13, 62, 63, 80, 101, 119], "toler": 11, "tabl": [11, 75], "summar": 11, "tradeoff": 11, "consid": [11, 22], "medium": 11, "min": [11, 64, 82, 84, 113, 117], "50": 11, "ada": 11, "hopper": 11, "variant": [11, 20, 36], "w4a16": [11, 75], "wise": [11, 13, 27, 43, 75], "25": 11, "ten": 11, "w4a8": [11, 52, 75], "impact": 11, "measur": [11, 54, 120], "10": [11, 12, 13, 15], "popular": 11, "ll": 11, "subject": [11, 22, 80], "togeth": [12, 13, 52, 62, 63], "eq": 12, "advantag": [12, 13], "offer": [12, 13], "expert": [12, 13, 51, 52], "white": 12, "box": 12, "design": 12, "vision": 12, "new": [12, 15, 35, 46, 61, 63, 78, 97, 102], "rule": [12, 13, 27, 61, 63, 70, 80, 107], "real": [12, 13, 75, 79, 93, 96, 97], "6": [12, 29], "link": [12, 15, 54, 70], "done": [12, 13, 36, 111], "random": [12, 15, 24, 38], "npz": [12, 53, 57], "npy": 12, "numpi": [12, 24, 35, 37, 38, 74, 93, 122], "arrai": [12, 35, 36, 37, 74, 93, 122], "calib_data": 12, "np": [12, 54, 73], "randn": 12, "batch_siz": [12, 38, 92, 114], "h": [12, 105], "w": [12, 29, 63, 105], "multi": [12, 49], "match": [12, 13, 27, 34, 61, 75, 76, 80, 104, 116], "input_nam": [12, 27, 38], "shape": [12, 19, 22, 24, 35, 38, 45, 52, 55, 74, 92, 93, 101], "input_name2": 12, "shape2": 12, "savez": 12, "moq": 12, "calibration_data": [12, 24, 37], "calibration_data_path": 12, "onnx_path": [12, 24, 26, 27, 29, 30, 33, 37, 38], "output_path": [12, 26, 29, 30, 37], "quant": [12, 37, 78], "quantize_mod": [12, 37], "m": [12, 75, 101, 105], "path": [12, 15, 19, 20, 24, 27, 37, 38, 49, 53, 55, 57, 59, 93, 113], "calibraton": 12, "tool": [12, 20, 22, 60], "insert": [12, 13, 27, 35, 62, 70], "friendli": [12, 30], "chang": [12, 15, 22, 43, 62, 70, 74, 80], "behavior": [12, 62, 63, 82], "tweak": 12, "param": [12, 119], "op_types_to_quant": [12, 22, 26, 30, 33, 37], "op_types_to_exclud": [12, 26, 27, 30, 37], "trtexec": 12, "usr": 12, "src": [12, 27], "bin": [12, 73], "previou": [12, 13], "saveengin": 12, "report": [12, 120], "latenc": [12, 67], "field": [12, 41, 52, 54, 61, 75, 104], "flag": [12, 37, 62], "implicit": 12, "nativ": [13, 15, 34], "hug": [13, 15], "face": [13, 15, 80], "fake": [13, 62, 75, 93, 97, 101], "mean": [13, 37, 53, 111, 117], "cover": 13, "128": [13, 73, 75, 80, 101], "512": [13, 24, 75, 80, 114], "sampl": [13, 19, 24, 63, 114, 119, 121], "collect": [13, 20, 27, 34, 49, 70, 71, 73, 74, 75, 93, 110], "statist": [13, 71, 75, 80, 93, 102], "around": 13, "select": [13, 22, 29, 37, 48, 63, 79, 105, 121], "look": [13, 34, 44, 61, 63], "verifi": 13, "let": [13, 63], "summari": [13, 80], "successfulli": 13, "print_quant_summari": [13, 80], "normal": [13, 22, 31, 64, 86, 88, 111, 119], "flow": [13, 22], "sample_input": 13, "onnx_fil": 13, "recov": 13, "resourc": 13, "directli": [13, 42, 63, 93, 101], "frozen": [13, 107], "int8_default_cfg": [13, 75], "calib_set": 13, "rate": 13, "durat": 13, "schedul": 13, "epoch": 13, "less": [13, 92], "suffici": [13, 31], "resum": [13, 60], "modelopt_st": [13, 62, 93], "save_model": 13, "restore_from_modelopt_st": [13, 62], "un": [13, 76], "under": [13, 53], "hood": 13, "linear": [13, 22, 27, 51, 52, 54, 70, 75, 80, 89, 90, 102, 104], "conv": [13, 26, 30, 34, 37, 51, 52], "patch": [13, 28, 32, 33, 63], "paramet": [13, 15, 19, 20, 22, 24, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 67, 68, 70, 71, 73, 74, 75, 76, 79, 80, 84, 92, 93, 97, 98, 99, 101, 102, 105, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 122], "quantizerattributeconfig": [13, 15, 73, 74, 75, 76, 80, 87, 89, 90, 92, 93], "thei": [13, 38, 41, 63, 75, 80, 93, 104, 111, 119], "set_from_attribute_config": [13, 15, 76, 93], "explicitli": [13, 28, 61, 63], "quant_x": 13, "quantizer_custom": 13, "num_bit": [13, 51, 73, 74, 75, 87, 89, 90, 92, 93, 101], "block_siz": [13, 29, 75, 87, 89, 90, 92, 93, 97, 98, 99], "disabl": [13, 15, 80, 92, 93, 102], "who": 13, "wildcard": [13, 75, 76, 80], "filter": [13, 75, 76, 80], "copi": [13, 15, 22, 75], "quant_cfg": [13, 75, 76, 80, 114], "bmm": 13, "output_quant": [13, 51, 90], "true": [13, 19, 26, 29, 30, 38, 41, 43, 52, 53, 55, 57, 62, 63, 67, 73, 75, 76, 80, 84, 87, 89, 90, 92, 93, 101, 102, 116, 119], "howev": [13, 63, 70, 80], "regist": [13, 15, 61, 63, 64, 76, 101, 110], "them": [13, 15, 36, 37, 45, 52, 55, 60, 63, 80, 93, 97, 119], "unsupport": 13, "kv": [13, 19], "attent": [13, 51, 52, 56], "layernorm": [13, 51, 52, 76], "quantlayernorm": [13, 76], "__init__": [13, 19, 20, 24, 29, 31, 44, 45, 49, 52, 62, 63, 64, 67, 70, 73, 74, 76, 84, 92, 93, 97, 120], "self": [13, 62, 63, 64, 76, 90, 92], "normalized_shap": [13, 76], "super": [13, 76], "_setup": [13, 63, 76], "input_quant": [13, 75, 76, 80, 90, 92], "weight_quant": [13, 73, 75, 76, 80, 90, 92], "anywher": 13, "f": [13, 62, 76], "layer_norm": [13, 76], "bia": [13, 52, 76, 101], "ep": [13, 52, 76], "so": [13, 37, 48, 52, 61, 63, 70, 73, 74, 92], "instanti": [13, 20], "attribut": [13, 15, 51, 63, 75, 76, 80, 93, 97, 119], "original_cl": [13, 63, 76], "quantized_cl": [13, 76], "fold": [13, 63, 80], "repeat": [13, 117], "inferec": 13, "fold_weight": [13, 80], "quantized_model": 13, "user_evaluate_func": 13, "refactor": 13, "extend": [13, 61, 63], "statement": 13, "instal": [14, 15, 102], "distil": [14, 41, 43, 44, 45, 46, 47], "sparsiti": [14, 15, 104, 105, 106, 107, 108, 109, 111], "changelog": 14, "contact": 14, "u": 14, "faq": 14, "deprec": [15, 73, 94, 100, 118], "quantdescriptor": 15, "tensorquant": [15, 51, 75, 76, 80, 90, 92, 93], "backend": [15, 115], "compat": [15, 51, 53, 57, 59, 62, 63, 80, 97, 119], "ad": [15, 27, 37, 46, 62, 63, 93, 101, 111], "rnn": [15, 92], "lstm": 15, "gru": 15, "now": [15, 34, 78], "dbrx": 15, "upgrad": 15, "experiment": [15, 79, 80, 101], "auto_quant": [15, 70, 80], "search": [15, 60, 62, 63, 67, 68, 70, 75, 80, 106, 109, 110, 111, 121], "qlora": 15, "nf4": [15, 99], "pack": [15, 36, 53, 54, 92, 97, 98, 99], "align": 15, "misc": 15, "warn": [15, 61, 119], "lt": [15, 75], "drop": 15, "releas": 15, "been": [15, 62, 80], "medusa": [15, 51], "decod": [15, 20, 51, 52, 53, 57], "offici": 15, "medusamodel": 15, "gptmodel": 15, "recurrentgemma": [15, 52], "spars": [15, 104, 105, 106, 107, 109, 110, 111], "fit": [15, 52], "vllm": 15, "wa": [15, 67, 119], "renam": 15, "ammo": 15, "full": [15, 49, 51, 52, 61, 62, 75], "product": 15, "being": [15, 63], "inference_gpu": 15, "model_config_export": 15, "torch_to_tensorrt_llm_checkpoint": [15, 53], "chain": [15, 78], "set_data_parallel_group": [15, 115], "set_tensor_parallel_group": [15, 115], "float8": 15, "fsdp": [15, 41, 43], "fulli": [15, 63], "shard": 15, "window": [15, 22], "win_amd64": 15, "wheel": 15, "submodul": [15, 63, 104], "bug": 15, "issu": [15, 41, 119, 123], "dim": [15, 75], "opset": 15, "neg": 15, "pb": 15, "tmp": [15, 53, 59], "folder": 15, "tensorrt_llm": [18, 19, 20, 52, 53, 57], "level": [19, 27, 63, 80, 111], "runner": 19, "hlapi": 19, "profil": [19, 119], "valid": [19, 38, 55, 61, 63], "engine_dir": 19, "token": [19, 20, 59, 75, 114], "kv_cache_config": 19, "tokenizerbas": 19, "int": [19, 29, 35, 38, 45, 49, 51, 52, 53, 55, 56, 57, 63, 64, 68, 70, 73, 75, 80, 92, 93, 97, 98, 99, 102, 105, 114, 115, 117, 119], "blob": [19, 20, 22, 53, 101, 119], "main": [19, 20, 22, 31, 42, 53], "doc": [19, 53, 61, 101], "sourc": [19, 46, 53, 78, 95, 106, 113], "perf": 19, "md": [19, 53, 101], "generate_text": 19, "prompt": 19, "max_new_token": 19, "temperatur": [19, 45], "keep_input_prompt": 19, "text": [19, 20, 114], "string": [19, 42, 62, 73, 75, 76, 79, 80, 105, 111, 118, 119], "length": [19, 64, 92, 102, 114], "bool": [19, 26, 27, 29, 30, 36, 37, 38, 41, 43, 46, 51, 52, 53, 55, 61, 62, 63, 67, 68, 73, 75, 78, 80, 92, 105, 106, 114, 115, 116, 119], "prommpt": 19, "max_beam_width": 19, "2d": [19, 87], "beam": 19, "generate_token": 19, "3d": [19, 87, 88], "sequence_len": 19, "properti": [19, 20, 43, 46, 49, 52, 61, 62, 63, 64, 67, 70, 74, 78, 92, 93, 106, 109, 110], "get": [19, 61, 63, 65, 67, 68, 70, 75, 93, 105, 109, 110, 114, 115, 119, 120], "instanc": [19, 41, 42, 43, 54, 62, 63, 68, 75, 76, 80, 88, 93, 97, 111, 114], "max_input_len": 19, "customsentencepiecetoken": 20, "pretrainedtoken": [20, 114], "sentencepiecetoken": 20, "nemo_exampl": 20, "sh": 20, "constructor": [20, 43, 44, 45, 75, 119], "legaci": 20, "batch_decod": 20, "id": [20, 54], "introduc": 20, "batch_encode_plu": 20, "ignor": [20, 80], "mmethod": 20, "encod": [20, 57], "return_tensor": 20, "max_length": 20, "eos_token": 20, "eos_token_id": 20, "pad_token": 20, "pad_token_id": 20, "get_nemo_token": 20, "tokenizer_cfg_path": 20, "logic": [20, 36, 51, 57, 67], "get_nmt_token": 20, "nlp": 20, "tokenizer_util": 20, "py": [20, 22, 53, 119], "get_tokenzi": 20, "tokenizer_dir_or_path": 20, "dir": [20, 49], "subpackag": [21, 23, 39, 40], "op": [22, 27, 30, 31, 33, 34, 37, 62], "is_binary_op": 22, "whether": [22, 27, 35, 36, 43, 46, 49, 51, 53, 62, 63, 64, 67, 78, 101, 111, 114, 115, 119], "binari": 22, "is_control_flow_op": 22, "control": [22, 75], "categori": 22, "is_conversion_op": 22, "is_copy_op": 22, "is_default_quantizable_op_by_ort": 22, "ort": [22, 31, 32, 33], "nodes_to_quant": [22, 26, 30, 34, 37], "microsoft": 22, "onnxruntim": [22, 33], "registri": [22, 61, 62, 63], "is_fusible_reduction_op": 22, "fusibl": [22, 34], "myelin": [22, 27, 30], "is_generator_op": 22, "is_irregular_mem_access_op": 22, "irreggular": 22, "mem": 22, "is_linear_op": 22, "is_modifier_op": 22, "modifi": [22, 27, 31, 35, 38, 43, 61, 62, 63, 80, 107], "is_multiclass_op": 22, "multiclass": 22, "is_non_reshape_copy_op": 22, "reshap": [22, 105], "is_normalization_op": 22, "is_pointwise_or_elementwise_op": 22, "pointwis": [22, 34, 45], "elementwis": 22, "is_pooling_or_window_op": 22, "pool": [22, 91], "is_recurrent_op": 22, "is_selection_op": 22, "is_sequence_op": 22, "sequenc": [22, 35, 36, 64, 65, 70, 92, 116, 121], "is_shape_op": 22, "is_unary_op": 22, "unari": 22, "calibrationdataprovid": 24, "calibrationdataread": [24, 26, 29, 30], "intial": [24, 49], "ndarrai": [24, 29, 35, 36, 37, 38, 54, 57, 122], "ex": [24, 27], "64": [24, 55, 75], "timestep": 24, "encoder_hidden_st": 24, "768": 24, "1024": [24, 75], "get_next": 24, "reader": 24, "randomdataprovid": 24, "import_scales_from_calib_cach": 24, "cache_path": 24, "float_scal": 24, "tensor_nam": 24, "gemm": [26, 29, 30, 37], "modelproto": [26, 29, 30, 38], "calibration_method": [26, 29, 30, 37], "calibration_data_read": [26, 29, 30], "calibration_cache_path": [26, 30, 37], "nodes_to_exclud": [26, 27, 30, 37], "use_external_data_format": [26, 29, 30, 37], "intermediate_generated_fil": [26, 30], "verbos": [26, 27, 30, 37, 80, 111], "fals": [26, 29, 30, 37, 38, 41, 43, 52, 53, 61, 62, 63, 67, 73, 74, 75, 76, 80, 84, 87, 89, 90, 92, 93, 101, 114, 116, 119, 124], "trt_extra_plugin_lib_path": [26, 30, 32, 33], "matmul": [26, 27, 30, 34, 37], "placement": 27, "add_fp16_fp32_cast": 27, "custom_ops_to_cast_to_fp16": 27, "cast_to_fp16": 27, "cast_to_fp32": 27, "build_non_residual_input_map": 27, "residu": [27, 34], "subgraph": [27, 34], "convolut": [27, 87], "sum": [27, 44, 70, 105], "anoth": [27, 62, 63], "constant": [27, 35, 38, 51, 54, 57, 75], "becaus": [27, 29, 57, 80, 113, 119], "occur": [27, 51, 57, 75], "modern": 27, "convnet": 27, "connect": 27, "v": [27, 52, 80, 119], "classify_partition_nod": 27, "partit": [27, 37], "outsid": 27, "algo": 27, "dst": 27, "filter_quantizable_kgen_head": 27, "cask_fusible_partit": 27, "kgen_partit": 27, "quantizable_op_typ": [27, 34], "kgen": [27, 34], "head": [27, 51], "cask": [27, 34], "find_fp8_mha_partit": 27, "mha": [27, 34, 37], "q": [27, 29, 35, 37, 52, 80], "dq": [27, 35, 37], "bmm1": [27, 37], "mul": [27, 30, 34], "div": [27, 34], "softmax": [27, 34], "cast": [27, 37], "bmm2": [27, 37], "find_mha_partit": [27, 34], "find_nodes_to_exclud": 27, "exclus": 27, "get_fusible_backbon": 27, "backbon": [27, 34], "fuse": [27, 34, 80], "bn": 27, "relu": 27, "some": [27, 34, 36, 41, 43, 51, 57, 65, 74, 82], "tri": 27, "those": [27, 34, 104], "biasadd": 27, "constmul": 27, "has_const_input": 27, "has_path_typ": 27, "path_typ": 27, "is_forward": 27, "wild_card_typ": 27, "path_nod": 27, "wrt": [27, 70], "travers": [27, 34], "wild": 27, "card": 27, "skip": [27, 63, 73, 75, 80], "accumul": [27, 37, 119], "insert_fp8_mha_cast": 27, "onnx_model": [27, 29, 38], "input0": 27, "fp32": [27, 37], "second": [27, 38], "input1": 27, "back": [27, 60, 63, 97], "part": 27, "forbid": 27, "insert_matmul_cast": 27, "matmul_nod": 27, "is_const_input": 27, "const": 27, "foldabl": 27, "print_stat": 27, "stat": [27, 67, 80, 111, 117], "remove_partial_input_qdq": 27, "no_quantize_input": 27, "mark": 27, "onnx_graphsurgeon": 28, "patch_gs_modul": 28, "graphsurgeon": [28, 35], "woq": 29, "awqcliphelp": 29, "helper": [29, 36], "alpha_step": [29, 75], "05": [29, 52, 75], "alpha": [29, 75], "55": 29, "65": [29, 45], "7": 29, "75": 29, "85": 29, "9": [29, 57], "95": 29, "min_alpha": 29, "update_best_param": 29, "dq_tensor": 29, "dequant": [29, 35, 93, 97, 98, 99, 101], "find_scal": 29, "quant_tensor": 29, "awq_clip": [29, 75, 79], "quantize_awq_clip": 29, "data_read": 29, "force_fp16": 29, "k": [29, 52, 80], "quantize_rtn": 29, "gemm_io_typ": 29, "dq_onli": [29, 35], "rtn": 29, "ab": [29, 45, 82], "round_to_even": 29, "denot": 29, "ti": 29, "alwai": 29, "cin": 29, "plug": 29, "rh": 29, "y": [29, 119], "googl": [29, 35, 101], "protobuf": [29, 35], "intern": [29, 35, 63, 121], "enum_type_wrapp": [29, 35], "enumtypewrapp": [29, 35], "0x7f2e8de70cb0": [29, 35], "broken": 29, "heurist": 30, "averagepool": 30, "batchnorm": 30, "convtranspos": [30, 31], "globalaveragepool": 30, "maxpool": 30, "top": [31, 62, 63], "qdqconvtranspos": 31, "qdqoperatorbas": 31, "onnx_quant": 31, "onnx_nod": 31, "init": [31, 92], "qdqnormal": 31, "intend": [31, 63], "contain": [32, 42, 60, 61, 62, 63, 67, 78, 80, 93, 98, 99, 111, 119], "patch_ort_modul": 32, "shoul": 33, "ort_client": 33, "configure_ort": 33, "op_typ": [33, 37, 38], "create_inference_sess": 33, "inferencesess": 33, "get_quantizable_op_typ": 33, "_configure_ort": 33, "suppli": 33, "find_fusible_partit": 34, "partitioned_nod": 34, "non_residual_input": 34, "find_hardcoded_pattern": 34, "tail": 34, "mtl_v1": 34, "reducesum": 34, "sub": [34, 60, 67], "pow": 34, "sqrt": 34, "find_layer_norm_partit": 34, "norm": 34, "find_non_quantizable_partitions_from_pattern": 34, "certain": [34, 62, 63, 80], "counterpart": [34, 63, 80], "find_quantizable_nod": 34, "yet": [34, 80], "get_skiped_output_lay": 34, "paritially_quantizable_nod": 34, "insert_dq_nod": 35, "quantized_weight": 35, "insert_qdq_nod": 35, "weight_map": 35, "make_gs_dequantize_nod": 35, "_basename_": 35, "make_gs_dequantize_output": 35, "variabl": [35, 38, 75, 92, 93, 119], "repres": [35, 63, 64, 101, 119], "make_gs_quantize_nod": 35, "make_gs_quantize_output": 35, "make_gs_quantized_weight": 35, "wq": 35, "make_gs_scal": 35, "make_gs_zp": 35, "replace_scale_valu": 35, "act_scales_dict": 35, "graphproto": [35, 38], "use_trt_qdq_op": 35, "trt": [35, 57], "pack_float32_to_4bit_cpp_bas": 36, "float32": [36, 93, 101], "4bit": 36, "everi": 36, "concecut": 36, "byte": [36, 38, 120], "pack_float32_to_4bit": 36, "round_and_pack": 36, "suppos": 36, "unsign": [36, 73, 74, 75, 87, 89, 90, 92, 93, 101], "ceil": 36, "pack_float32_to_4bit_optim": 36, "mainli": 36, "reli": 36, "move": [36, 73, 122], "therebi": 36, "remain": [36, 63], "keep_intermediate_fil": 37, "trt_plugin": 37, "trt_plugins_precis": 37, "high_precision_dtyp": 37, "mha_accumulation_dtyp": 37, "disable_mha_qdq": 37, "minmax": 37, "aka": 37, "indic": [37, 42, 62, 64, 67, 75, 78, 101, 111, 119, 121], "express": [37, 104], "exclud": 37, "conv__224": 37, "conv__252": 37, "keep": [37, 70, 92, 97], "filenam": 37, "suffix": [37, 44, 118], "throughout": 37, "int4_rtn": 37, "int4_rtn_dq": 37, "int4_rtn_trt": 37, "int4_rtn_trt_dq": 37, "int4_awq_clip": 37, "int4_awq_clip_trt": 37, "semicolon": 37, "lib_1": 37, "lib_2": 37, "tensorrtexecutionprovid": 37, "space": [37, 63, 67, 68, 70, 121], "item": [37, 55, 61], "op_type_1": 37, "op_type_2": 37, "model_nam": [37, 52], "duplicate_shared_const": 38, "duplic": [38, 63, 105], "find_lowest_common_ancestor": 38, "node1": 38, "node2": 38, "lowest": 38, "ancestor": 38, "lca": 38, "distanc": 38, "gen_random_input": 38, "get_all_input_nam": 38, "get_batch_s": 38, "assert": [38, 62], "fail": 38, "get_batch_size_from_byt": 38, "onnx_byt": 38, "get_child_nod": 38, "consum": [38, 53], "get_input_nam": 38, "external_inputs_onli": 38, "extern": 38, "external_input_nam": 38, "initializer_nam": 38, "get_input_names_from_byt": 38, "model_byt": 38, "get_input_shap": 38, "get_input_shapes_from_byt": 38, "get_node_nam": 38, "get_node_names_from_byt": 38, "get_output_nam": 38, "get_output_names_from_byt": 38, "get_output_shap": 38, "get_parent_nod": 38, "get_variable_input": 38, "is_valid_onnx_model": 38, "file_path": 38, "name_onnx_nod": 38, "assign": [38, 63, 75], "statu": 38, "randomize_weight": 38, "randomize_weights_onnx_byt": 38, "seed": [38, 121], "remove_weights_data": 38, "raw": 38, "save_onnx": 38, "save_as_external_data": 38, "save_onnx_bytes_to_dir": 38, "onnx_dir": 38, "onnx_nam": 38, "udpate_domain": 38, "domain": 38, "validate_batch_s": 38, "equal": [38, 64], "validate_onnx": 38, "els": [38, 51], "modeloptconfig": [41, 61, 75, 104], "kdlossconfig": [41, 42], "modeloptbaseconfig": [41, 46, 61, 62, 75, 78, 104, 106], "null": [41, 75, 104], "expose_minimal_state_dict": [41, 43], "_loss": [41, 43, 45], "student_layer_nam": 41, "teacher_layer_nam": 41, "loss_modul": [41, 43], "hide": [41, 43], "unnecessarili": [41, 43], "again": [41, 63], "balanc": [41, 43, 44, 75], "weigh": [41, 43], "scheme": [41, 43, 75], "init_model_from_model_lik": [41, 119], "cannot": [41, 111, 119], "model_dump": [41, 61], "dump": [41, 61], "serial": [41, 49, 119], "dataclass": 41, "turn": 42, "_modedescriptor": [42, 46, 62, 78, 106, 111], "encapsul": [42, 43], "inner": 42, "dynamicmodul": [43, 47, 63, 64, 90, 92, 107, 119], "loss_reduction_fn": 43, "skip_balanc": 43, "total": [43, 44, 75, 80], "prior": [43, 44], "situat": 43, "posit": [43, 51, 75], "hide_loss_modul": 43, "manag": [43, 60, 62, 63, 93, 100, 102], "temporarili": [43, 63], "hide_teacher_model": 43, "overrid": [43, 67], "fetch": 43, "modulelist": [43, 51], "would": [43, 44, 73, 75, 111], "aggreg": 44, "_": 44, "idx": 44, "uniqu": [44, 53, 63, 105, 119], "And": [44, 51, 52], "student_loss_kei": 44, "mod1_": 44, "mod1_t": 44, "mseloss": 44, "mod2_": 44, "mod2_t": 44, "mseloss_0": 44, "mseloss_1": 44, "kd": [44, 45], "set_student_loss_reduction_fn": 44, "student_loss_reduction_fn": 44, "static": [44, 62, 75, 82, 87, 89, 90, 92, 93, 97, 101], "kd_loss_weight": 44, "rais": [44, 62, 74, 84, 101, 102], "valueerror": [44, 84, 101, 102], "kl": 45, "diverg": 45, "paper": [45, 75, 82, 111], "arxiv": [45, 82], "1503": 45, "02531": 45, "batchmean": 45, "soften": 45, "logits_t": 45, "logits_": 45, "final": [45, 51, 63, 67], "afterward": [45, 63], "treat": 45, "predict": [45, 114], "last": [45, 62, 75, 119], "mgdloss": 45, "2205": 45, "01529": 45, "num_student_channel": 45, "num_teacher_channel": 45, "alpha_mgd": 45, "lambda_mgd": 45, "ratio": [45, 75, 105], "out_": 45, "out_t": 45, "bxcxhxw": 45, "na": [46, 121], "mtn": [46, 119, 121], "exportstudentmodedescriptor": 46, "inspect": [46, 51, 78, 106], "config_class": [46, 78, 106], "entrypoint": [46, 67, 78, 106], "is_export_mod": [46, 78, 106], "knowledgedistillationmodedescriptor": 46, "export_mod": [46, 78, 106], "next_mod": [46, 78, 106], "immedi": [46, 78], "update_for_new_mod": [46, 78, 106], "hold": 47, "far": [48, 74], "nfsworkspac": 49, "workspac": [49, 53], "storag": [49, 97, 98, 99], "nf": [49, 53], "modifit": 49, "commun": [49, 53], "nor": 49, "barrier": [49, 115], "respons": 49, "synchron": [49, 93, 115, 121], "workspace_path": [49, 53, 55], "postprocess": [49, 53, 79], "cross": [49, 53], "sharedmemori": 49, "clean": [49, 93], "is_initi": [49, 115], "read_configs_and_weights_from_rank": 49, "target_rank": 49, "target": [49, 53, 54, 55, 62, 63, 98, 99, 114, 119], "write_configs_and_weight": 49, "config_json": 49, "get_configs_parallel": 49, "gather": [49, 80], "shm": 49, "nullabl": 49, "sync": 49, "yield": [49, 53, 62, 63, 68, 75, 80, 93, 111], "empti": [49, 55, 101, 104, 119], "destroi": [49, 111], "consumpt": 49, "get_tensors_parallel": 49, "model_config": [51, 53, 54, 55, 57], "empir": [51, 57], "except": [51, 57, 93, 104, 118], "build_attention_config": 51, "model_metadata_config": 51, "ext_config": 51, "decoderlayerconfig": [51, 52, 57], "attentionconfig": [51, 52], "build_conv_config": 51, "convconfig": [51, 52], "build_decoder_config": 51, "build_embedding_config": 51, "normalization_const": 51, "embed": [51, 52, 55, 73], "embeddingconfig": [51, 52], "build_layernorm_config": 51, "layernormconfig": [51, 52], "build_linear_config": 51, "linear_typ": [51, 52], "linearconfig": [51, 52, 54], "build_medusa_heads_config": 51, "medusaheadconfig": [51, 52], "num_medusa_head": [51, 52], "medsua_head": 51, "compos": 51, "lm_head": [51, 52, 54, 55, 75, 80, 104], "vocab_s": [51, 52], "hidden_s": [51, 52], "num_medusa_lay": [51, 52], "linearactconfig": [51, 52], "hidden_act": [51, 52], "silu": 51, "column": [51, 52, 102], "build_mlp_config": 51, "mlp": [51, 52, 80], "mlpconfig": [51, 52], "build_moe_config": 51, "moe": [51, 75], "moeconfig": [51, 52], "build_qkv": 51, "qkv_modul": 51, "qkv": [51, 52, 54], "qkvconfig": [51, 52, 54], "build_recurrent_config": 51, "build_stacked_expert": 51, "linear_nam": 51, "num_expert": 51, "expert_gett": 51, "experts_weight_1": 51, "experts_weight_2": 51, "check_model_compat": 51, "module_list": 51, "assembl": 51, "get_activation_scaling_factor": 51, "get_kv_cache_dtyp": 51, "kv_cach": 51, "union": [51, 64], "get_kv_cache_scaling_factor": 51, "get_prequant_scaling_factor": 51, "prequant": [51, 52], "get_quantization_format": 51, "get_scaling_factor": 51, "get_transformer_lay": 51, "root": [51, 62], "get_weight_block_s": 51, "get_weight_scaling_factor": 51, "get_weight_scaling_factor_2": 51, "secondari": 51, "is_attent": 51, "is_decoder_list": 51, "is_embed": 51, "is_layernorm": 51, "is_linear": 51, "is_mlp": 51, "is_mo": 51, "is_quantlinear": 51, "is_recurr": 51, "kv_cache_scaling_factor": 52, "kv_cache_dtyp": 52, "rotary_dim": 52, "inf": 52, "clip_qkv": 52, "rel_attn_t": 52, "input_layernorm": 52, "mlp_layernorm": 52, "post_layernorm": 52, "pre_feedforward_layernorm": 52, "post_feedforward_layernorm": 52, "num_attention_head": 52, "attention_head_s": 52, "num_kv_head": 52, "max_position_embed": 52, "rotary_pct": 52, "use_alibi": 52, "new_decoder_architectur": 52, "parallel_attent": 52, "apply_residual_connection_post_layernorm": 52, "use_cach": 52, "rope_ratio": 52, "seq_length": 52, "qwen_typ": 52, "rotary_bas": 52, "partial_rotary_factor": 52, "original_max_position_embed": 52, "longrope_scaling_short_factor": 52, "longrope_scaling_long_factor": 52, "mup_attn_multipli": 52, "mup_embedding_multipli": 52, "mup_use_sc": 52, "mup_width_multipli": 52, "blocksparse_block_s": 52, "blocksparse_homo_head_pattern": 52, "blocksparse_num_local_block": 52, "blocksparse_vertical_strid": 52, "dense_attention_every_n_lay": 52, "gegelu_limit": 52, "longrope_short_mscal": 52, "longrope_long_mscal": 52, "moe_num_expert": 52, "moe_top_k": 52, "moe_tp_mod": 52, "moe_renorm_mod": 52, "alibi_bias_max": 52, "residual_layernorm": 52, "residual_mlp": 52, "rnn_hidden_s": 52, "logits_soft_cap": 52, "emb_scale_by_sqrt_dim": 52, "layer_typ": 52, "factori": 52, "final_logit_softcap": 52, "attn_logit_softcap": 52, "query_pre_attn_scalar": 52, "cross_attent": 52, "cross_attention_layernorm": 52, "self_attent": 52, "self_attention_layernorm": 52, "attention_layernorm": 52, "rel_attn_max_dist": 52, "rel_attn_num_bucket": 52, "use_scaled_rop": 52, "recurrentconfig": 52, "ffn_hidden_size_loc": 52, "ffn": 52, "hidden": [52, 92], "local_vocab_s": 52, "expertconfig": 52, "fc": 52, "proj": 52, "layernorm_typ": 52, "1e": 52, "activation_scaling_factor": 52, "weights_scaling_factor": [52, 54], "weights_scaling_factor_2": 52, "prequant_scaling_factor": 52, "awq_block_s": 52, "gate": [52, 75], "merged_fc1_g": 52, "mixtur": 52, "router": [52, 75], "medusa_lay": 52, "modelconfig": [52, 54, 55, 57], "pipeline_parallel": 52, "float16": [52, 53, 93], "tensor_parallel": 52, "vocab_embed": 52, "position_embed": 52, "ln_emb": 52, "ln_f": 52, "share_embedding_t": 52, "medusa_head": 52, "enc_dec": [52, 57], "encoder_hidden_s": 52, "encoder_num_head": 52, "encoder_head_s": 52, "num_key_value_head": 52, "vocab_size_pad": 52, "pad": [52, 54, 55, 119], "merg": [52, 53, 54, 55, 56], "concat": 52, "quanitz": 52, "weight_scaling_factor_2": 52, "recurrentblock": 52, "linear_i": 52, "y_bia": 52, "linear_x": 52, "linear_out": 52, "conv1d": [52, 87], "rg_lru": 52, "rglruconfig": 52, "rg": 52, "lru": 52, "recurrent_param": 52, "input_g": 52, "recurrent_g": 52, "export_hf_checkpoint": 53, "unifi": [53, 73], "export_npz": 53, "naive_fp8_quant": 53, "use_nfs_workspac": 53, "split": [53, 54, 55, 73], "manual": 53, "old": 53, "naiv": 53, "nest": [53, 54], "pretrainedconfig": 53, "modeling_util": 53, "tensorrt_llm_config": [53, 57], "from_quantized_weight": 54, "torch_dtyp": 54, "merge_fc1_g": 54, "merge_qkv": 54, "model_config_from_dict": 54, "d": [54, 70], "model_config_to_dict": 54, "naive_quant": 54, "debug": [54, 75], "pack_linear_weight": 54, "pad_weight": 54, "tp_size": [54, 57], "restore_model_config": 54, "recurs": [54, 63, 68, 76, 122], "split_config_and_weight": 54, "prefix": [54, 93], "to_quantized_weight": 54, "check_weight_shape_valid": 55, "training_tensor_parallel": 55, "tp": [55, 57], "recurisv": 55, "pad_embedding_lm_head": 55, "padding_factor": 55, "postprocess_model_config": 55, "training_pipeline_parallel": 55, "pp": 55, "postprocess_tensor": 55, "force_cpu": 55, "force_contigu": 55, "force_non_view": 55, "cpu": [55, 73], "adjust_attn_amax_valu": 56, "amax": [56, 73, 74, 75, 79, 93, 101, 102], "get_weights_scaling_factor": 56, "group_siz": 56, "facotr": 56, "resmooth_and_get_scal": 56, "merged_weight": 56, "pre_quant_scal": [56, 93], "avg_pre_quant_scal": 56, "resmooth": 56, "averag": 56, "weight_scaling_factor": 56, "convert_to_tensorrt_llm_config": 57, "tp_size_overwrit": 57, "overwrit": [57, 63, 104], "builder": 57, "unshard": 57, "is_tensorrt_llm_0_8_or_9": 57, "prepare_enc_dec_decoder_lay": 57, "layer_config": 57, "prepar": [57, 65, 70, 110, 114], "t5config": 57, "prepare_enc_dec_export_dir": 57, "export_root": 57, "weights_to_npz": 57, "convert_to_transformer_engin": 58, "transformers_engin": 58, "export_to_vllm": 59, "export_path": 59, "infrastructur": 60, "ingest": 60, "procedur": [60, 61, 67, 80], "individu": [60, 63, 93, 111], "wihin": 60, "pydant": 61, "basemodel": 61, "our": 61, "capabl": 61, "easier": [61, 73], "manipul": 61, "alia": [61, 64, 87, 89, 91], "get_field_name_from_kei": 61, "alias": 61, "itemsview": 61, "keysview": 61, "model_dump_json": 61, "valuesview": 61, "modeloptbaserul": 61, "what": 61, "govern": 61, "classmethod": [61, 62, 63, 70, 97, 98, 99], "customize_rul": 61, "construct": [61, 63, 92, 93], "accord": [61, 63, 82, 111, 119], "get_rule_typ": 61, "wrapped_onli": 61, "typealia": 61, "validate_rul": 61, "cl": [61, 97], "unwrap": [61, 62, 119], "modeloptbaseruleconfig": [61, 104], "made": 61, "register_default": 61, "extra_default": 61, "unregister_default": 61, "unregist": [61, 76], "modeloptfield": 61, "pydanticundefin": 61, "get_kwargs_for_create_model_with_rul": 61, "default_rul": 61, "create_model": 61, "auto": [61, 114], "relev": 61, "rule_field": 61, "docstr": 61, "pertain": 61, "myruleconfig": 61, "get_create_model_kwargs_for_rule_model": 61, "sparsemagnitudeconfig": [61, 104, 111], "conveni": 61, "sinc": [61, 73, 78], "autodoc": 61, "workaround": 61, "burden": 61, "standard": [62, 63, 64, 67, 97, 111, 119], "histori": [62, 67, 80], "modeloptstatemanag": 62, "correspondig": 62, "init_st": 62, "add_mod": 62, "_state": 62, "therefor": [62, 63], "recal": 62, "check_mod": 62, "propos": 62, "get_config_class": 62, "has_stat": 62, "trivial": 62, "is_convert": 62, "is_root": 62, "detect": 62, "last_mod": 62, "modes_with_st": 62, "transfer_state_dict": 62, "model_from": 62, "model_to": [62, 119], "update_last_state_before_new_mod": 62, "update_last_state_before_sav": 62, "apply_mod": 62, "quantizemodedescriptor": [62, 78], "_moderegistrycl": 62, "retriev": [62, 119], "error": [62, 75, 78, 94, 100, 118], "bias": 62, "model_weight": 62, "pathlik": 62, "binaryio": 62, "locat": [62, 76], "distributeddataparallel": 62, "previous": [62, 106], "hparam": [63, 68, 70], "famili": 63, "searchabl": 63, "unit": [63, 65, 119], "candid": 63, "dynamicconv2d": 63, "callback": [63, 64], "out_channel": 63, "temporari": [63, 93], "ensur": [63, 80, 119], "expos": 63, "outermost": 63, "child": [63, 73], "dynamiclinear": 63, "inherit": 63, "__class__": 63, "henc": [63, 80, 107], "simultan": 63, "inject": 63, "rigoruo": 63, "fashion": 63, "vanilla": 63, "mechan": 63, "parent": [63, 76], "mutual": 63, "exlus": 63, "append": [63, 80], "dyanmic": 63, "affect": [63, 119], "underli": 63, "kept": [63, 75, 119], "until": [63, 119], "resultign": 63, "extra_repr": [63, 93], "sure": 63, "__dict__": 63, "heavili": 63, "force_assign": 63, "forc": 63, "overwritt": 63, "buffer": [63, 93], "circumst": 63, "freez": 63, "restrict": [63, 70, 80], "tbe": 63, "orgin": 63, "although": [63, 64], "get_hparam": [63, 68], "get_paramet": 63, "scalabl": 63, "overriden": 63, "out_features_ratio": 63, "system": 63, "keyword": [63, 73, 113, 119], "_dmregistrycl": 63, "fly": [63, 92], "leav": 63, "intact": 63, "some_dynamic_modul": 63, "named_hparam": [63, 68], "accordingli": [63, 76], "symbol": [63, 64, 101], "reset_dynamic_attribut": 63, "interf": 63, "getattr": 63, "setattr": 63, "delattr": 63, "exit": 63, "dynamicspac": 63, "hyperparamet": [63, 64, 67], "hp": 63, "parameter_nam": 63, "subnet": [63, 67, 106, 121], "convert_to_dynam": 63, "dm_registri": 63, "result": [63, 80, 121], "is_configur": [63, 64, 68], "is_dynam": [63, 68], "named_dynamic_modul": 63, "strict": [63, 93], "exact": 63, "ident": 64, "activeslic": 64, "slice": 64, "longtensor": 64, "importanceestim": 64, "customhptyp": [64, 70], "active_slic": 64, "enforce_ord": 64, "32": [64, 75], "equival": [64, 75, 76, 80], "_order": 64, "todo": 64, "ever": [64, 78], "cycl": 64, "detector": 64, "1d": [64, 87, 105], "in_channel": 64, "conv2d": [64, 75, 87, 101, 104], "score": [64, 67, 70, 80, 111], "associ": 64, "notion": 64, "is_sort": 64, "sortabl": 64, "register_import": 64, "importance_estim": 64, "constitut": 65, "arbitrari": 65, "whenev": 67, "conjunct": [67, 124], "basesearch": [67, 70, 106, 109], "abc": 67, "after_search": [67, 110], "before_search": [67, 70, 110], "constraint": [67, 70, 75, 80], "construct_forward_loop": 67, "silent": 67, "progress_bar_msg": 67, "max_iter_data_load": 67, "post_process_fn": [67, 79], "runnabl": 67, "default_search_config": [67, 70, 109, 110], "default_state_dict": [67, 70, 109], "dummy_input": [67, 119], "eval_scor": 67, "has_scor": 67, "load_search_checkpoint": 67, "reset_search": 67, "reset": [67, 73, 74, 93], "begin": 67, "run_search": [67, 70, 109], "sanitize_search_config": [67, 70, 109], "sanit": [67, 70, 109], "save_search_checkpoint": 67, "prunabl": 67, "net": [67, 119], "score_func": 67, "satisfi": [67, 113], "upper": [67, 84], "metric": 67, "flop": 67, "convent": [67, 101], "search_space_s": 68, "autoquantizesearch": [70, 80], "searcher": [70, 105, 110], "autoquant": 70, "program": 70, "solver": 70, "approxim": [70, 111, 121], "particular": 70, "taylor": 70, "expans": 70, "fisher": 70, "hessian": [70, 110, 111], "mathemat": 70, "log": 70, "likelihood": 70, "bert": 70, "proxi": 70, "resnet": 70, "candidate_stat": 70, "insert_quant_recipe_hparam": 70, "quant_recip": 70, "quantrecipehparam": 70, "quantrecip": 70, "merge_search_hparam_by_rul": 70, "q_proj": [70, 80], "k_proj": [70, 80], "v_proj": [70, 80], "gate_proj": 70, "up_proj": 70, "w1": 70, "w2": 70, "w3": 70, "w1_linear": 70, "w2_linear": 70, "w3_linear": 70, "quantizeconfig": [70, 75, 80], "unsupported_recip": 70, "track": [70, 74], "nn_modul": 70, "link_to": 70, "histogramcalibr": 73, "_calibr": [73, 74, 75], "compute_amax": [73, 74, 93], "percentil": 73, "axi": [73, 74, 75, 87, 89, 90, 92, 93, 102], "boolean": [73, 74, 84, 93, 101, 102], "num_bin": 73, "2048": [73, 75], "grow_method": 73, "skip_zero": 73, "torch_hist": 73, "histc": 73, "stride": 73, "start_bin": 73, "99": 73, "100": 73, "calibrate_weight": 73, "perchannel": 73, "collector": 73, "But": 73, "haven": 73, "decoupl": 73, "decid": [73, 101], "NOT": [73, 101], "everyth": 73, "neuron": 73, "absolut": [74, 102], "maxcalibr": 74, "calib_desc": 74, "maxcalibdescriptor": 74, "readonli": 74, "plot": 74, "track_amax": 74, "runtimeerror": 74, "definit": [75, 80], "cnn": 75, "fp8_default_cfg": [75, 80], "int4_awq_cfg": 75, "w4a8_awq_beta_cfg": 75, "against": [75, 76, 80], "miss": 75, "sequentialquant": [75, 76, 90, 92, 93], "sequenti": [75, 93, 104], "entri": [75, 76, 102], "quantmoduleregistri": 75, "class_nam": 75, "get_kei": 75, "my_quant_cfg": 75, "leakyrelu": 75, "block_sparse_mo": 75, "int4_blockwise_weight_only_cfg": 75, "awq_lit": [75, 79], "awq_ful": [75, 79], "max_co_batch_s": [75, 79], "These": 75, "custom_int4_awq_cfg": 75, "deepcopi": 75, "awqclipcalibconfig": [75, 79], "quantizealgorithmconfig": 75, "lite": 75, "oom": 75, "out_featur": 75, "max_tokens_per_batch": 75, "min_clip_ratio": 75, "shrink_step": 75, "gt": 75, "le": 75, "awqfullcalibconfig": [75, 79], "awqlitecalibconfig": [75, 79], "maxcalibconfig": [75, 79], "smoothquantcalibconfig": [75, 79], "realquantizeconfig": [75, 79], "fake_qu": [75, 87, 89, 90, 92, 93], "narrow_rang": [75, 87, 89, 90, 92, 93, 101], "learn_amax": [75, 87, 89, 90, 92], "trt_high_precision_dtyp": [75, 87, 89, 90, 92, 93, 101], "ax": 75, "input_tensor": [75, 102], "kcr": 75, "quant_axi": 75, "scale_bit": 75, "scale_block_s": [75, 99], "histogram": 75, "standardize_constructor_arg": [75, 119], "narrow": 75, "emul": 75, "fpx": 75, "half": 75, "bfloat16": [75, 93], "additional_algorithm": [75, 79], "smooth": 75, "outlier": 75, "hyper": 75, "migrat": 75, "strength": 75, "difficulti": 75, "ge": 75, "replace_quant_modul": 76, "set_quantizer_attribut": 76, "quant_model": 76, "wildcard_or_filter_func": [76, 80], "parent_class": 76, "finegrain": 76, "set_quantizer_by_cfg": 76, "get_cuda_ext": 77, "extent": 77, "tensor_qu": [77, 93], "get_cuda_ext_fp8": 77, "tensor_quant_fp8": 77, "descriptor": [78, 106], "quantizeexportmodedescriptor": 78, "placehold": [78, 94, 100], "throw": [78, 94, 100], "properli": 78, "update_for_sav": [78, 106], "4096": 79, "real_quant": 79, "postprocess_amax": 79, "loss_func": 80, "weight_compress": 80, "quantization_format": 80, "num_calib_step": 80, "num_score_step": 80, "gradient": [80, 82, 101, 102, 111, 119], "sensit": 80, "30": 80, "percentag": 80, "impli": 80, "basi": 80, "run_forward_loop": [80, 111, 119], "increas": 80, "taken": [80, 119], "progress": [80, 119], "belong": 80, "regex": 80, "r": 80, "readili": 80, "disable_quant": 80, "enable_quant": 80, "anyth": 80, "entir": 80, "subsampl": 80, "clipfunct": 82, "univers": [82, 101], "clamp": [82, 84], "doesn": [82, 92, 102], "broadcast": [82, 101], "genar": 82, "ibm": 82, "pact": 82, "1805": 82, "06085": 82, "tensorflow": [82, 101, 119], "clip_by_valu": 82, "ctx": [82, 101], "grad_output": [82, 101], "clip_value_min": [82, 84], "clip_value_max": [82, 84], "learn_min": 84, "learn_max": 84, "similar": [84, 93], "quantconv1d": 87, "quantconv2d": 87, "conv3d": 87, "quantconv3d": 87, "convtranspose1d": 87, "quantconvtranspose1d": 87, "convtranspose2d": 87, "quantconvtranspose2d": 87, "convtranspose3d": 87, "quantconvtranspose3d": 87, "_legacyquantlinearconvbasemixin": [87, 89], "default_quant_desc_weight": [87, 89, 90, 92], "transpos": 87, "quantinstancenorm1d": 88, "_legacyquantinputbasemixin": [88, 91], "instancenorm1d": 88, "quantinstancenorm2d": 88, "instancenorm2d": 88, "4d": 88, "quantinstancenorm3d": 88, "instancenorm3d": 88, "5d": 88, "quantlinear": 89, "quantinputbas": 90, "default_quant_desc_input": [90, 92], "default_quant_desc_output": 90, "quantlinearconvbas": 90, "initialize_quantizer_with_dummy_st": 90, "dummi": 90, "devic": [90, 114, 119, 120], "quantize_weight": [90, 92], "adaptiveavgpool1d": 91, "quantadaptiveavgpool1d": 91, "adaptiveavgpool2d": 91, "quantadaptiveavgpool2d": 91, "adaptiveavgpool3d": 91, "quantadaptiveavgpool3d": 91, "avgpool1d": 91, "quantavgpool1d": 91, "avgpool2d": 91, "quantavgpool2d": 91, "avgpool3d": 91, "quantavgpool3d": 91, "maxpool1d": 91, "quantmaxpool1d": 91, "maxpool2d": 91, "quantmaxpool2d": 91, "maxpool3d": 91, "quantmaxpool3d": 91, "quantrnnbas": 92, "all_input_quantizers_dis": 92, "functionals_to_replac": 92, "quantrnnfullbas": 92, "rnnlayerforward": 92, "cell": 92, "revers": 92, "variable_len": 92, "vfrnnforward": 92, "reimplement": 92, "_vf": 92, "oringin": 92, "bidirect": 92, "num_lay": 92, "has_proj": 92, "has_bia": 92, "proj_input_quant": 92, "batch_first": 92, "vf": 92, "overhead": 92, "layer_forward": 92, "flat_weight": 92, "dropout": 92, "get_quantized_rnn_layer_forward": 92, "signatur": [92, 119], "get_quantized_rnn_layer_variable_len_forward": 92, "get_quantized_rnn_layer_variable_len_reverse_forward": 92, "lstm_cell_with_proj": 92, "lstm_cell": 92, "project": 92, "h_n": 92, "c_n": 92, "quantized_cell_forward": 92, "container": 93, "get_modelopt_st": 93, "replace_sequential_quantizer_with_single_quant": 93, "indx": 93, "attribute_dict": 93, "tensor_quantizer_iter": 93, "quant_attribute_cfg": 93, "if_quant": 93, "if_clip": 93, "_learn_amax": 93, "if_calib": 93, "clean_up_after_set_from_modelopt_st": 93, "set_from_modelopt_st": 93, "qtensor": [93, 97], "de": 93, "basequantizedtensor": [93, 97, 98, 99], "bypass": 93, "neither": 93, "disable_calib": 93, "disable_clip": 93, "stage": 93, "disable_qu": 93, "enable_calib": 93, "enable_clip": 93, "enable_qu": 93, "export_amax": 93, "output_dtyp": [93, 101], "init_learn_amax": 93, "is_en": 93, "load_calib_amax": 93, "maxbound": 93, "symmetr": [93, 101], "reset_amax": 93, "attribute_cfg": 93, "step_siz": 93, "sync_amax_across_distributed_group": 93, "parallel_group": 93, "distributedprocessgroup": [93, 115], "freeze_paramet": 94, "group_paramet": 94, "match_paramet": 94, "quant_weight_inplac": 94, "apex": 95, "original_meta_tensor": 97, "quantized_data": [97, 98, 99], "quantizedtensor": 97, "fake_quant_tensor": 97, "qtensorwrapp": 97, "__new__": 97, "int4qtensor": 98, "uint8": [98, 99], "dequantz": [98, 99], "nf4qtensor": 99, "double_quant": 99, "num_scale_bit": 99, "unlik": 99, "deactiv": [100, 104, 119], "enable_onnx_export": 100, "fakeaffinetensorquantfunct": 101, "affin": 101, "gemmlowp": 101, "style": 101, "shift": 101, "cancel": 101, "come": 101, "penalti": 101, "grad_input": 101, "min_rang": 101, "max_rang": 101, "granular": [101, 102], "faketensorquantfunct": 101, "tensorquantfunct": 101, "legacyfaketensorquantfunct": 101, "comment": 101, "scalede4m3funct": 101, "e4m3fi": 101, "interpret": [101, 119], "127": 101, "grad_scal": 101, "natur": 101, "int32": 101, "255": 101, "scaled_e4m3_abstract": 101, "scaled_e4m3": 101, "export_torch_mod": 102, "is_quant": 102, "is_quantized_column_parallel_linear": 102, "is_quantized_layer_with_weight": 102, "is_quantized_row_parallel_linear": 102, "row": 102, "is_torch_library_support": 102, "exce": 102, "reduce_amax": 102, "keepdim": 102, "unless": 102, "never": 102, "meant": 102, "deprect": 102, "sens": 102, "unknown": 102, "replace_funct": 102, "new_func": 102, "exportsparseconfig": [104, 106], "export_spars": [104, 106], "sparsegptconfig": [104, 111], "sparse_gpt": 104, "sparseconv2dconfig": 104, "shown": 104, "glob": 104, "unnest": 104, "short": 104, "sparselinearconfig": 104, "inspir": 105, "magnitudesearch": 105, "basesparsesearch": [105, 109, 110], "compute_valid_1d_pattern": 105, "vector": 105, "permut": 105, "create_asp_mask": 105, "m4n2_1d": 105, "booltensor": [105, 107], "get_nmprune_info": 105, "mat": 105, "mn_1d_best": 105, "reshape_1d": 105, "dimension": 105, "hw": 105, "exportsparsemodedescriptor": 106, "sparsegptmodedescriptor": 106, "sparsemagnitudemodedescriptor": 106, "search_algorithm": 106, "convert_sparse_model": 106, "restore_export_spars": 106, "restore_sparse_model": 106, "update_sparse_metadata": 106, "sparsemodul": 107, "set_mask": 107, "sparsegptsearch": 110, "artifcat": 110, "hook": [110, 119], "create_sgpt_mask": 110, "invert": 110, "hessian_damp": 110, "invers": 110, "finish": 111, "carefulli": 111, "runtim": 111, "significantli": 111, "fewer": 111, "cpp": 113, "load_cpp_extens": 113, "cuda_version_specifi": 113, "fail_msg": 113, "load_kwarg": 113, "instantan": 113, "create_forward_loop": 114, "dataset_nam": 114, "cnn_dailymail": 114, "max_sample_length": 114, "tailor": 114, "feed": [114, 119], "preprocess": 114, "suitabl": 114, "pretrainedtokenizerfast": 114, "get_dataset_dataload": 114, "include_label": 114, "tokniz": 114, "instancn": 114, "hugginfac": 114, "get_data_parallel_group": 115, "get_tensor_parallel_group": 115, "is_avail": 115, "is_mast": 115, "processgroup": 115, "list_closest_to_median": 117, "closest": [117, 121], "val": 117, "avg": 117, "std": 117, "val2list": 117, "repeat_tim": 117, "val2tupl": 117, "min_len": 117, "idx_repeat": 117, "deprecatederror": 118, "notimplementederror": 118, "no_stdout": 118, "silenc": 118, "stdout": 118, "num2hrb": 118, "num": 118, "big": 118, "human": 118, "readabl": 118, "print_rank_0": 118, "compare_dict": 119, "dict1": 119, "dict2": 119, "unmatch": 119, "create_param_grad_clear_hook": 119, "clear": [119, 120], "fire": 119, "accum_grad": 119, "aliv": 119, "long": 119, "get_model_attribut": 119, "get_module_devic": 119, "get_same_pad": 119, "kernel_s": 119, "is_channels_last": 119, "is_parallel": 119, "make_divis": 119, "divisor": 119, "min_val": 119, "tf": 119, "repo": 119, "divis": 119, "seen": 119, "research": 119, "slim": 119, "mobilenet": 119, "target_model": 119, "layout": 119, "param_num": 119, "trainable_onli": 119, "1000000": 119, "count": 119, "trainabl": 119, "1e6": 119, "million": 119, "param_num_from_forward": 119, "circumv": 119, "appear": 119, "remove_bn": 119, "max_it": 119, "progress_bar": 119, "post_process": 119, "infiinit": 119, "exhaust": 119, "z": 119, "imag": 119, "descript": 119, "bar": 119, "set_submodul": 119, "target_submodul": 119, "complement": 119, "get_submodul": 119, "constructor_arg": 119, "standardize_model_arg": 119, "model_or_fw_or_sig": 119, "use_kwarg": 119, "matter": 119, "were": 119, "kw_only_arg": 119, "standardize_model_like_tupl": 119, "standardize_named_model_arg": 119, "args_norm": 119, "args_with_default": 119, "exactli": 119, "unwrap_model": 119, "raise_error": 119, "msg": 119, "timer": 120, "contextdecor": 120, "decor": 120, "stop": 120, "clear_cuda_cach": 120, "get_cuda_memory_stat": 120, "report_memori": 120, "determinist": 121, "centroid": 121, "seq": 121, "prod": 121, "aim": 121, "cheapli": 121, "median": 121, "recogn": 121, "popul": 121, "shuffl": 121, "mutablesequ": 121, "numpy_to_torch": 122, "np_output": 122, "torch_detach": 122, "detach": 122, "torch_to": 122, "torch_to_numpi": 122, "submit": 123}, "objects": {"modelopt": [[17, 0, 0, "-", "deploy"], [21, 0, 0, "-", "onnx"], [39, 0, 0, "-", "torch"]], "modelopt.deploy": [[18, 0, 0, "-", "llm"]], "modelopt.deploy.llm": [[19, 0, 0, "-", "generate"], [20, 0, 0, "-", "nemo_utils"]], "modelopt.deploy.llm.generate": [[19, 1, 1, "", "LLM"]], "modelopt.deploy.llm.generate.LLM": [[19, 2, 1, "", "__init__"], [19, 2, 1, "", "generate_text"], [19, 2, 1, "", "generate_tokens"], [19, 3, 1, "", "max_beam_width"], [19, 3, 1, "", "max_input_len"]], "modelopt.deploy.llm.nemo_utils": [[20, 1, 1, "", "CustomSentencePieceTokenizer"], [20, 4, 1, "", "get_nemo_tokenizer"], [20, 4, 1, "", "get_tokenzier"]], "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer": [[20, 2, 1, "", "__init__"], [20, 2, 1, "", "batch_decode"], [20, 2, 1, "", "batch_encode_plus"], [20, 2, 1, "", "decode"], [20, 2, 1, "", "encode"], [20, 3, 1, "", "eos_token"], [20, 3, 1, "", "eos_token_id"], [20, 3, 1, "", "pad_token"], [20, 3, 1, "", "pad_token_id"]], "modelopt.onnx": [[22, 0, 0, "-", "op_types"], [23, 0, 0, "-", "quantization"], [38, 0, 0, "-", "utils"]], "modelopt.onnx.op_types": [[22, 4, 1, "", "is_binary_op"], [22, 4, 1, "", "is_control_flow_op"], [22, 4, 1, "", "is_conversion_op"], [22, 4, 1, "", "is_copy_op"], [22, 4, 1, "", "is_default_quantizable_op_by_ort"], [22, 4, 1, "", "is_fusible_reduction_op"], [22, 4, 1, "", "is_generator_op"], [22, 4, 1, "", "is_irregular_mem_access_op"], [22, 4, 1, "", "is_linear_op"], [22, 4, 1, "", "is_modifier_op"], [22, 4, 1, "", "is_multiclass_op"], [22, 4, 1, "", "is_non_reshape_copy_op"], [22, 4, 1, "", "is_normalization_op"], [22, 4, 1, "", "is_pointwise_or_elementwise_op"], [22, 4, 1, "", "is_pooling_or_window_op"], [22, 4, 1, "", "is_recurrent_op"], [22, 4, 1, "", "is_selection_op"], [22, 4, 1, "", "is_sequence_op"], [22, 4, 1, "", "is_shape_op"], [22, 4, 1, "", "is_unary_op"]], "modelopt.onnx.quantization": [[24, 0, 0, "-", "calib_utils"], [25, 0, 0, "-", "extensions"], [26, 0, 0, "-", "fp8"], [27, 0, 0, "-", "graph_utils"], [28, 0, 0, "-", "gs_patching"], [29, 0, 0, "-", "int4"], [30, 0, 0, "-", "int8"], [31, 0, 0, "-", "operators"], [32, 0, 0, "-", "ort_patching"], [33, 0, 0, "-", "ort_utils"], [34, 0, 0, "-", "partitioning"], [35, 0, 0, "-", "qdq_utils"], [36, 0, 0, "-", "quant_utils"], [37, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.calib_utils": [[24, 1, 1, "", "CalibrationDataProvider"], [24, 1, 1, "", "RandomDataProvider"], [24, 4, 1, "", "import_scales_from_calib_cache"]], "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider": [[24, 2, 1, "", "__init__"], [24, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.calib_utils.RandomDataProvider": [[24, 2, 1, "", "__init__"], [24, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.fp8": [[26, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.graph_utils": [[27, 4, 1, "", "add_fp16_fp32_cast"], [27, 4, 1, "", "build_non_residual_input_map"], [27, 4, 1, "", "classify_partition_nodes"], [27, 4, 1, "", "filter_quantizable_kgen_heads"], [27, 4, 1, "", "find_fp8_mha_partitions"], [27, 4, 1, "", "find_mha_partitions"], [27, 4, 1, "", "find_nodes_to_exclude"], [27, 4, 1, "", "get_fusible_backbone"], [27, 4, 1, "", "has_const_input"], [27, 4, 1, "", "has_path_type"], [27, 4, 1, "", "insert_fp8_mha_casts"], [27, 4, 1, "", "insert_matmul_casts"], [27, 4, 1, "", "is_const_input"], [27, 4, 1, "", "print_stat"], [27, 4, 1, "", "remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[28, 4, 1, "", "patch_gs_modules"]], "modelopt.onnx.quantization.int4": [[29, 1, 1, "", "AWQClipHelper"], [29, 4, 1, "", "dq_tensor"], [29, 4, 1, "", "find_scales"], [29, 4, 1, "", "quant_tensor"], [29, 4, 1, "", "quantize"], [29, 4, 1, "", "quantize_awq_clip"], [29, 4, 1, "", "quantize_rtn"], [29, 4, 1, "", "rtn"]], "modelopt.onnx.quantization.int4.AWQClipHelper": [[29, 2, 1, "", "__init__"], [29, 5, 1, "", "alpha_step"], [29, 5, 1, "", "alphas"], [29, 5, 1, "", "min_alpha"], [29, 2, 1, "", "update_best_params"]], "modelopt.onnx.quantization.int8": [[30, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.operators": [[31, 1, 1, "", "QDQConvTranspose"], [31, 1, 1, "", "QDQNormalization"]], "modelopt.onnx.quantization.operators.QDQConvTranspose": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.operators.QDQNormalization": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.ort_patching": [[32, 4, 1, "", "patch_ort_modules"]], "modelopt.onnx.quantization.ort_utils": [[33, 4, 1, "", "configure_ort"], [33, 4, 1, "", "create_inference_session"], [33, 4, 1, "", "get_quantizable_op_types"]], "modelopt.onnx.quantization.partitioning": [[34, 4, 1, "", "find_fusible_partitions"], [34, 4, 1, "", "find_hardcoded_patterns"], [34, 4, 1, "", "find_layer_norm_partitions"], [34, 4, 1, "", "find_mha_partitions"], [34, 4, 1, "", "find_non_quantizable_partitions_from_patterns"], [34, 4, 1, "", "find_quantizable_nodes"], [34, 4, 1, "", "get_skiped_output_layers"]], "modelopt.onnx.quantization.qdq_utils": [[35, 4, 1, "", "insert_dq_nodes"], [35, 4, 1, "", "insert_qdq_nodes"], [35, 4, 1, "", "make_gs_dequantize_node"], [35, 4, 1, "", "make_gs_dequantize_output"], [35, 4, 1, "", "make_gs_quantize_node"], [35, 4, 1, "", "make_gs_quantize_output"], [35, 4, 1, "", "make_gs_quantized_weight"], [35, 4, 1, "", "make_gs_scale"], [35, 4, 1, "", "make_gs_zp"], [35, 4, 1, "", "replace_scale_values"], [35, 4, 1, "", "use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[36, 4, 1, "", "pack_float32_to_4bit_cpp_based"], [36, 4, 1, "", "pack_float32_to_4bit_optimized"]], "modelopt.onnx.utils": [[38, 4, 1, "", "duplicate_shared_constants"], [38, 4, 1, "", "find_lowest_common_ancestor"], [38, 4, 1, "", "gen_random_inputs"], [38, 4, 1, "", "get_all_input_names"], [38, 4, 1, "", "get_batch_size"], [38, 4, 1, "", "get_batch_size_from_bytes"], [38, 4, 1, "", "get_child_nodes"], [38, 4, 1, "", "get_input_names"], [38, 4, 1, "", "get_input_names_from_bytes"], [38, 4, 1, "", "get_input_shapes"], [38, 4, 1, "", "get_input_shapes_from_bytes"], [38, 4, 1, "", "get_node_names"], [38, 4, 1, "", "get_node_names_from_bytes"], [38, 4, 1, "", "get_output_names"], [38, 4, 1, "", "get_output_names_from_bytes"], [38, 4, 1, "", "get_output_shapes"], [38, 4, 1, "", "get_parent_nodes"], [38, 4, 1, "", "get_variable_inputs"], [38, 4, 1, "", "is_valid_onnx_model"], [38, 4, 1, "", "name_onnx_nodes"], [38, 4, 1, "", "randomize_weights"], [38, 4, 1, "", "randomize_weights_onnx_bytes"], [38, 4, 1, "", "remove_weights_data"], [38, 4, 1, "", "save_onnx"], [38, 4, 1, "", "save_onnx_bytes_to_dir"], [38, 4, 1, "", "udpate_domain"], [38, 4, 1, "", "validate_batch_size"], [38, 4, 1, "", "validate_onnx"]], "modelopt.torch": [[40, 0, 0, "-", "distill"], [48, 0, 0, "-", "export"], [60, 0, 0, "-", "opt"], [69, 0, 0, "-", "quantization"], [103, 0, 0, "-", "sparsity"], [112, 0, 0, "-", "utils"]], "modelopt.torch.distill": [[41, 0, 0, "-", "config"], [42, 0, 0, "-", "distillation"], [43, 0, 0, "-", "distillation_model"], [44, 0, 0, "-", "loss_balancers"], [45, 0, 0, "-", "losses"], [46, 0, 0, "-", "mode"], [47, 0, 0, "-", "registry"]], "modelopt.torch.distill.config": [[41, 6, 1, "", "KDLossConfig"]], "modelopt.torch.distill.config.KDLossConfig": [[41, 7, 1, "", "criterion"], [41, 7, 1, "", "expose_minimal_state_dict"], [41, 7, 1, "", "loss_balancer"], [41, 2, 1, "", "model_dump"], [41, 7, 1, "", "teacher_model"]], "modelopt.torch.distill.distillation": [[42, 4, 1, "", "convert"], [42, 4, 1, "", "export"]], "modelopt.torch.distill.distillation_model": [[43, 1, 1, "", "DistillationModel"]], "modelopt.torch.distill.distillation_model.DistillationModel": [[43, 2, 1, "", "compute_kd_loss"], [43, 2, 1, "", "forward"], [43, 2, 1, "", "hide_loss_modules"], [43, 2, 1, "", "hide_teacher_model"], [43, 2, 1, "", "load_state_dict"], [43, 3, 1, "", "loss_balancer"], [43, 3, 1, "", "loss_modules"], [43, 2, 1, "", "modify"], [43, 2, 1, "", "state_dict"], [43, 3, 1, "", "teacher_model"]], "modelopt.torch.distill.loss_balancers": [[44, 1, 1, "", "DistillationLossBalancer"], [44, 1, 1, "", "StaticLossBalancer"]], "modelopt.torch.distill.loss_balancers.DistillationLossBalancer": [[44, 2, 1, "", "__init__"], [44, 2, 1, "", "forward"], [44, 2, 1, "", "set_student_loss_reduction_fn"]], "modelopt.torch.distill.loss_balancers.StaticLossBalancer": [[44, 2, 1, "", "__init__"], [44, 2, 1, "", "forward"]], "modelopt.torch.distill.losses": [[45, 1, 1, "", "LogitsDistillationLoss"], [45, 1, 1, "", "MGDLoss"]], "modelopt.torch.distill.losses.LogitsDistillationLoss": [[45, 2, 1, "", "__init__"], [45, 2, 1, "", "forward"]], "modelopt.torch.distill.losses.MGDLoss": [[45, 2, 1, "", "__init__"], [45, 2, 1, "", "forward"]], "modelopt.torch.distill.mode": [[46, 1, 1, "", "ExportStudentModeDescriptor"], [46, 1, 1, "", "KnowledgeDistillationModeDescriptor"]], "modelopt.torch.distill.mode.ExportStudentModeDescriptor": [[46, 3, 1, "", "config_class"], [46, 3, 1, "", "convert"], [46, 3, 1, "", "is_export_mode"], [46, 3, 1, "", "name"], [46, 3, 1, "", "restore"]], "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor": [[46, 3, 1, "", "config_class"], [46, 3, 1, "", "convert"], [46, 3, 1, "", "export_mode"], [46, 3, 1, "", "name"], [46, 3, 1, "", "next_modes"], [46, 3, 1, "", "restore"], [46, 3, 1, "", "update_for_new_mode"]], "modelopt.torch.export": [[49, 0, 0, "-", "distribute"], [50, 0, 0, "-", "hf_config_map"], [51, 0, 0, "-", "layer_utils"], [52, 0, 0, "-", "model_config"], [53, 0, 0, "-", "model_config_export"], [54, 0, 0, "-", "model_config_utils"], [55, 0, 0, "-", "postprocess"], [56, 0, 0, "-", "scaling_factor_utils"], [57, 0, 0, "-", "tensorrt_llm_utils"], [58, 0, 0, "-", "transformer_engine"], [59, 0, 0, "-", "vllm"]], "modelopt.torch.export.distribute": [[49, 1, 1, "", "NFSWorkspace"], [49, 4, 1, "", "get_configs_parallel"], [49, 4, 1, "", "get_tensors_parallel"]], "modelopt.torch.export.distribute.NFSWorkspace": [[49, 2, 1, "", "__init__"], [49, 3, 1, "", "is_initialized"], [49, 2, 1, "", "read_configs_and_weights_from_rank"], [49, 2, 1, "", "write_configs_and_weights"]], "modelopt.torch.export.layer_utils": [[51, 4, 1, "", "build_attention_config"], [51, 4, 1, "", "build_conv_config"], [51, 4, 1, "", "build_decoder_config"], [51, 4, 1, "", "build_embedding_config"], [51, 4, 1, "", "build_layernorm_config"], [51, 4, 1, "", "build_linear_config"], [51, 4, 1, "", "build_medusa_heads_config"], [51, 4, 1, "", "build_mlp_config"], [51, 4, 1, "", "build_moe_config"], [51, 4, 1, "", "build_qkv"], [51, 4, 1, "", "build_recurrent_config"], [51, 4, 1, "", "build_stacked_experts"], [51, 4, 1, "", "check_model_compatibility"], [51, 4, 1, "", "get_activation_scaling_factor"], [51, 4, 1, "", "get_kv_cache_dtype"], [51, 4, 1, "", "get_kv_cache_scaling_factor"], [51, 4, 1, "", "get_prequant_scaling_factor"], [51, 4, 1, "", "get_quantization_format"], [51, 4, 1, "", "get_scaling_factor"], [51, 4, 1, "", "get_transformer_layers"], [51, 4, 1, "", "get_weight_block_size"], [51, 4, 1, "", "get_weight_scaling_factor"], [51, 4, 1, "", "get_weight_scaling_factor_2"], [51, 4, 1, "", "is_attention"], [51, 4, 1, "", "is_decoder_list"], [51, 4, 1, "", "is_embedding"], [51, 4, 1, "", "is_layernorm"], [51, 4, 1, "", "is_linear"], [51, 4, 1, "", "is_mlp"], [51, 4, 1, "", "is_moe"], [51, 4, 1, "", "is_quantlinear"], [51, 4, 1, "", "is_recurrent"]], "modelopt.torch.export.model_config": [[52, 1, 1, "", "AttentionConfig"], [52, 1, 1, "", "ConvConfig"], [52, 1, 1, "", "DecoderLayerConfig"], [52, 1, 1, "", "EmbeddingConfig"], [52, 1, 1, "", "ExpertConfig"], [52, 1, 1, "", "LayernormConfig"], [52, 1, 1, "", "LinearActConfig"], [52, 1, 1, "", "LinearConfig"], [52, 1, 1, "", "MLPConfig"], [52, 1, 1, "", "MOEConfig"], [52, 1, 1, "", "MedusaHeadConfig"], [52, 1, 1, "", "ModelConfig"], [52, 1, 1, "", "QKVConfig"], [52, 1, 1, "", "RecurrentConfig"], [52, 1, 1, "", "RgLruConfig"]], "modelopt.torch.export.model_config.AttentionConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "clip_qkv"], [52, 5, 1, "", "dense"], [52, 5, 1, "", "kv_cache_dtype"], [52, 5, 1, "", "kv_cache_scaling_factor"], [52, 5, 1, "", "qkv"], [52, 5, 1, "", "rel_attn_table"], [52, 5, 1, "", "rotary_dim"]], "modelopt.torch.export.model_config.ConvConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "bias"], [52, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.DecoderLayerConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "alibi_bias_max"], [52, 5, 1, "", "apply_residual_connection_post_layernorm"], [52, 5, 1, "", "attention"], [52, 5, 1, "", "attention_head_size"], [52, 5, 1, "", "attention_layernorm"], [52, 5, 1, "", "attn_logit_softcapping"], [52, 5, 1, "", "blocksparse_block_size"], [52, 5, 1, "", "blocksparse_homo_head_pattern"], [52, 5, 1, "", "blocksparse_num_local_blocks"], [52, 5, 1, "", "blocksparse_vertical_stride"], [52, 5, 1, "", "clip_qkv"], [52, 5, 1, "", "cross_attention"], [52, 5, 1, "", "cross_attention_layernorm"], [52, 5, 1, "", "decoder_type"], [52, 5, 1, "", "dense_attention_every_n_layers"], [52, 5, 1, "", "emb_scale_by_sqrt_dim"], [52, 3, 1, "", "ffn_hidden_size_local"], [52, 5, 1, "", "final_logit_softcapping"], [52, 5, 1, "", "gegelu_limit"], [52, 3, 1, "", "hidden_size"], [52, 5, 1, "", "input_layernorm"], [52, 5, 1, "", "layer_types"], [52, 5, 1, "", "logits_soft_cap"], [52, 5, 1, "", "longrope_long_mscale"], [52, 5, 1, "", "longrope_scaling_long_factors"], [52, 5, 1, "", "longrope_scaling_short_factors"], [52, 5, 1, "", "longrope_short_mscale"], [52, 5, 1, "", "max_position_embeddings"], [52, 5, 1, "", "mlp"], [52, 5, 1, "", "mlp_layernorm"], [52, 5, 1, "", "model_name"], [52, 5, 1, "", "moe_num_experts"], [52, 5, 1, "", "moe_renorm_mode"], [52, 5, 1, "", "moe_top_k"], [52, 5, 1, "", "moe_tp_mode"], [52, 5, 1, "", "mup_attn_multiplier"], [52, 5, 1, "", "mup_embedding_multiplier"], [52, 5, 1, "", "mup_use_scaling"], [52, 5, 1, "", "mup_width_multiplier"], [52, 5, 1, "", "new_decoder_architecture"], [52, 5, 1, "", "num_attention_heads"], [52, 5, 1, "", "num_kv_heads"], [52, 5, 1, "", "original_max_position_embeddings"], [52, 5, 1, "", "parallel_attention"], [52, 5, 1, "", "partial_rotary_factor"], [52, 5, 1, "", "post_feedforward_layernorm"], [52, 5, 1, "", "post_layernorm"], [52, 5, 1, "", "pre_feedforward_layernorm"], [52, 5, 1, "", "quantization"], [52, 5, 1, "", "query_pre_attn_scalar"], [52, 5, 1, "", "qwen_type"], [52, 5, 1, "", "recurrent"], [52, 5, 1, "", "rel_attn_max_distance"], [52, 5, 1, "", "rel_attn_num_buckets"], [52, 5, 1, "", "residual_layernorm"], [52, 5, 1, "", "residual_mlp"], [52, 5, 1, "", "rnn_hidden_size"], [52, 5, 1, "", "rope_ratio"], [52, 5, 1, "", "rotary_base"], [52, 5, 1, "", "rotary_pct"], [52, 5, 1, "", "self_attention"], [52, 5, 1, "", "self_attention_layernorm"], [52, 5, 1, "", "seq_length"], [52, 5, 1, "", "use_alibi"], [52, 5, 1, "", "use_cache"], [52, 5, 1, "", "use_scaled_rope"]], "modelopt.torch.export.model_config.EmbeddingConfig": [[52, 2, 1, "", "__init__"], [52, 3, 1, "", "hidden_size"], [52, 3, 1, "", "local_vocab_size"], [52, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.ExpertConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "fc"], [52, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.LayernormConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "bias"], [52, 5, 1, "", "eps"], [52, 5, 1, "", "layernorm_type"], [52, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.LinearActConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "hidden_act"], [52, 5, 1, "", "linear"]], "modelopt.torch.export.model_config.LinearConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "activation_scaling_factor"], [52, 5, 1, "", "awq_block_size"], [52, 5, 1, "", "bias"], [52, 5, 1, "", "linear_type"], [52, 5, 1, "", "prequant_scaling_factor"], [52, 5, 1, "", "weight"], [52, 5, 1, "", "weights_scaling_factor"], [52, 5, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.MLPConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "fc"], [52, 5, 1, "", "gate"], [52, 5, 1, "", "hidden_act"], [52, 5, 1, "", "merged_fc1_gate"], [52, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.MOEConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "experts"], [52, 3, 1, "", "fc"], [52, 5, 1, "", "hidden_act"], [52, 5, 1, "", "router"]], "modelopt.torch.export.model_config.MedusaHeadConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "lm_head"], [52, 5, 1, "", "medusa_layers"]], "modelopt.torch.export.model_config.ModelConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "dtype"], [52, 5, 1, "", "enc_dec"], [52, 5, 1, "", "encoder_head_size"], [52, 5, 1, "", "encoder_hidden_size"], [52, 5, 1, "", "encoder_num_heads"], [52, 3, 1, "", "hidden_act"], [52, 3, 1, "", "hidden_size"], [52, 5, 1, "", "layers"], [52, 5, 1, "", "lm_head"], [52, 5, 1, "", "ln_embed"], [52, 5, 1, "", "ln_f"], [52, 3, 1, "", "max_position_embeddings"], [52, 5, 1, "", "medusa_heads"], [52, 3, 1, "", "num_attention_heads"], [52, 3, 1, "", "num_kv_heads"], [52, 5, 1, "", "num_medusa_heads"], [52, 5, 1, "", "num_medusa_layers"], [52, 5, 1, "", "pipeline_parallel"], [52, 5, 1, "", "position_embedding"], [52, 5, 1, "", "quantization"], [52, 5, 1, "", "rank"], [52, 5, 1, "", "share_embedding_table"], [52, 5, 1, "", "tensor_parallel"], [52, 5, 1, "", "version"], [52, 5, 1, "", "vocab_embedding"], [52, 5, 1, "", "vocab_size"], [52, 3, 1, "", "vocab_size_padded"]], "modelopt.torch.export.model_config.QKVConfig": [[52, 2, 1, "", "__init__"], [52, 3, 1, "", "activation_scaling_factor"], [52, 3, 1, "", "awq_block_size"], [52, 3, 1, "", "bias"], [52, 5, 1, "", "k"], [52, 3, 1, "", "prequant_scaling_factor"], [52, 5, 1, "", "q"], [52, 5, 1, "", "v"], [52, 3, 1, "", "weight"], [52, 3, 1, "", "weights_scaling_factor"], [52, 3, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.RecurrentConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "conv1d"], [52, 5, 1, "", "linear_out"], [52, 5, 1, "", "linear_x"], [52, 5, 1, "", "linear_y"], [52, 5, 1, "", "rg_lru"], [52, 5, 1, "", "y_bias"]], "modelopt.torch.export.model_config.RgLruConfig": [[52, 2, 1, "", "__init__"], [52, 5, 1, "", "input_gate"], [52, 5, 1, "", "recurrent_gate"], [52, 5, 1, "", "recurrent_param"]], "modelopt.torch.export.model_config_export": [[53, 4, 1, "", "export_hf_checkpoint"], [53, 4, 1, "", "export_tensorrt_llm_checkpoint"], [53, 4, 1, "", "torch_to_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_utils": [[54, 4, 1, "", "from_quantized_weight"], [54, 4, 1, "", "merge_fc1_gate"], [54, 4, 1, "", "merge_qkv"], [54, 4, 1, "", "model_config_from_dict"], [54, 4, 1, "", "model_config_to_dict"], [54, 4, 1, "", "naive_quantization"], [54, 4, 1, "", "pack_linear_weights"], [54, 4, 1, "", "pad_weights"], [54, 4, 1, "", "restore_model_config"], [54, 4, 1, "", "split_config_and_weights"], [54, 4, 1, "", "to_quantized_weight"]], "modelopt.torch.export.postprocess": [[55, 4, 1, "", "check_weight_shape_valid"], [55, 4, 1, "", "pad_embedding_lm_head"], [55, 4, 1, "", "postprocess_model_config"], [55, 4, 1, "", "postprocess_tensors"]], "modelopt.torch.export.scaling_factor_utils": [[56, 4, 1, "", "adjust_attn_amax_values"], [56, 4, 1, "", "get_weights_scaling_factor"], [56, 4, 1, "", "resmooth_and_get_scale"]], "modelopt.torch.export.tensorrt_llm_utils": [[57, 4, 1, "", "convert_to_tensorrt_llm_config"], [57, 4, 1, "", "is_tensorrt_llm_0_8_or_9"], [57, 4, 1, "", "prepare_enc_dec_decoder_layer"], [57, 4, 1, "", "prepare_enc_dec_export_dir"], [57, 4, 1, "", "weights_to_npz"]], "modelopt.torch.export.transformer_engine": [[58, 4, 1, "", "convert_to_transformer_engine"]], "modelopt.torch.export.vllm": [[59, 4, 1, "", "export_to_vllm"]], "modelopt.torch.opt": [[61, 0, 0, "-", "config"], [62, 0, 0, "-", "conversion"], [63, 0, 0, "-", "dynamic"], [64, 0, 0, "-", "hparam"], [65, 0, 0, "-", "mode"], [66, 0, 0, "-", "plugins"], [67, 0, 0, "-", "searcher"], [68, 0, 0, "-", "utils"]], "modelopt.torch.opt.config": [[61, 6, 1, "", "ModeloptBaseConfig"], [61, 6, 1, "", "ModeloptBaseRule"], [61, 6, 1, "", "ModeloptBaseRuleConfig"], [61, 4, 1, "", "ModeloptField"], [61, 4, 1, "", "get_kwargs_for_create_model_with_rules"]], "modelopt.torch.opt.config.ModeloptBaseConfig": [[61, 2, 1, "", "get"], [61, 2, 1, "", "get_field_name_from_key"], [61, 2, 1, "", "items"], [61, 2, 1, "", "keys"], [61, 2, 1, "", "model_dump"], [61, 2, 1, "", "model_dump_json"], [61, 2, 1, "", "update"], [61, 2, 1, "", "values"]], "modelopt.torch.opt.config.ModeloptBaseRule": [[61, 2, 1, "", "customize_rule"], [61, 2, 1, "", "get_rule_type"], [61, 2, 1, "", "validate_rule"]], "modelopt.torch.opt.config.ModeloptBaseRuleConfig": [[61, 2, 1, "", "register_default"], [61, 2, 1, "", "unregister_default"]], "modelopt.torch.opt.conversion": [[62, 1, 1, "", "ModeloptStateManager"], [62, 4, 1, "", "apply_mode"], [62, 4, 1, "", "modelopt_state"], [62, 4, 1, "", "restore"], [62, 4, 1, "", "restore_from_modelopt_state"], [62, 4, 1, "", "save"]], "modelopt.torch.opt.conversion.ModeloptStateManager": [[62, 2, 1, "", "__init__"], [62, 2, 1, "", "add_mode"], [62, 2, 1, "", "check_mode"], [62, 2, 1, "", "get_config_class"], [62, 3, 1, "", "has_state"], [62, 2, 1, "", "is_converted"], [62, 3, 1, "", "last_mode"], [62, 2, 1, "", "load_state_dict"], [62, 2, 1, "", "modes_with_states"], [62, 2, 1, "", "state_dict"], [62, 2, 1, "", "transfer_state_dict"], [62, 2, 1, "", "update_last_state_before_new_mode"], [62, 2, 1, "", "update_last_state_before_save"]], "modelopt.torch.opt.dynamic": [[63, 1, 1, "", "DynamicModule"], [63, 1, 1, "", "DynamicSpace"]], "modelopt.torch.opt.dynamic.DynamicModule": [[63, 2, 1, "", "__init__"], [63, 2, 1, "", "convert"], [63, 2, 1, "", "export"], [63, 2, 1, "", "extra_repr"], [63, 2, 1, "", "force_assign"], [63, 2, 1, "", "freeze"], [63, 2, 1, "", "get_hparam"], [63, 2, 1, "", "modify"], [63, 2, 1, "", "named_hparams"], [63, 3, 1, "", "original_cls"], [63, 2, 1, "", "reset_dynamic_attributes"]], "modelopt.torch.opt.dynamic.DynamicSpace": [[63, 2, 1, "", "__init__"], [63, 2, 1, "", "config"], [63, 2, 1, "", "convert_to_dynamic"], [63, 2, 1, "", "export"], [63, 2, 1, "", "get_hparam"], [63, 2, 1, "", "is_configurable"], [63, 2, 1, "", "is_dynamic"], [63, 2, 1, "", "named_dynamic_modules"], [63, 2, 1, "", "named_hparams"], [63, 2, 1, "", "select"], [63, 2, 1, "", "size"]], "modelopt.torch.opt.hparam": [[64, 1, 1, "", "Hparam"]], "modelopt.torch.opt.hparam.Hparam": [[64, 5, 1, "", "ActiveSlice"], [64, 5, 1, "", "Importance"], [64, 5, 1, "", "ImportanceEstimator"], [64, 2, 1, "", "__init__"], [64, 3, 1, "", "active"], [64, 3, 1, "", "active_slice"], [64, 3, 1, "", "choices"], [64, 2, 1, "", "enforce_order"], [64, 3, 1, "", "importance"], [64, 3, 1, "", "is_configurable"], [64, 3, 1, "", "is_sortable"], [64, 3, 1, "", "max"], [64, 3, 1, "", "min"], [64, 3, 1, "", "original"], [64, 2, 1, "", "register_importance"]], "modelopt.torch.opt.searcher": [[67, 1, 1, "", "BaseSearcher"]], "modelopt.torch.opt.searcher.BaseSearcher": [[67, 2, 1, "", "__init__"], [67, 2, 1, "", "after_search"], [67, 2, 1, "", "before_search"], [67, 5, 1, "", "config"], [67, 5, 1, "", "constraints"], [67, 2, 1, "", "construct_forward_loop"], [67, 3, 1, "", "default_search_config"], [67, 3, 1, "", "default_state_dict"], [67, 5, 1, "", "deployment"], [67, 5, 1, "", "dummy_input"], [67, 2, 1, "", "eval_score"], [67, 5, 1, "", "forward_loop"], [67, 3, 1, "", "has_score"], [67, 2, 1, "", "load_search_checkpoint"], [67, 5, 1, "", "model"], [67, 2, 1, "", "reset_search"], [67, 2, 1, "", "run_search"], [67, 2, 1, "", "sanitize_search_config"], [67, 2, 1, "", "save_search_checkpoint"], [67, 2, 1, "", "search"], [67, 2, 1, "", "state_dict"]], "modelopt.torch.opt.utils": [[68, 4, 1, "", "get_hparam"], [68, 4, 1, "", "is_configurable"], [68, 4, 1, "", "is_dynamic"], [68, 4, 1, "", "named_hparams"], [68, 4, 1, "", "search_space_size"]], "modelopt.torch.quantization": [[70, 0, 0, "-", "algorithms"], [71, 0, 0, "-", "calib"], [75, 0, 0, "-", "config"], [76, 0, 0, "-", "conversion"], [77, 0, 0, "-", "extensions"], [78, 0, 0, "-", "mode"], [79, 0, 0, "-", "model_calib"], [80, 0, 0, "-", "model_quant"], [81, 0, 0, "-", "nn"], [94, 0, 0, "-", "optim"], [95, 0, 0, "-", "plugins"], [96, 0, 0, "-", "qtensor"], [100, 0, 0, "-", "quant_modules"], [101, 0, 0, "-", "tensor_quant"], [102, 0, 0, "-", "utils"]], "modelopt.torch.quantization.algorithms": [[70, 1, 1, "", "AutoQuantizeSearcher"], [70, 1, 1, "", "QuantRecipe"], [70, 1, 1, "", "QuantRecipeHparam"]], "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher": [[70, 2, 1, "", "before_search"], [70, 5, 1, "", "candidate_stats"], [70, 3, 1, "", "default_search_config"], [70, 3, 1, "", "default_state_dict"], [70, 2, 1, "", "insert_quant_recipe_hparams"], [70, 2, 1, "", "merge_search_hparam_by_rules"], [70, 5, 1, "", "rules"], [70, 2, 1, "", "run_search"], [70, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.quantization.algorithms.QuantRecipe": [[70, 5, 1, "", "UNSUPPORTED_RECIPES"], [70, 2, 1, "", "__init__"], [70, 3, 1, "", "compression"], [70, 3, 1, "", "config"]], "modelopt.torch.quantization.algorithms.QuantRecipeHparam": [[70, 2, 1, "", "__init__"], [70, 3, 1, "", "active"], [70, 2, 1, "", "link_to"]], "modelopt.torch.quantization.calib": [[72, 0, 0, "-", "calibrator"], [73, 0, 0, "-", "histogram"], [74, 0, 0, "-", "max"]], "modelopt.torch.quantization.calib.histogram": [[73, 1, 1, "", "HistogramCalibrator"], [73, 4, 1, "", "calibrate_weights"]], "modelopt.torch.quantization.calib.histogram.HistogramCalibrator": [[73, 2, 1, "", "__init__"], [73, 2, 1, "", "collect"], [73, 2, 1, "", "compute_amax"], [73, 2, 1, "", "reset"]], "modelopt.torch.quantization.calib.max": [[74, 1, 1, "", "MaxCalibrator"]], "modelopt.torch.quantization.calib.max.MaxCalibrator": [[74, 2, 1, "", "__init__"], [74, 3, 1, "", "amaxs"], [74, 2, 1, "", "collect"], [74, 2, 1, "", "compute_amax"], [74, 2, 1, "", "reset"]], "modelopt.torch.quantization.config": [[75, 6, 1, "", "AWQClipCalibConfig"], [75, 6, 1, "", "AWQFullCalibConfig"], [75, 6, 1, "", "AWQLiteCalibConfig"], [75, 6, 1, "", "MaxCalibConfig"], [75, 6, 1, "", "QuantizeAlgorithmConfig"], [75, 6, 1, "", "QuantizeConfig"], [75, 6, 1, "", "QuantizerAttributeConfig"], [75, 6, 1, "", "RealQuantizeConfig"], [75, 6, 1, "", "SmoothQuantCalibConfig"]], "modelopt.torch.quantization.config.AWQClipCalibConfig": [[75, 7, 1, "", "debug"], [75, 7, 1, "", "max_co_batch_size"], [75, 7, 1, "", "max_tokens_per_batch"], [75, 7, 1, "", "min_clip_ratio"], [75, 7, 1, "", "shrink_step"]], "modelopt.torch.quantization.config.AWQFullCalibConfig": [[75, 7, 1, "", "debug"]], "modelopt.torch.quantization.config.AWQLiteCalibConfig": [[75, 7, 1, "", "alpha_step"], [75, 7, 1, "", "debug"]], "modelopt.torch.quantization.config.QuantizeAlgorithmConfig": [[75, 7, 1, "", "method"]], "modelopt.torch.quantization.config.QuantizeConfig": [[75, 7, 1, "", "algorithm"], [75, 7, 1, "", "quant_cfg"]], "modelopt.torch.quantization.config.QuantizerAttributeConfig": [[75, 7, 1, "", "axis"], [75, 7, 1, "", "block_sizes"], [75, 7, 1, "", "calibrator"], [75, 7, 1, "", "enable"], [75, 7, 1, "", "fake_quant"], [75, 7, 1, "", "learn_amax"], [75, 7, 1, "", "narrow_range"], [75, 7, 1, "", "num_bits"], [75, 7, 1, "", "trt_high_precision_dtype"], [75, 7, 1, "", "type"], [75, 7, 1, "", "unsigned"]], "modelopt.torch.quantization.config.RealQuantizeConfig": [[75, 7, 1, "", "additional_algorithm"]], "modelopt.torch.quantization.config.SmoothQuantCalibConfig": [[75, 7, 1, "", "alpha"]], "modelopt.torch.quantization.conversion": [[76, 4, 1, "", "register"], [76, 4, 1, "", "replace_quant_module"], [76, 4, 1, "", "set_quantizer_attribute"], [76, 4, 1, "", "set_quantizer_by_cfg"], [76, 4, 1, "", "unregister"]], "modelopt.torch.quantization.extensions": [[77, 4, 1, "", "get_cuda_ext"], [77, 4, 1, "", "get_cuda_ext_fp8"]], "modelopt.torch.quantization.mode": [[78, 1, 1, "", "QuantizeExportModeDescriptor"], [78, 1, 1, "", "QuantizeModeDescriptor"]], "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor": [[78, 3, 1, "", "config_class"], [78, 3, 1, "", "convert"], [78, 3, 1, "", "is_export_mode"], [78, 3, 1, "", "name"], [78, 3, 1, "", "restore"]], "modelopt.torch.quantization.mode.QuantizeModeDescriptor": [[78, 3, 1, "", "config_class"], [78, 3, 1, "", "convert"], [78, 3, 1, "", "export_mode"], [78, 3, 1, "", "name"], [78, 3, 1, "", "next_modes"], [78, 3, 1, "", "restore"], [78, 3, 1, "", "update_for_new_mode"], [78, 3, 1, "", "update_for_save"]], "modelopt.torch.quantization.model_calib": [[79, 4, 1, "", "calibrate"], [79, 4, 1, "", "postprocess_amax"]], "modelopt.torch.quantization.model_quant": [[80, 4, 1, "", "auto_quantize"], [80, 4, 1, "", "disable_quantizer"], [80, 4, 1, "", "enable_quantizer"], [80, 4, 1, "", "fold_weight"], [80, 4, 1, "", "print_quant_summary"], [80, 4, 1, "", "quantize"]], "modelopt.torch.quantization.nn": [[82, 0, 0, "-", "functional"], [83, 0, 0, "-", "modules"]], "modelopt.torch.quantization.nn.functional": [[82, 1, 1, "", "ClipFunction"]], "modelopt.torch.quantization.nn.functional.ClipFunction": [[82, 2, 1, "", "backward"], [82, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules": [[84, 0, 0, "-", "clip"], [85, 0, 0, "-", "quant_activations"], [86, 0, 0, "-", "quant_batchnorm"], [87, 0, 0, "-", "quant_conv"], [88, 0, 0, "-", "quant_instancenorm"], [89, 0, 0, "-", "quant_linear"], [90, 0, 0, "-", "quant_module"], [91, 0, 0, "-", "quant_pooling"], [92, 0, 0, "-", "quant_rnn"], [93, 0, 0, "-", "tensor_quantizer"]], "modelopt.torch.quantization.nn.modules.clip": [[84, 1, 1, "", "Clip"]], "modelopt.torch.quantization.nn.modules.clip.Clip": [[84, 2, 1, "", "__init__"], [84, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[87, 5, 1, "", "Conv1d"], [87, 5, 1, "", "Conv2d"], [87, 5, 1, "", "Conv3d"], [87, 5, 1, "", "ConvTranspose1d"], [87, 5, 1, "", "ConvTranspose2d"], [87, 5, 1, "", "ConvTranspose3d"], [87, 1, 1, "", "QuantConv1d"], [87, 1, 1, "", "QuantConv2d"], [87, 1, 1, "", "QuantConv3d"], [87, 1, 1, "", "QuantConvTranspose1d"], [87, 1, 1, "", "QuantConvTranspose2d"], [87, 1, 1, "", "QuantConvTranspose3d"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d": [[87, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d": [[87, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d": [[87, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d": [[87, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d": [[87, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d": [[87, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[88, 1, 1, "", "QuantInstanceNorm1d"], [88, 1, 1, "", "QuantInstanceNorm2d"], [88, 1, 1, "", "QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[89, 5, 1, "", "Linear"], [89, 1, 1, "", "QuantLinear"]], "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear": [[89, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_module": [[90, 1, 1, "", "QuantInputBase"], [90, 1, 1, "", "QuantLinearConvBase"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase": [[90, 5, 1, "", "default_quant_desc_input"], [90, 5, 1, "", "default_quant_desc_output"], [90, 2, 1, "", "forward"], [90, 5, 1, "", "input_quantizer"], [90, 5, 1, "", "output_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase": [[90, 5, 1, "", "default_quant_desc_weight"], [90, 2, 1, "", "forward"], [90, 2, 1, "", "initialize_quantizer_with_dummy_states"], [90, 2, 1, "", "quantize_weight"], [90, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[91, 5, 1, "", "AdaptiveAvgPool1d"], [91, 5, 1, "", "AdaptiveAvgPool2d"], [91, 5, 1, "", "AdaptiveAvgPool3d"], [91, 5, 1, "", "AvgPool1d"], [91, 5, 1, "", "AvgPool2d"], [91, 5, 1, "", "AvgPool3d"], [91, 5, 1, "", "MaxPool1d"], [91, 5, 1, "", "MaxPool2d"], [91, 5, 1, "", "MaxPool3d"], [91, 1, 1, "", "QuantAdaptiveAvgPool1d"], [91, 1, 1, "", "QuantAdaptiveAvgPool2d"], [91, 1, 1, "", "QuantAdaptiveAvgPool3d"], [91, 1, 1, "", "QuantAvgPool1d"], [91, 1, 1, "", "QuantAvgPool2d"], [91, 1, 1, "", "QuantAvgPool3d"], [91, 1, 1, "", "QuantMaxPool1d"], [91, 1, 1, "", "QuantMaxPool2d"], [91, 1, 1, "", "QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_rnn": [[92, 1, 1, "", "QuantRNNBase"], [92, 1, 1, "", "QuantRNNFullBase"], [92, 1, 1, "", "RNNLayerForward"], [92, 1, 1, "", "VFRNNForward"], [92, 4, 1, "", "get_quantized_rnn_layer_forward"], [92, 4, 1, "", "get_quantized_rnn_layer_variable_len_forward"], [92, 4, 1, "", "get_quantized_rnn_layer_variable_len_reverse_forward"], [92, 4, 1, "", "lstm_cell_with_proj"], [92, 4, 1, "", "quantized_cell_forward"]], "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase": [[92, 3, 1, "", "all_input_quantizers_disabled"], [92, 5, 1, "", "default_quant_desc_input"], [92, 5, 1, "", "default_quant_desc_weight"], [92, 2, 1, "", "forward"], [92, 3, 1, "", "functionals_to_replace"], [92, 2, 1, "", "quantize_weight"], [92, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward": [[92, 2, 1, "", "__init__"]], "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward": [[92, 2, 1, "", "__init__"], [92, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[93, 1, 1, "", "SequentialQuantizer"], [93, 1, 1, "", "TensorQuantizer"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer": [[93, 2, 1, "", "__init__"], [93, 2, 1, "", "disable"], [93, 2, 1, "", "get_modelopt_state"], [93, 2, 1, "", "replace_sequential_quantizer_with_single_quantizer"], [93, 2, 1, "", "set_from_attribute_config"], [93, 2, 1, "", "tensor_quantizer_iterator"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer": [[93, 2, 1, "", "__init__"], [93, 3, 1, "", "amax"], [93, 3, 1, "", "axis"], [93, 3, 1, "", "block_sizes"], [93, 2, 1, "", "clean_up_after_set_from_modelopt_state"], [93, 2, 1, "", "dequantize"], [93, 2, 1, "", "disable"], [93, 2, 1, "", "disable_calib"], [93, 2, 1, "", "disable_clip"], [93, 2, 1, "", "disable_quant"], [93, 2, 1, "", "enable"], [93, 2, 1, "", "enable_calib"], [93, 2, 1, "", "enable_clip"], [93, 2, 1, "", "enable_quant"], [93, 2, 1, "", "export_amax"], [93, 2, 1, "", "extra_repr"], [93, 3, 1, "", "fake_quant"], [93, 2, 1, "", "forward"], [93, 2, 1, "", "get_modelopt_state"], [93, 2, 1, "", "init_learn_amax"], [93, 3, 1, "", "is_enabled"], [93, 2, 1, "", "load_calib_amax"], [93, 3, 1, "", "maxbound"], [93, 3, 1, "", "narrow_range"], [93, 3, 1, "", "num_bits"], [93, 3, 1, "", "pre_quant_scale"], [93, 2, 1, "", "reset_amax"], [93, 3, 1, "", "scale"], [93, 2, 1, "", "set_from_attribute_config"], [93, 2, 1, "", "set_from_modelopt_state"], [93, 3, 1, "", "step_size"], [93, 2, 1, "", "sync_amax_across_distributed_group"], [93, 3, 1, "", "trt_high_precision_dtype"], [93, 3, 1, "", "unsigned"]], "modelopt.torch.quantization.optim": [[94, 4, 1, "", "freeze_parameters"], [94, 4, 1, "", "group_parameters"], [94, 4, 1, "", "match_parameters"], [94, 4, 1, "", "quant_weight_inplace"]], "modelopt.torch.quantization.qtensor": [[97, 0, 0, "-", "base_qtensor"], [98, 0, 0, "-", "int4_tensor"], [99, 0, 0, "-", "nf4_tensor"]], "modelopt.torch.quantization.qtensor.base_qtensor": [[97, 1, 1, "", "BaseQuantizedTensor"], [97, 1, 1, "", "QTensorWrapper"]], "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor": [[97, 2, 1, "", "__init__"], [97, 2, 1, "", "dequantize"], [97, 5, 1, "", "original_meta_tensor"], [97, 2, 1, "", "quantize"], [97, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper": [[97, 2, 1, "", "__new__"]], "modelopt.torch.quantization.qtensor.int4_tensor": [[98, 1, 1, "", "INT4QTensor"]], "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor": [[98, 2, 1, "", "dequantize"], [98, 2, 1, "", "quantize"], [98, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.nf4_tensor": [[99, 1, 1, "", "NF4QTensor"]], "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor": [[99, 2, 1, "", "dequantize"], [99, 2, 1, "", "double_quantization"], [99, 2, 1, "", "quantize"], [99, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.quant_modules": [[100, 4, 1, "", "deactivate"], [100, 4, 1, "", "enable_onnx_export"], [100, 4, 1, "", "initialize"]], "modelopt.torch.quantization.tensor_quant": [[101, 1, 1, "", "FakeAffineTensorQuantFunction"], [101, 1, 1, "", "FakeTensorQuantFunction"], [101, 1, 1, "", "LegacyFakeTensorQuantFunction"], [101, 1, 1, "", "ScaledE4M3Function"], [101, 1, 1, "", "TensorQuantFunction"], [101, 4, 1, "", "scaled_e4m3_abstract"]], "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction": [[101, 2, 1, "", "backward"], [101, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction": [[101, 2, 1, "", "backward"], [101, 2, 1, "", "forward"], [101, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction": [[101, 2, 1, "", "backward"], [101, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function": [[101, 2, 1, "", "backward"], [101, 2, 1, "", "forward"], [101, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.TensorQuantFunction": [[101, 2, 1, "", "backward"], [101, 2, 1, "", "forward"], [101, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.utils": [[102, 4, 1, "", "export_torch_mode"], [102, 4, 1, "", "is_quantized"], [102, 4, 1, "", "is_quantized_column_parallel_linear"], [102, 4, 1, "", "is_quantized_layer_with_weight"], [102, 4, 1, "", "is_quantized_row_parallel_linear"], [102, 4, 1, "", "is_torch_library_supported"], [102, 4, 1, "", "reduce_amax"], [102, 4, 1, "", "replace_function"]], "modelopt.torch.sparsity": [[104, 0, 0, "-", "config"], [105, 0, 0, "-", "magnitude"], [106, 0, 0, "-", "mode"], [107, 0, 0, "-", "module"], [108, 0, 0, "-", "plugins"], [109, 0, 0, "-", "searcher"], [110, 0, 0, "-", "sparsegpt"], [111, 0, 0, "-", "sparsification"]], "modelopt.torch.sparsity.config": [[104, 6, 1, "", "ExportSparseConfig"], [104, 6, 1, "", "SparseGPTConfig"], [104, 6, 1, "", "SparseMagnitudeConfig"]], "modelopt.torch.sparsity.config.SparseGPTConfig": [[104, 7, 1, "", "nn_conv2d"], [104, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.config.SparseMagnitudeConfig": [[104, 7, 1, "", "nn_conv2d"], [104, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.magnitude": [[105, 1, 1, "", "MagnitudeSearcher"], [105, 4, 1, "", "compute_valid_1d_patterns"], [105, 4, 1, "", "create_asp_mask"], [105, 4, 1, "", "fill"], [105, 4, 1, "", "get_nmprune_info"], [105, 4, 1, "", "m4n2_1d"], [105, 4, 1, "", "mn_1d_best"], [105, 4, 1, "", "reshape_1d"]], "modelopt.torch.sparsity.mode": [[106, 1, 1, "", "ExportSparseModeDescriptor"], [106, 1, 1, "", "SparseGPTModeDescriptor"], [106, 1, 1, "", "SparseMagnitudeModeDescriptor"], [106, 4, 1, "", "convert_sparse_model"], [106, 4, 1, "", "export_sparse"], [106, 4, 1, "", "restore_export_sparse"], [106, 4, 1, "", "restore_sparse_model"], [106, 4, 1, "", "update_sparse_metadata"]], "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor": [[106, 3, 1, "", "config_class"], [106, 3, 1, "", "convert"], [106, 3, 1, "", "is_export_mode"], [106, 3, 1, "", "name"], [106, 3, 1, "", "restore"]], "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor": [[106, 3, 1, "", "config_class"], [106, 3, 1, "", "name"], [106, 3, 1, "", "search_algorithm"]], "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor": [[106, 3, 1, "", "config_class"], [106, 3, 1, "", "convert"], [106, 3, 1, "", "export_mode"], [106, 3, 1, "", "name"], [106, 3, 1, "", "next_modes"], [106, 3, 1, "", "restore"], [106, 3, 1, "", "search_algorithm"], [106, 3, 1, "", "update_for_new_mode"], [106, 3, 1, "", "update_for_save"]], "modelopt.torch.sparsity.module": [[107, 1, 1, "", "SparseModule"]], "modelopt.torch.sparsity.module.SparseModule": [[107, 2, 1, "", "modify"], [107, 2, 1, "", "set_mask"]], "modelopt.torch.sparsity.searcher": [[109, 1, 1, "", "BaseSparseSearcher"]], "modelopt.torch.sparsity.searcher.BaseSparseSearcher": [[109, 3, 1, "", "default_search_config"], [109, 3, 1, "", "default_state_dict"], [109, 2, 1, "", "run_search"], [109, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.sparsity.sparsegpt": [[110, 1, 1, "", "SparseGPTSearcher"], [110, 4, 1, "", "create_sgpt_mask"], [110, 4, 1, "", "invert"], [110, 4, 1, "", "prepare"]], "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher": [[110, 2, 1, "", "after_search"], [110, 2, 1, "", "before_search"], [110, 3, 1, "", "default_search_config"]], "modelopt.torch.sparsity.sparsification": [[111, 4, 1, "", "export"], [111, 4, 1, "", "sparsify"]], "modelopt.torch.utils": [[113, 0, 0, "-", "cpp_extension"], [114, 0, 0, "-", "dataset_utils"], [115, 0, 0, "-", "distributed"], [116, 0, 0, "-", "graph"], [117, 0, 0, "-", "list"], [118, 0, 0, "-", "logging"], [119, 0, 0, "-", "network"], [120, 0, 0, "-", "perf"], [121, 0, 0, "-", "random"], [122, 0, 0, "-", "tensor"]], "modelopt.torch.utils.cpp_extension": [[113, 4, 1, "", "load_cpp_extension"]], "modelopt.torch.utils.dataset_utils": [[114, 4, 1, "", "create_forward_loop"], [114, 4, 1, "", "get_dataset_dataloader"]], "modelopt.torch.utils.distributed": [[115, 4, 1, "", "backend"], [115, 4, 1, "", "barrier"], [115, 4, 1, "", "get_data_parallel_group"], [115, 4, 1, "", "get_tensor_parallel_group"], [115, 4, 1, "", "is_available"], [115, 4, 1, "", "is_initialized"], [115, 4, 1, "", "is_master"], [115, 4, 1, "", "rank"], [115, 4, 1, "", "set_data_parallel_group"], [115, 4, 1, "", "set_tensor_parallel_group"], [115, 4, 1, "", "size"]], "modelopt.torch.utils.graph": [[116, 4, 1, "", "match"]], "modelopt.torch.utils.list": [[117, 4, 1, "", "list_closest_to_median"], [117, 4, 1, "", "stats"], [117, 4, 1, "", "val2list"], [117, 4, 1, "", "val2tuple"]], "modelopt.torch.utils.logging": [[118, 8, 1, "", "DeprecatedError"], [118, 4, 1, "", "no_stdout"], [118, 4, 1, "", "num2hrb"], [118, 4, 1, "", "print_rank_0"]], "modelopt.torch.utils.network": [[119, 4, 1, "", "compare_dict"], [119, 4, 1, "", "create_param_grad_clear_hook"], [119, 4, 1, "", "get_model_attributes"], [119, 4, 1, "", "get_module_device"], [119, 4, 1, "", "get_same_padding"], [119, 4, 1, "", "init_model_from_model_like"], [119, 4, 1, "", "is_channels_last"], [119, 4, 1, "", "is_parallel"], [119, 4, 1, "", "make_divisible"], [119, 4, 1, "", "model_to"], [119, 4, 1, "", "param_num"], [119, 4, 1, "", "param_num_from_forward"], [119, 4, 1, "", "remove_bn"], [119, 4, 1, "", "run_forward_loop"], [119, 4, 1, "", "set_submodule"], [119, 4, 1, "", "standardize_constructor_args"], [119, 4, 1, "", "standardize_model_args"], [119, 4, 1, "", "standardize_model_like_tuple"], [119, 4, 1, "", "standardize_named_model_args"], [119, 4, 1, "", "unwrap_model"], [119, 4, 1, "", "zero_grad"]], "modelopt.torch.utils.perf": [[120, 1, 1, "", "Timer"], [120, 4, 1, "", "clear_cuda_cache"], [120, 4, 1, "", "get_cuda_memory_stats"], [120, 4, 1, "", "report_memory"]], "modelopt.torch.utils.perf.Timer": [[120, 2, 1, "", "__init__"], [120, 2, 1, "", "start"], [120, 2, 1, "", "stop"]], "modelopt.torch.utils.random": [[121, 4, 1, "", "centroid"], [121, 4, 1, "", "choice"], [121, 4, 1, "", "original"], [121, 4, 1, "", "random"], [121, 4, 1, "", "sample"], [121, 4, 1, "", "shuffle"]], "modelopt.torch.utils.tensor": [[122, 4, 1, "", "numpy_to_torch"], [122, 4, 1, "", "torch_detach"], [122, 4, 1, "", "torch_to"], [122, 4, 1, "", "torch_to_numpy"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:function", "5": "py:attribute", "6": "py:pydantic_model", "7": "py:pydantic_field", "8": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "function", "Python function"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "pydantic_model", "Python model"], "7": ["py", "pydantic_field", "Python field"], "8": ["py", "exception", "Python exception"]}, "titleterms": {"tensorrt": [0, 2], "llm": [0, 18], "deploy": [0, 4, 14], "export": [0, 5, 48], "quantiz": [0, 2, 4, 7, 10, 11, 12, 13, 23, 37, 69, 75], "model": [0, 2, 3, 4, 5, 6, 9, 12, 13, 14, 15], "support": [0, 14], "matrix": 0, "checkpoint": 0, "convert": [0, 8], "github": 1, "exampl": [1, 14, 75], "overview": [2, 8], "nvidia": 2, "optim": [2, 3, 14, 15, 94], "techniqu": 2, "sparsiti": [2, 6, 9, 103], "instal": 3, "system": 3, "requir": [3, 12], "check": 3, "quick": [4, 5, 6], "start": [4, 5, 6, 14], "ptq": [4, 12, 13], "pytorch": [4, 6, 13], "distil": [5, 8, 40, 42], "set": 5, "up": 5, "your": 5, "base": 5, "meta": 5, "dure": 5, "train": [5, 6, 9, 10, 12, 13], "post": [6, 9, 12, 13], "sparsif": [6, 9, 111], "pt": 6, "awar": [6, 10, 13], "sat": 6, "introduct": [8, 9], "integr": 8, "concept": [8, 9, 10], "glossari": 8, "knowledg": 8, "student": 8, "teacher": 8, "loss": [8, 45], "balanc": 8, "soft": 8, "label": 8, "save": 9, "restor": 9, "spars": 9, "structur": 9, "unstructur": 9, "n": 9, "m": 9, "algorithm": [9, 10, 70], "basic": 10, "precis": 10, "format": [10, 75], "scale": 10, "factor": 10, "block": 10, "calibr": [10, 12, 72], "qat": [10, 13], "more": 10, "read": 10, "best": 11, "practic": 11, "choos": 11, "right": 11, "method": 11, "onnx": [12, 21, 37], "beta": 12, "appli": [12, 13], "prepar": 12, "dataset": 12, "call": 12, "function": [12, 82], "deploi": [12, 17], "compar": 12, "perform": 12, "store": 13, "load": 13, "advanc": 13, "topic": 13, "tensorquant": 13, "custom": 13, "config": [13, 41, 61, 75, 104], "modul": [13, 83, 107], "placement": 13, "fast": 13, "evalu": 13, "migrat": 13, "from": 13, "pytorch_quant": 13, "welcom": 14, "modelopt": [14, 16, 37], "document": 14, "get": 14, "guid": 14, "refer": 14, "changelog": 15, "0": 15, "15": 15, "2024": 15, "07": 15, "25": 15, "13": 15, "06": 15, "14": 15, "11": 15, "05": 15, "api": 16, "gener": 19, "nemo_util": 20, "op_typ": 22, "calib_util": 24, "extens": [25, 77], "fp8": 26, "graph_util": 27, "gs_patch": 28, "int4": 29, "int8": 30, "oper": 31, "ort_patch": 32, "ort_util": 33, "partit": 34, "qdq_util": 35, "quant_util": 36, "util": [38, 68, 102, 112], "torch": 39, "distillation_model": 43, "loss_balanc": 44, "mode": [46, 65, 78, 106], "registri": 47, "distribut": [49, 115], "hf_config_map": 50, "layer_util": 51, "model_config": 52, "model_config_export": 53, "model_config_util": 54, "postprocess": 55, "scaling_factor_util": 56, "tensorrt_llm_util": 57, "transformer_engin": 58, "vllm": 59, "opt": 60, "convers": [62, 76], "dynam": 63, "hparam": 64, "plugin": [66, 95, 108], "searcher": [67, 109], "calib": 71, "histogram": 73, "max": 74, "configur": 75, "model_calib": 79, "model_qu": 80, "nn": 81, "clip": 84, "quant_activ": 85, "quant_batchnorm": 86, "quant_conv": 87, "quant_instancenorm": 88, "quant_linear": 89, "quant_modul": [90, 100], "quant_pool": 91, "quant_rnn": 92, "tensor_quant": 93, "qtensor": 96, "base_qtensor": 97, "int4_tensor": 98, "nf4_tensor": 99, "tensor_qu": 101, "magnitud": 105, "sparsegpt": 110, "cpp_extens": 113, "dataset_util": 114, "graph": 116, "list": 117, "log": 118, "network": 119, "perf": 120, "random": 121, "tensor": 122, "contact": 123, "u": 123, "faq": 124, "known": 124, "issu": 124, "1": 124, "potenti": 124, "memori": 124, "leak": 124, "fsdp": 124, "use_orig_param": 124, "true": 124}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"TensorRT-LLM Deployment": [[0, "tensorrt-llm-deployment"]], "Export Quantized Model": [[0, "export-quantized-model"]], "Model support matrix for the TensorRT-LLM checkpoint export": [[0, "id1"]], "Convert to TensorRT-LLM": [[0, "convert-to-tensorrt-llm"]], "GitHub Examples": [[1, "github-examples"]], "Overview": [[2, "overview"], [8, "overview"]], "NVIDIA TensorRT Model Optimizer": [[2, "nvidia-tensorrt-model-optimizer"]], "Techniques": [[2, "techniques"]], "Quantization": [[2, "quantization"], [4, "quantization"], [7, "quantization"]], "Sparsity": [[2, "sparsity"], [6, "sparsity"], [9, "sparsity"]], "Installation": [[3, "installation"]], "System requirements": [[3, "system-requirements"]], "Install Model Optimizer": [[3, "install-model-optimizer"]], "Check installation": [[3, "check-installation"]], "Quick Start: Quantization": [[4, "quick-start-quantization"]], "PTQ for PyTorch models": [[4, "ptq-for-pytorch-models"]], "Deployment": [[4, "deployment"], [14, null]], "Quick Start: Distillation": [[5, "quick-start-distillation"]], "Set up your base models": [[5, "set-up-your-base-models"]], "Set up the meta model": [[5, "set-up-the-meta-model"]], "Distill during training": [[5, "distill-during-training"]], "Export trained model": [[5, "export-trained-model"]], "Quick Start: Sparsity": [[6, "quick-start-sparsity"]], "Post-Training Sparsification (PTS) for PyTorch models": [[6, "post-training-sparsification-pts-for-pytorch-models"]], "Sparsity-aware Training (SAT) for PyTorch models": [[6, "sparsity-aware-training-sat-for-pytorch-models"]], "Distillation": [[8, "distillation"]], "Introduction": [[8, "introduction"], [9, "introduction"]], "Convert and integrate": [[8, "convert-and-integrate"]], "Distillation Concepts": [[8, "distillation-concepts"]], "Glossary": [[8, "id3"]], "Concepts": [[8, "concepts"]], "Knowledge Distillation": [[8, "knowledge-distillation"]], "Student": [[8, "student"]], "Teacher": [[8, "teacher"]], "Distillation loss": [[8, "distillation-loss"]], "Loss Balancer": [[8, "loss-balancer"]], "Soft-label Distillation": [[8, "soft-label-distillation"]], "Post-Training Sparsification": [[9, "post-training-sparsification"]], "Save and restore the sparse model": [[9, "save-and-restore-the-sparse-model"]], "Sparsity Concepts": [[9, "sparsity-concepts"]], "Structured and Unstructured Sparsity": [[9, "structured-and-unstructured-sparsity"]], "N:M Sparsity": [[9, "n-m-sparsity"]], "Sparsification algorithm": [[9, "sparsification-algorithm"]], "Basic Concepts": [[10, "basic-concepts"]], "Precision format": [[10, "precision-format"]], "Scaling factor": [[10, "scaling-factor"]], "Block format": [[10, "block-format"]], "Calibration algorithm": [[10, "calibration-algorithm"]], "Quantization-aware training (QAT)": [[10, "quantization-aware-training-qat"]], "More Readings": [[10, "more-readings"]], "Best practices to choose the right quantization methods": [[11, "best-practices-to-choose-the-right-quantization-methods"]], "ONNX Quantization (Beta)": [[12, "onnx-quantization-beta"]], "Requirements": [[12, "requirements"]], "Apply Post Training Quantization (PTQ)": [[12, "apply-post-training-quantization-ptq"], [13, "apply-post-training-quantization-ptq"]], "Prepare calibration dataset": [[12, "prepare-calibration-dataset"]], "Call PTQ function": [[12, "call-ptq-function"]], "Deploy Quantized ONNX Model": [[12, "deploy-quantized-onnx-model"]], "Compare the performance": [[12, "compare-the-performance"]], "PyTorch Quantization": [[13, "pytorch-quantization"]], "Quantization-aware Training (QAT)": [[13, "quantization-aware-training-qat"]], "Storing and loading quantized model": [[13, "storing-and-loading-quantized-model"]], "Advanced Topics": [[13, "advanced-topics"]], "TensorQuantizer": [[13, "tensorquantizer"]], "Customize quantizer config": [[13, "customize-quantizer-config"]], "Custom quantized module and quantizer placement": [[13, "custom-quantized-module-and-quantizer-placement"]], "Fast evaluation": [[13, "fast-evaluation"]], "Migrate from pytorch_quantization": [[13, "migrate-from-pytorch-quantization"]], "Welcome to Model Optimizer (ModelOpt) documentation!": [[14, "welcome-to-model-optimizer-modelopt-documentation"]], "Getting Started": [[14, null]], "Optimization Guides": [[14, null]], "Examples": [[14, null]], "Reference": [[14, null]], "Support": [[14, null]], "Changelog": [[15, "changelog"]], "Model Optimizer Changelog": [[15, "model-optimizer-changelog"]], "0.15 (2024-07-25)": [[15, "id1"]], "0.13 (2024-06-14)": [[15, "id2"]], "0.11 (2024-05-07)": [[15, "id4"]], "modelopt API": [[16, "modelopt-api"]], "deploy": [[17, "deploy"]], "llm": [[18, "llm"]], "generate": [[19, "generate"]], "nemo_utils": [[20, "nemo-utils"]], "onnx": [[21, "onnx"]], "op_types": [[22, "op-types"]], "quantization": [[23, "quantization"], [69, "quantization"]], "calib_utils": [[24, "calib-utils"]], "extensions": [[25, "extensions"], [77, "extensions"]], "fp8": [[26, "fp8"]], "graph_utils": [[27, "graph-utils"]], "gs_patching": [[28, "gs-patching"]], "int4": [[29, "int4"]], "int8": [[30, "int8"]], "operators": [[31, "operators"]], "ort_patching": [[32, "ort-patching"]], "ort_utils": [[33, "ort-utils"]], "partitioning": [[34, "partitioning"]], "qdq_utils": [[35, "qdq-utils"]], "quant_utils": [[36, "quant-utils"]], "modelopt.onnx.quantization.quantize": [[37, "modelopt-onnx-quantization-quantize"]], "utils": [[38, "utils"], [68, "utils"], [102, "utils"], [112, "utils"]], "torch": [[39, "torch"]], "distill": [[40, "distill"]], "config": [[41, "config"], [61, "config"], [75, "config"], [104, "config"]], "distillation": [[42, "distillation"]], "distillation_model": [[43, "distillation-model"]], "loss_balancers": [[44, "loss-balancers"]], "losses": [[45, "losses"]], "mode": [[46, "mode"], [65, "mode"], [78, "mode"], [106, "mode"]], "registry": [[47, "registry"]], "export": [[48, "export"]], "distribute": [[49, "distribute"]], "hf_config_map": [[50, "hf-config-map"]], "layer_utils": [[51, "layer-utils"]], "model_config": [[52, "model-config"]], "model_config_export": [[53, "model-config-export"]], "model_config_utils": [[54, "model-config-utils"]], "postprocess": [[55, "postprocess"]], "scaling_factor_utils": [[56, "scaling-factor-utils"]], "tensorrt_llm_utils": [[57, "tensorrt-llm-utils"]], "transformer_engine": [[58, "transformer-engine"]], "vllm": [[59, "vllm"]], "opt": [[60, "opt"]], "conversion": [[62, "conversion"], [76, "conversion"]], "dynamic": [[63, "dynamic"]], "hparam": [[64, "hparam"]], "plugins": [[66, "plugins"], [95, "plugins"], [108, "plugins"]], "searcher": [[67, "searcher"], [109, "searcher"]], "algorithms": [[70, "algorithms"]], "calib": [[71, "calib"]], "calibrator": [[72, "calibrator"]], "histogram": [[73, "histogram"]], "max": [[74, "max"]], "Quantization Formats": [[75, "quantization-formats"]], "Quantization Configs": [[75, "quantization-configs"]], "Example Quantization Configurations": [[75, "example-quantization-configurations"]], "model_calib": [[79, "model-calib"]], "model_quant": [[80, "model-quant"]], "nn": [[81, "nn"]], "functional": [[82, "functional"]], "modules": [[83, "modules"]], "clip": [[84, "clip"]], "quant_activations": [[85, "quant-activations"]], "quant_batchnorm": [[86, "quant-batchnorm"]], "quant_conv": [[87, "quant-conv"]], "quant_instancenorm": [[88, "quant-instancenorm"]], "quant_linear": [[89, "quant-linear"]], "quant_module": [[90, "quant-module"]], "quant_pooling": [[91, "quant-pooling"]], "quant_rnn": [[92, "quant-rnn"]], "tensor_quantizer": [[93, "tensor-quantizer"]], "optim": [[94, "optim"]], "qtensor": [[96, "qtensor"]], "base_qtensor": [[97, "base-qtensor"]], "int4_tensor": [[98, "int4-tensor"]], "nf4_tensor": [[99, "nf4-tensor"]], "quant_modules": [[100, "quant-modules"]], "tensor_quant": [[101, "tensor-quant"]], "sparsity": [[103, "sparsity"]], "magnitude": [[105, "magnitude"]], "module": [[107, "module"]], "sparsegpt": [[110, "sparsegpt"]], "sparsification": [[111, "sparsification"]], "cpp_extension": [[113, "cpp-extension"]], "dataset_utils": [[114, "dataset-utils"]], "distributed": [[115, "distributed"]], "graph": [[116, "graph"]], "list": [[117, "list"]], "logging": [[118, "logging"]], "network": [[119, "network"]], "perf": [[120, "perf"]], "random": [[121, "random"]], "tensor": [[122, "tensor"]], "Contact us": [[123, "contact-us"]], "FAQs": [[124, "faqs"]], "Known Issues": [[124, "known-issues"]], "1. Potential memory leak for FSDP with use_orig_params=True": [[124, "potential-memory-leak-for-fsdp-with-use-orig-params-true"]]}, "indexentries": {"modelopt.deploy": [[17, "module-modelopt.deploy"]], "module": [[17, "module-modelopt.deploy"], [18, "module-modelopt.deploy.llm"], [19, "module-modelopt.deploy.llm.generate"], [20, "module-modelopt.deploy.llm.nemo_utils"], [21, "module-modelopt.onnx"], [22, "module-modelopt.onnx.op_types"], [23, "module-modelopt.onnx.quantization"], [24, "module-modelopt.onnx.quantization.calib_utils"], [25, "module-modelopt.onnx.quantization.extensions"], [26, "module-modelopt.onnx.quantization.fp8"], [27, "module-modelopt.onnx.quantization.graph_utils"], [28, "module-modelopt.onnx.quantization.gs_patching"], [29, "module-modelopt.onnx.quantization.int4"], [30, "module-modelopt.onnx.quantization.int8"], [31, "module-modelopt.onnx.quantization.operators"], [32, "module-modelopt.onnx.quantization.ort_patching"], [33, "module-modelopt.onnx.quantization.ort_utils"], [34, "module-modelopt.onnx.quantization.partitioning"], [35, "module-modelopt.onnx.quantization.qdq_utils"], [36, "module-modelopt.onnx.quantization.quant_utils"], [38, "module-modelopt.onnx.utils"], [39, "module-modelopt.torch"], [40, "module-modelopt.torch.distill"], [41, "module-modelopt.torch.distill.config"], [42, "module-modelopt.torch.distill.distillation"], [43, "module-modelopt.torch.distill.distillation_model"], [44, "module-modelopt.torch.distill.loss_balancers"], [45, "module-modelopt.torch.distill.losses"], [46, "module-modelopt.torch.distill.mode"], [47, "module-modelopt.torch.distill.registry"], [48, "module-modelopt.torch.export"], [49, "module-modelopt.torch.export.distribute"], [50, "module-modelopt.torch.export.hf_config_map"], [51, "module-modelopt.torch.export.layer_utils"], [52, "module-modelopt.torch.export.model_config"], [53, "module-modelopt.torch.export.model_config_export"], [54, "module-modelopt.torch.export.model_config_utils"], [55, "module-modelopt.torch.export.postprocess"], [56, "module-modelopt.torch.export.scaling_factor_utils"], [57, "module-modelopt.torch.export.tensorrt_llm_utils"], [58, "module-modelopt.torch.export.transformer_engine"], [59, "module-modelopt.torch.export.vllm"], [60, "module-modelopt.torch.opt"], [61, "module-modelopt.torch.opt.config"], [62, "module-modelopt.torch.opt.conversion"], [63, "module-modelopt.torch.opt.dynamic"], [64, "module-modelopt.torch.opt.hparam"], [65, "module-modelopt.torch.opt.mode"], [66, "module-modelopt.torch.opt.plugins"], [67, "module-modelopt.torch.opt.searcher"], [68, "module-modelopt.torch.opt.utils"], [69, "module-modelopt.torch.quantization"], [70, "module-modelopt.torch.quantization.algorithms"], [71, "module-modelopt.torch.quantization.calib"], [72, "module-modelopt.torch.quantization.calib.calibrator"], [73, "module-modelopt.torch.quantization.calib.histogram"], [74, "module-modelopt.torch.quantization.calib.max"], [75, "module-modelopt.torch.quantization.config"], [76, "module-modelopt.torch.quantization.conversion"], [77, "module-modelopt.torch.quantization.extensions"], [78, "module-modelopt.torch.quantization.mode"], [79, "module-modelopt.torch.quantization.model_calib"], [80, "module-modelopt.torch.quantization.model_quant"], [81, "module-modelopt.torch.quantization.nn"], [82, "module-modelopt.torch.quantization.nn.functional"], [83, "module-modelopt.torch.quantization.nn.modules"], [84, "module-modelopt.torch.quantization.nn.modules.clip"], [85, "module-modelopt.torch.quantization.nn.modules.quant_activations"], [86, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"], [87, "module-modelopt.torch.quantization.nn.modules.quant_conv"], [88, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"], [89, "module-modelopt.torch.quantization.nn.modules.quant_linear"], [90, "module-modelopt.torch.quantization.nn.modules.quant_module"], [91, "module-modelopt.torch.quantization.nn.modules.quant_pooling"], [92, "module-modelopt.torch.quantization.nn.modules.quant_rnn"], [93, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"], [94, "module-modelopt.torch.quantization.optim"], [95, "module-modelopt.torch.quantization.plugins"], [96, "module-modelopt.torch.quantization.qtensor"], [97, "module-modelopt.torch.quantization.qtensor.base_qtensor"], [98, "module-modelopt.torch.quantization.qtensor.int4_tensor"], [99, "module-modelopt.torch.quantization.qtensor.nf4_tensor"], [100, "module-modelopt.torch.quantization.quant_modules"], [101, "module-modelopt.torch.quantization.tensor_quant"], [102, "module-modelopt.torch.quantization.utils"], [103, "module-modelopt.torch.sparsity"], [104, "module-modelopt.torch.sparsity.config"], [105, "module-modelopt.torch.sparsity.magnitude"], [106, "module-modelopt.torch.sparsity.mode"], [107, "module-modelopt.torch.sparsity.module"], [108, "module-modelopt.torch.sparsity.plugins"], [109, "module-modelopt.torch.sparsity.searcher"], [110, "module-modelopt.torch.sparsity.sparsegpt"], [111, "module-modelopt.torch.sparsity.sparsification"], [112, "module-modelopt.torch.utils"], [113, "module-modelopt.torch.utils.cpp_extension"], [114, "module-modelopt.torch.utils.dataset_utils"], [115, "module-modelopt.torch.utils.distributed"], [116, "module-modelopt.torch.utils.graph"], [117, "module-modelopt.torch.utils.list"], [118, "module-modelopt.torch.utils.logging"], [119, "module-modelopt.torch.utils.network"], [120, "module-modelopt.torch.utils.perf"], [121, "module-modelopt.torch.utils.random"], [122, "module-modelopt.torch.utils.tensor"]], "modelopt.deploy.llm": [[18, "module-modelopt.deploy.llm"]], "llm (class in modelopt.deploy.llm.generate)": [[19, "modelopt.deploy.llm.generate.LLM"]], "__init__() (llm method)": [[19, "modelopt.deploy.llm.generate.LLM.__init__"]], "generate_text() (llm method)": [[19, "modelopt.deploy.llm.generate.LLM.generate_text"]], "generate_tokens() (llm method)": [[19, "modelopt.deploy.llm.generate.LLM.generate_tokens"]], "max_beam_width (llm property)": [[19, "modelopt.deploy.llm.generate.LLM.max_beam_width"]], "max_input_len (llm property)": [[19, "modelopt.deploy.llm.generate.LLM.max_input_len"]], "modelopt.deploy.llm.generate": [[19, "module-modelopt.deploy.llm.generate"]], "customsentencepiecetokenizer (class in modelopt.deploy.llm.nemo_utils)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer"]], "__init__() (customsentencepiecetokenizer method)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.__init__"]], "batch_decode() (customsentencepiecetokenizer method)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_decode"]], "batch_encode_plus() (customsentencepiecetokenizer method)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_encode_plus"]], "decode() (customsentencepiecetokenizer method)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.decode"]], "encode() (customsentencepiecetokenizer method)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.encode"]], "eos_token (customsentencepiecetokenizer property)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token"]], "eos_token_id (customsentencepiecetokenizer property)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token_id"]], "get_nemo_tokenizer() (in module modelopt.deploy.llm.nemo_utils)": [[20, "modelopt.deploy.llm.nemo_utils.get_nemo_tokenizer"]], "get_tokenzier() (in module modelopt.deploy.llm.nemo_utils)": [[20, "modelopt.deploy.llm.nemo_utils.get_tokenzier"]], "modelopt.deploy.llm.nemo_utils": [[20, "module-modelopt.deploy.llm.nemo_utils"]], "pad_token (customsentencepiecetokenizer property)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token"]], "pad_token_id (customsentencepiecetokenizer property)": [[20, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token_id"]], "modelopt.onnx": [[21, "module-modelopt.onnx"]], "is_binary_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_binary_op"]], "is_control_flow_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_control_flow_op"]], "is_conversion_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_conversion_op"]], "is_copy_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_copy_op"]], "is_default_quantizable_op_by_ort() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_default_quantizable_op_by_ort"]], "is_fusible_reduction_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_fusible_reduction_op"]], "is_generator_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_generator_op"]], "is_irregular_mem_access_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_irregular_mem_access_op"]], "is_linear_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_linear_op"]], "is_modifier_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_modifier_op"]], "is_multiclass_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_multiclass_op"]], "is_non_reshape_copy_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_non_reshape_copy_op"]], "is_normalization_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_normalization_op"]], "is_pointwise_or_elementwise_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_pointwise_or_elementwise_op"]], "is_pooling_or_window_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_pooling_or_window_op"]], "is_recurrent_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_recurrent_op"]], "is_selection_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_selection_op"]], "is_sequence_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_sequence_op"]], "is_shape_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_shape_op"]], "is_unary_op() (in module modelopt.onnx.op_types)": [[22, "modelopt.onnx.op_types.is_unary_op"]], "modelopt.onnx.op_types": [[22, "module-modelopt.onnx.op_types"]], "modelopt.onnx.quantization": [[23, "module-modelopt.onnx.quantization"]], "calibrationdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[24, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider"]], "randomdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[24, "modelopt.onnx.quantization.calib_utils.RandomDataProvider"]], "__init__() (calibrationdataprovider method)": [[24, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.__init__"]], "__init__() (randomdataprovider method)": [[24, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.__init__"]], "get_next() (calibrationdataprovider method)": [[24, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.get_next"]], "get_next() (randomdataprovider method)": [[24, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.get_next"]], "import_scales_from_calib_cache() (in module modelopt.onnx.quantization.calib_utils)": [[24, "modelopt.onnx.quantization.calib_utils.import_scales_from_calib_cache"]], "modelopt.onnx.quantization.calib_utils": [[24, "module-modelopt.onnx.quantization.calib_utils"]], "modelopt.onnx.quantization.extensions": [[25, "module-modelopt.onnx.quantization.extensions"]], "modelopt.onnx.quantization.fp8": [[26, "module-modelopt.onnx.quantization.fp8"]], "quantize() (in module modelopt.onnx.quantization.fp8)": [[26, "modelopt.onnx.quantization.fp8.quantize"]], "add_fp16_fp32_cast() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast"]], "build_non_residual_input_map() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.build_non_residual_input_map"]], "classify_partition_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.classify_partition_nodes"]], "filter_quantizable_kgen_heads() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads"]], "find_fp8_mha_partitions() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.find_mha_partitions"]], "find_nodes_to_exclude() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude"]], "get_fusible_backbone() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.get_fusible_backbone"]], "has_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.has_const_input"]], "has_path_type() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.has_path_type"]], "insert_fp8_mha_casts() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts"]], "insert_matmul_casts() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.insert_matmul_casts"]], "is_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.is_const_input"]], "modelopt.onnx.quantization.graph_utils": [[27, "module-modelopt.onnx.quantization.graph_utils"]], "print_stat() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.print_stat"]], "remove_partial_input_qdq() (in module modelopt.onnx.quantization.graph_utils)": [[27, "modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[28, "module-modelopt.onnx.quantization.gs_patching"]], "patch_gs_modules() (in module modelopt.onnx.quantization.gs_patching)": [[28, "modelopt.onnx.quantization.gs_patching.patch_gs_modules"]], "awqcliphelper (class in modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.AWQClipHelper"]], "__init__() (awqcliphelper method)": [[29, "modelopt.onnx.quantization.int4.AWQClipHelper.__init__"]], "alpha_step (awqcliphelper attribute)": [[29, "modelopt.onnx.quantization.int4.AWQClipHelper.alpha_step"]], "alphas (awqcliphelper attribute)": [[29, "modelopt.onnx.quantization.int4.AWQClipHelper.alphas"]], "dq_tensor() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.dq_tensor"]], "find_scales() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.find_scales"]], "min_alpha (awqcliphelper attribute)": [[29, "modelopt.onnx.quantization.int4.AWQClipHelper.min_alpha"]], "modelopt.onnx.quantization.int4": [[29, "module-modelopt.onnx.quantization.int4"]], "quant_tensor() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.quant_tensor"]], "quantize() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.quantize"]], "quantize_awq_clip() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.quantize_awq_clip"]], "quantize_rtn() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.quantize_rtn"]], "rtn() (in module modelopt.onnx.quantization.int4)": [[29, "modelopt.onnx.quantization.int4.rtn"]], "update_best_params() (awqcliphelper method)": [[29, "modelopt.onnx.quantization.int4.AWQClipHelper.update_best_params"]], "modelopt.onnx.quantization.int8": [[30, "module-modelopt.onnx.quantization.int8"]], "quantize() (in module modelopt.onnx.quantization.int8)": [[30, "modelopt.onnx.quantization.int8.quantize"]], "qdqconvtranspose (class in modelopt.onnx.quantization.operators)": [[31, "modelopt.onnx.quantization.operators.QDQConvTranspose"]], "qdqnormalization (class in modelopt.onnx.quantization.operators)": [[31, "modelopt.onnx.quantization.operators.QDQNormalization"]], "__init__() (qdqconvtranspose method)": [[31, "modelopt.onnx.quantization.operators.QDQConvTranspose.__init__"]], "__init__() (qdqnormalization method)": [[31, "modelopt.onnx.quantization.operators.QDQNormalization.__init__"]], "modelopt.onnx.quantization.operators": [[31, "module-modelopt.onnx.quantization.operators"]], "quantize() (qdqconvtranspose method)": [[31, "modelopt.onnx.quantization.operators.QDQConvTranspose.quantize"]], "quantize() (qdqnormalization method)": [[31, "modelopt.onnx.quantization.operators.QDQNormalization.quantize"]], "modelopt.onnx.quantization.ort_patching": [[32, "module-modelopt.onnx.quantization.ort_patching"]], "patch_ort_modules() (in module modelopt.onnx.quantization.ort_patching)": [[32, "modelopt.onnx.quantization.ort_patching.patch_ort_modules"]], "configure_ort() (in module modelopt.onnx.quantization.ort_utils)": [[33, "modelopt.onnx.quantization.ort_utils.configure_ort"]], "create_inference_session() (in module modelopt.onnx.quantization.ort_utils)": [[33, "modelopt.onnx.quantization.ort_utils.create_inference_session"]], "get_quantizable_op_types() (in module modelopt.onnx.quantization.ort_utils)": [[33, "modelopt.onnx.quantization.ort_utils.get_quantizable_op_types"]], "modelopt.onnx.quantization.ort_utils": [[33, "module-modelopt.onnx.quantization.ort_utils"]], "find_fusible_partitions() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.find_fusible_partitions"]], "find_hardcoded_patterns() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.find_hardcoded_patterns"]], "find_layer_norm_partitions() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.find_layer_norm_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.find_mha_partitions"]], "find_non_quantizable_partitions_from_patterns() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.find_non_quantizable_partitions_from_patterns"]], "find_quantizable_nodes() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.find_quantizable_nodes"]], "get_skiped_output_layers() (in module modelopt.onnx.quantization.partitioning)": [[34, "modelopt.onnx.quantization.partitioning.get_skiped_output_layers"]], "modelopt.onnx.quantization.partitioning": [[34, "module-modelopt.onnx.quantization.partitioning"]], "insert_dq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.insert_dq_nodes"]], "insert_qdq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.insert_qdq_nodes"]], "make_gs_dequantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_node"]], "make_gs_dequantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_output"]], "make_gs_quantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_node"]], "make_gs_quantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_output"]], "make_gs_quantized_weight() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_quantized_weight"]], "make_gs_scale() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_scale"]], "make_gs_zp() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.make_gs_zp"]], "modelopt.onnx.quantization.qdq_utils": [[35, "module-modelopt.onnx.quantization.qdq_utils"]], "replace_scale_values() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.replace_scale_values"]], "use_trt_qdq_ops() (in module modelopt.onnx.quantization.qdq_utils)": [[35, "modelopt.onnx.quantization.qdq_utils.use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[36, "module-modelopt.onnx.quantization.quant_utils"]], "pack_float32_to_4bit_cpp_based() (in module modelopt.onnx.quantization.quant_utils)": [[36, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_cpp_based"]], "pack_float32_to_4bit_optimized() (in module modelopt.onnx.quantization.quant_utils)": [[36, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_optimized"]], "quantize() (in module modelopt.onnx.quantization)": [[37, "modelopt.onnx.quantization.quantize"]], "duplicate_shared_constants() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.duplicate_shared_constants"]], "find_lowest_common_ancestor() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.find_lowest_common_ancestor"]], "gen_random_inputs() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.gen_random_inputs"]], "get_all_input_names() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_all_input_names"]], "get_batch_size() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_batch_size"]], "get_batch_size_from_bytes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_batch_size_from_bytes"]], "get_child_nodes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_child_nodes"]], "get_input_names() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_input_names"]], "get_input_names_from_bytes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_input_names_from_bytes"]], "get_input_shapes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_input_shapes"]], "get_input_shapes_from_bytes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_input_shapes_from_bytes"]], "get_node_names() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_node_names"]], "get_node_names_from_bytes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_node_names_from_bytes"]], "get_output_names() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_output_names"]], "get_output_names_from_bytes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_output_names_from_bytes"]], "get_output_shapes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_output_shapes"]], "get_parent_nodes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_parent_nodes"]], "get_variable_inputs() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.get_variable_inputs"]], "is_valid_onnx_model() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.is_valid_onnx_model"]], "modelopt.onnx.utils": [[38, "module-modelopt.onnx.utils"]], "name_onnx_nodes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.name_onnx_nodes"]], "randomize_weights() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.randomize_weights"]], "randomize_weights_onnx_bytes() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.randomize_weights_onnx_bytes"]], "remove_weights_data() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.remove_weights_data"]], "save_onnx() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.save_onnx"]], "save_onnx_bytes_to_dir() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.save_onnx_bytes_to_dir"]], "udpate_domain() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.udpate_domain"]], "validate_batch_size() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.validate_batch_size"]], "validate_onnx() (in module modelopt.onnx.utils)": [[38, "modelopt.onnx.utils.validate_onnx"]], "modelopt.torch": [[39, "module-modelopt.torch"]], "modelopt.torch.distill": [[40, "module-modelopt.torch.distill"]], "criterion (kdlossconfig attribute)": [[41, "modelopt.torch.distill.config.KDLossConfig.criterion"]], "expose_minimal_state_dict (kdlossconfig attribute)": [[41, "modelopt.torch.distill.config.KDLossConfig.expose_minimal_state_dict"]], "loss_balancer (kdlossconfig attribute)": [[41, "modelopt.torch.distill.config.KDLossConfig.loss_balancer"]], "model_dump() (kdlossconfig method)": [[41, "modelopt.torch.distill.config.KDLossConfig.model_dump"]], "modelopt.torch.distill.config": [[41, "module-modelopt.torch.distill.config"]], "teacher_model (kdlossconfig attribute)": [[41, "modelopt.torch.distill.config.KDLossConfig.teacher_model"]], "convert() (in module modelopt.torch.distill.distillation)": [[42, "modelopt.torch.distill.distillation.convert"]], "export() (in module modelopt.torch.distill.distillation)": [[42, "modelopt.torch.distill.distillation.export"]], "modelopt.torch.distill.distillation": [[42, "module-modelopt.torch.distill.distillation"]], "distillationmodel (class in modelopt.torch.distill.distillation_model)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel"]], "compute_kd_loss() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.compute_kd_loss"]], "forward() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.forward"]], "hide_loss_modules() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.hide_loss_modules"]], "hide_teacher_model() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.hide_teacher_model"]], "load_state_dict() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.load_state_dict"]], "loss_balancer (distillationmodel property)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.loss_balancer"]], "loss_modules (distillationmodel property)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.loss_modules"]], "modelopt.torch.distill.distillation_model": [[43, "module-modelopt.torch.distill.distillation_model"]], "modify() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.modify"]], "state_dict() (distillationmodel method)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.state_dict"]], "teacher_model (distillationmodel property)": [[43, "modelopt.torch.distill.distillation_model.DistillationModel.teacher_model"]], "distillationlossbalancer (class in modelopt.torch.distill.loss_balancers)": [[44, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer"]], "staticlossbalancer (class in modelopt.torch.distill.loss_balancers)": [[44, "modelopt.torch.distill.loss_balancers.StaticLossBalancer"]], "__init__() (distillationlossbalancer method)": [[44, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.__init__"]], "__init__() (staticlossbalancer method)": [[44, "modelopt.torch.distill.loss_balancers.StaticLossBalancer.__init__"]], "forward() (distillationlossbalancer method)": [[44, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.forward"]], "forward() (staticlossbalancer method)": [[44, "modelopt.torch.distill.loss_balancers.StaticLossBalancer.forward"]], "modelopt.torch.distill.loss_balancers": [[44, "module-modelopt.torch.distill.loss_balancers"]], "set_student_loss_reduction_fn() (distillationlossbalancer method)": [[44, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.set_student_loss_reduction_fn"]], "logitsdistillationloss (class in modelopt.torch.distill.losses)": [[45, "modelopt.torch.distill.losses.LogitsDistillationLoss"]], "mgdloss (class in modelopt.torch.distill.losses)": [[45, "modelopt.torch.distill.losses.MGDLoss"]], "__init__() (logitsdistillationloss method)": [[45, "modelopt.torch.distill.losses.LogitsDistillationLoss.__init__"]], "__init__() (mgdloss method)": [[45, "modelopt.torch.distill.losses.MGDLoss.__init__"]], "forward() (logitsdistillationloss method)": [[45, "modelopt.torch.distill.losses.LogitsDistillationLoss.forward"]], "forward() (mgdloss method)": [[45, "modelopt.torch.distill.losses.MGDLoss.forward"]], "modelopt.torch.distill.losses": [[45, "module-modelopt.torch.distill.losses"]], "exportstudentmodedescriptor (class in modelopt.torch.distill.mode)": [[46, "modelopt.torch.distill.mode.ExportStudentModeDescriptor"]], "knowledgedistillationmodedescriptor (class in modelopt.torch.distill.mode)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor"]], "config_class (exportstudentmodedescriptor property)": [[46, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.config_class"]], "config_class (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.config_class"]], "convert (exportstudentmodedescriptor property)": [[46, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.convert"]], "convert (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.convert"]], "export_mode (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.export_mode"]], "is_export_mode (exportstudentmodedescriptor property)": [[46, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.is_export_mode"]], "modelopt.torch.distill.mode": [[46, "module-modelopt.torch.distill.mode"]], "name (exportstudentmodedescriptor property)": [[46, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.name"]], "name (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.name"]], "next_modes (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.next_modes"]], "restore (exportstudentmodedescriptor property)": [[46, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.restore"]], "restore (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.restore"]], "update_for_new_mode (knowledgedistillationmodedescriptor property)": [[46, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.update_for_new_mode"]], "modelopt.torch.distill.registry": [[47, "module-modelopt.torch.distill.registry"]], "modelopt.torch.export": [[48, "module-modelopt.torch.export"]], "nfsworkspace (class in modelopt.torch.export.distribute)": [[49, "modelopt.torch.export.distribute.NFSWorkspace"]], "__init__() (nfsworkspace method)": [[49, "modelopt.torch.export.distribute.NFSWorkspace.__init__"]], "get_configs_parallel() (in module modelopt.torch.export.distribute)": [[49, "modelopt.torch.export.distribute.get_configs_parallel"]], "get_tensors_parallel() (in module modelopt.torch.export.distribute)": [[49, "modelopt.torch.export.distribute.get_tensors_parallel"]], "is_initialized (nfsworkspace property)": [[49, "modelopt.torch.export.distribute.NFSWorkspace.is_initialized"]], "modelopt.torch.export.distribute": [[49, "module-modelopt.torch.export.distribute"]], "read_configs_and_weights_from_rank() (nfsworkspace method)": [[49, "modelopt.torch.export.distribute.NFSWorkspace.read_configs_and_weights_from_rank"]], "write_configs_and_weights() (nfsworkspace method)": [[49, "modelopt.torch.export.distribute.NFSWorkspace.write_configs_and_weights"]], "modelopt.torch.export.hf_config_map": [[50, "module-modelopt.torch.export.hf_config_map"]], "build_attention_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_attention_config"]], "build_conv_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_conv_config"]], "build_decoder_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_decoder_config"]], "build_embedding_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_embedding_config"]], "build_layernorm_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_layernorm_config"]], "build_linear_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_linear_config"]], "build_medusa_heads_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_medusa_heads_config"]], "build_mlp_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_mlp_config"]], "build_moe_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_moe_config"]], "build_qkv() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_qkv"]], "build_recurrent_config() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_recurrent_config"]], "build_stacked_experts() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.build_stacked_experts"]], "check_model_compatibility() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.check_model_compatibility"]], "get_activation_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_activation_scaling_factor"]], "get_kv_cache_dtype() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_kv_cache_dtype"]], "get_kv_cache_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_kv_cache_scaling_factor"]], "get_prequant_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_prequant_scaling_factor"]], "get_quantization_format() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_quantization_format"]], "get_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_scaling_factor"]], "get_transformer_layers() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_transformer_layers"]], "get_weight_block_size() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_weight_block_size"]], "get_weight_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_weight_scaling_factor"]], "get_weight_scaling_factor_2() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.get_weight_scaling_factor_2"]], "is_attention() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_attention"]], "is_decoder_list() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_decoder_list"]], "is_embedding() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_embedding"]], "is_layernorm() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_layernorm"]], "is_linear() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_linear"]], "is_mlp() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_mlp"]], "is_moe() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_moe"]], "is_quantlinear() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_quantlinear"]], "is_recurrent() (in module modelopt.torch.export.layer_utils)": [[51, "modelopt.torch.export.layer_utils.is_recurrent"]], "modelopt.torch.export.layer_utils": [[51, "module-modelopt.torch.export.layer_utils"]], "attentionconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.AttentionConfig"]], "convconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.ConvConfig"]], "decoderlayerconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig"]], "embeddingconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.EmbeddingConfig"]], "expertconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.ExpertConfig"]], "layernormconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.LayernormConfig"]], "linearactconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.LinearActConfig"]], "linearconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.LinearConfig"]], "mlpconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.MLPConfig"]], "moeconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.MOEConfig"]], "medusaheadconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.MedusaHeadConfig"]], "modelconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.ModelConfig"]], "qkvconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.QKVConfig"]], "recurrentconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.RecurrentConfig"]], "rglruconfig (class in modelopt.torch.export.model_config)": [[52, "modelopt.torch.export.model_config.RgLruConfig"]], "__init__() (attentionconfig method)": [[52, "modelopt.torch.export.model_config.AttentionConfig.__init__"]], "__init__() (convconfig method)": [[52, "modelopt.torch.export.model_config.ConvConfig.__init__"]], "__init__() (decoderlayerconfig method)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.__init__"]], "__init__() (embeddingconfig method)": [[52, "modelopt.torch.export.model_config.EmbeddingConfig.__init__"]], "__init__() (expertconfig method)": [[52, "modelopt.torch.export.model_config.ExpertConfig.__init__"]], "__init__() (layernormconfig method)": [[52, "modelopt.torch.export.model_config.LayernormConfig.__init__"]], "__init__() (linearactconfig method)": [[52, "modelopt.torch.export.model_config.LinearActConfig.__init__"]], "__init__() (linearconfig method)": [[52, "modelopt.torch.export.model_config.LinearConfig.__init__"]], "__init__() (mlpconfig method)": [[52, "modelopt.torch.export.model_config.MLPConfig.__init__"]], "__init__() (moeconfig method)": [[52, "modelopt.torch.export.model_config.MOEConfig.__init__"]], "__init__() (medusaheadconfig method)": [[52, "modelopt.torch.export.model_config.MedusaHeadConfig.__init__"]], "__init__() (modelconfig method)": [[52, "modelopt.torch.export.model_config.ModelConfig.__init__"]], "__init__() (qkvconfig method)": [[52, "modelopt.torch.export.model_config.QKVConfig.__init__"]], "__init__() (recurrentconfig method)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.__init__"]], "__init__() (rglruconfig method)": [[52, "modelopt.torch.export.model_config.RgLruConfig.__init__"]], "activation_scaling_factor (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.activation_scaling_factor"]], "activation_scaling_factor (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.activation_scaling_factor"]], "alibi_bias_max (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.alibi_bias_max"]], "apply_residual_connection_post_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.apply_residual_connection_post_layernorm"]], "attention (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.attention"]], "attention_head_size (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_head_size"]], "attention_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_layernorm"]], "attn_logit_softcapping (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.attn_logit_softcapping"]], "awq_block_size (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.awq_block_size"]], "awq_block_size (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.awq_block_size"]], "bias (convconfig attribute)": [[52, "modelopt.torch.export.model_config.ConvConfig.bias"]], "bias (layernormconfig attribute)": [[52, "modelopt.torch.export.model_config.LayernormConfig.bias"]], "bias (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.bias"]], "bias (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.bias"]], "blocksparse_block_size (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_block_size"]], "blocksparse_homo_head_pattern (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_homo_head_pattern"]], "blocksparse_num_local_blocks (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_num_local_blocks"]], "blocksparse_vertical_stride (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_vertical_stride"]], "clip_qkv (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.clip_qkv"]], "clip_qkv (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.clip_qkv"]], "conv1d (recurrentconfig attribute)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.conv1d"]], "cross_attention (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.cross_attention"]], "cross_attention_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.cross_attention_layernorm"]], "decoder_type (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.decoder_type"]], "dense (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.dense"]], "dense_attention_every_n_layers (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.dense_attention_every_n_layers"]], "dtype (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.dtype"]], "emb_scale_by_sqrt_dim (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.emb_scale_by_sqrt_dim"]], "enc_dec (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.enc_dec"]], "encoder_head_size (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.encoder_head_size"]], "encoder_hidden_size (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.encoder_hidden_size"]], "encoder_num_heads (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.encoder_num_heads"]], "eps (layernormconfig attribute)": [[52, "modelopt.torch.export.model_config.LayernormConfig.eps"]], "experts (moeconfig attribute)": [[52, "modelopt.torch.export.model_config.MOEConfig.experts"]], "fc (expertconfig attribute)": [[52, "modelopt.torch.export.model_config.ExpertConfig.fc"]], "fc (mlpconfig attribute)": [[52, "modelopt.torch.export.model_config.MLPConfig.fc"]], "fc (moeconfig property)": [[52, "modelopt.torch.export.model_config.MOEConfig.fc"]], "ffn_hidden_size_local (decoderlayerconfig property)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.ffn_hidden_size_local"]], "final_logit_softcapping (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.final_logit_softcapping"]], "gate (mlpconfig attribute)": [[52, "modelopt.torch.export.model_config.MLPConfig.gate"]], "gegelu_limit (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.gegelu_limit"]], "hidden_act (linearactconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearActConfig.hidden_act"]], "hidden_act (mlpconfig attribute)": [[52, "modelopt.torch.export.model_config.MLPConfig.hidden_act"]], "hidden_act (moeconfig attribute)": [[52, "modelopt.torch.export.model_config.MOEConfig.hidden_act"]], "hidden_act (modelconfig property)": [[52, "modelopt.torch.export.model_config.ModelConfig.hidden_act"]], "hidden_size (decoderlayerconfig property)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.hidden_size"]], "hidden_size (embeddingconfig property)": [[52, "modelopt.torch.export.model_config.EmbeddingConfig.hidden_size"]], "hidden_size (modelconfig property)": [[52, "modelopt.torch.export.model_config.ModelConfig.hidden_size"]], "input_gate (rglruconfig attribute)": [[52, "modelopt.torch.export.model_config.RgLruConfig.input_gate"]], "input_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.input_layernorm"]], "k (qkvconfig attribute)": [[52, "modelopt.torch.export.model_config.QKVConfig.k"]], "kv_cache_dtype (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_dtype"]], "kv_cache_scaling_factor (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_scaling_factor"]], "layer_types (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.layer_types"]], "layernorm_type (layernormconfig attribute)": [[52, "modelopt.torch.export.model_config.LayernormConfig.layernorm_type"]], "layers (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.layers"]], "linear (linearactconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearActConfig.linear"]], "linear_out (recurrentconfig attribute)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.linear_out"]], "linear_type (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.linear_type"]], "linear_x (recurrentconfig attribute)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.linear_x"]], "linear_y (recurrentconfig attribute)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.linear_y"]], "lm_head (medusaheadconfig attribute)": [[52, "modelopt.torch.export.model_config.MedusaHeadConfig.lm_head"]], "lm_head (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.lm_head"]], "ln_embed (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.ln_embed"]], "ln_f (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.ln_f"]], "local_vocab_size (embeddingconfig property)": [[52, "modelopt.torch.export.model_config.EmbeddingConfig.local_vocab_size"]], "logits_soft_cap (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.logits_soft_cap"]], "longrope_long_mscale (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_long_mscale"]], "longrope_scaling_long_factors (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_scaling_long_factors"]], "longrope_scaling_short_factors (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_scaling_short_factors"]], "longrope_short_mscale (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_short_mscale"]], "max_position_embeddings (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.max_position_embeddings"]], "max_position_embeddings (modelconfig property)": [[52, "modelopt.torch.export.model_config.ModelConfig.max_position_embeddings"]], "medusa_heads (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.medusa_heads"]], "medusa_layers (medusaheadconfig attribute)": [[52, "modelopt.torch.export.model_config.MedusaHeadConfig.medusa_layers"]], "merged_fc1_gate (mlpconfig attribute)": [[52, "modelopt.torch.export.model_config.MLPConfig.merged_fc1_gate"]], "mlp (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp"]], "mlp_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp_layernorm"]], "model_name (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.model_name"]], "modelopt.torch.export.model_config": [[52, "module-modelopt.torch.export.model_config"]], "moe_num_experts (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_num_experts"]], "moe_renorm_mode (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_renorm_mode"]], "moe_top_k (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_top_k"]], "moe_tp_mode (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_tp_mode"]], "mup_attn_multiplier (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_attn_multiplier"]], "mup_embedding_multiplier (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_embedding_multiplier"]], "mup_use_scaling (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_use_scaling"]], "mup_width_multiplier (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_width_multiplier"]], "new_decoder_architecture (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.new_decoder_architecture"]], "num_attention_heads (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.num_attention_heads"]], "num_attention_heads (modelconfig property)": [[52, "modelopt.torch.export.model_config.ModelConfig.num_attention_heads"]], "num_kv_heads (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.num_kv_heads"]], "num_kv_heads (modelconfig property)": [[52, "modelopt.torch.export.model_config.ModelConfig.num_kv_heads"]], "num_medusa_heads (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.num_medusa_heads"]], "num_medusa_layers (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.num_medusa_layers"]], "original_max_position_embeddings (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.original_max_position_embeddings"]], "parallel_attention (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.parallel_attention"]], "partial_rotary_factor (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.partial_rotary_factor"]], "pipeline_parallel (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.pipeline_parallel"]], "position_embedding (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.position_embedding"]], "post_feedforward_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.post_feedforward_layernorm"]], "post_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.post_layernorm"]], "pre_feedforward_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.pre_feedforward_layernorm"]], "prequant_scaling_factor (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.prequant_scaling_factor"]], "prequant_scaling_factor (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.prequant_scaling_factor"]], "proj (expertconfig attribute)": [[52, "modelopt.torch.export.model_config.ExpertConfig.proj"]], "proj (mlpconfig attribute)": [[52, "modelopt.torch.export.model_config.MLPConfig.proj"]], "q (qkvconfig attribute)": [[52, "modelopt.torch.export.model_config.QKVConfig.q"]], "qkv (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.qkv"]], "quantization (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.quantization"]], "quantization (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.quantization"]], "query_pre_attn_scalar (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.query_pre_attn_scalar"]], "qwen_type (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.qwen_type"]], "rank (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.rank"]], "recurrent (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.recurrent"]], "recurrent_gate (rglruconfig attribute)": [[52, "modelopt.torch.export.model_config.RgLruConfig.recurrent_gate"]], "recurrent_param (rglruconfig attribute)": [[52, "modelopt.torch.export.model_config.RgLruConfig.recurrent_param"]], "rel_attn_max_distance (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.rel_attn_max_distance"]], "rel_attn_num_buckets (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.rel_attn_num_buckets"]], "rel_attn_table (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.rel_attn_table"]], "residual_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_layernorm"]], "residual_mlp (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_mlp"]], "rg_lru (recurrentconfig attribute)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.rg_lru"]], "rnn_hidden_size (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.rnn_hidden_size"]], "rope_ratio (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.rope_ratio"]], "rotary_base (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_base"]], "rotary_dim (attentionconfig attribute)": [[52, "modelopt.torch.export.model_config.AttentionConfig.rotary_dim"]], "rotary_pct (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_pct"]], "router (moeconfig attribute)": [[52, "modelopt.torch.export.model_config.MOEConfig.router"]], "self_attention (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.self_attention"]], "self_attention_layernorm (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.self_attention_layernorm"]], "seq_length (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.seq_length"]], "share_embedding_table (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.share_embedding_table"]], "tensor_parallel (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.tensor_parallel"]], "use_alibi (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.use_alibi"]], "use_cache (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.use_cache"]], "use_scaled_rope (decoderlayerconfig attribute)": [[52, "modelopt.torch.export.model_config.DecoderLayerConfig.use_scaled_rope"]], "v (qkvconfig attribute)": [[52, "modelopt.torch.export.model_config.QKVConfig.v"]], "version (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.version"]], "vocab_embedding (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.vocab_embedding"]], "vocab_size (modelconfig attribute)": [[52, "modelopt.torch.export.model_config.ModelConfig.vocab_size"]], "vocab_size_padded (modelconfig property)": [[52, "modelopt.torch.export.model_config.ModelConfig.vocab_size_padded"]], "weight (convconfig attribute)": [[52, "modelopt.torch.export.model_config.ConvConfig.weight"]], "weight (embeddingconfig attribute)": [[52, "modelopt.torch.export.model_config.EmbeddingConfig.weight"]], "weight (layernormconfig attribute)": [[52, "modelopt.torch.export.model_config.LayernormConfig.weight"]], "weight (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.weight"]], "weight (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.weight"]], "weights_scaling_factor (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor"]], "weights_scaling_factor (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor"]], "weights_scaling_factor_2 (linearconfig attribute)": [[52, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor_2"]], "weights_scaling_factor_2 (qkvconfig property)": [[52, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor_2"]], "y_bias (recurrentconfig attribute)": [[52, "modelopt.torch.export.model_config.RecurrentConfig.y_bias"]], "export_hf_checkpoint() (in module modelopt.torch.export.model_config_export)": [[53, "modelopt.torch.export.model_config_export.export_hf_checkpoint"]], "export_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[53, "modelopt.torch.export.model_config_export.export_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_export": [[53, "module-modelopt.torch.export.model_config_export"]], "torch_to_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[53, "modelopt.torch.export.model_config_export.torch_to_tensorrt_llm_checkpoint"]], "from_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.from_quantized_weight"]], "merge_fc1_gate() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.merge_fc1_gate"]], "merge_qkv() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.merge_qkv"]], "model_config_from_dict() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.model_config_from_dict"]], "model_config_to_dict() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.model_config_to_dict"]], "modelopt.torch.export.model_config_utils": [[54, "module-modelopt.torch.export.model_config_utils"]], "naive_quantization() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.naive_quantization"]], "pack_linear_weights() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.pack_linear_weights"]], "pad_weights() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.pad_weights"]], "restore_model_config() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.restore_model_config"]], "split_config_and_weights() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.split_config_and_weights"]], "to_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[54, "modelopt.torch.export.model_config_utils.to_quantized_weight"]], "check_weight_shape_valid() (in module modelopt.torch.export.postprocess)": [[55, "modelopt.torch.export.postprocess.check_weight_shape_valid"]], "modelopt.torch.export.postprocess": [[55, "module-modelopt.torch.export.postprocess"]], "pad_embedding_lm_head() (in module modelopt.torch.export.postprocess)": [[55, "modelopt.torch.export.postprocess.pad_embedding_lm_head"]], "postprocess_model_config() (in module modelopt.torch.export.postprocess)": [[55, "modelopt.torch.export.postprocess.postprocess_model_config"]], "postprocess_tensors() (in module modelopt.torch.export.postprocess)": [[55, "modelopt.torch.export.postprocess.postprocess_tensors"]], "adjust_attn_amax_values() (in module modelopt.torch.export.scaling_factor_utils)": [[56, "modelopt.torch.export.scaling_factor_utils.adjust_attn_amax_values"]], "get_weights_scaling_factor() (in module modelopt.torch.export.scaling_factor_utils)": [[56, "modelopt.torch.export.scaling_factor_utils.get_weights_scaling_factor"]], "modelopt.torch.export.scaling_factor_utils": [[56, "module-modelopt.torch.export.scaling_factor_utils"]], "resmooth_and_get_scale() (in module modelopt.torch.export.scaling_factor_utils)": [[56, "modelopt.torch.export.scaling_factor_utils.resmooth_and_get_scale"]], "convert_to_tensorrt_llm_config() (in module modelopt.torch.export.tensorrt_llm_utils)": [[57, "modelopt.torch.export.tensorrt_llm_utils.convert_to_tensorrt_llm_config"]], "is_tensorrt_llm_0_8_or_9() (in module modelopt.torch.export.tensorrt_llm_utils)": [[57, "modelopt.torch.export.tensorrt_llm_utils.is_tensorrt_llm_0_8_or_9"]], "modelopt.torch.export.tensorrt_llm_utils": [[57, "module-modelopt.torch.export.tensorrt_llm_utils"]], "prepare_enc_dec_decoder_layer() (in module modelopt.torch.export.tensorrt_llm_utils)": [[57, "modelopt.torch.export.tensorrt_llm_utils.prepare_enc_dec_decoder_layer"]], "prepare_enc_dec_export_dir() (in module modelopt.torch.export.tensorrt_llm_utils)": [[57, "modelopt.torch.export.tensorrt_llm_utils.prepare_enc_dec_export_dir"]], "weights_to_npz() (in module modelopt.torch.export.tensorrt_llm_utils)": [[57, "modelopt.torch.export.tensorrt_llm_utils.weights_to_npz"]], "convert_to_transformer_engine() (in module modelopt.torch.export.transformer_engine)": [[58, "modelopt.torch.export.transformer_engine.convert_to_transformer_engine"]], "modelopt.torch.export.transformer_engine": [[58, "module-modelopt.torch.export.transformer_engine"]], "export_to_vllm() (in module modelopt.torch.export.vllm)": [[59, "modelopt.torch.export.vllm.export_to_vllm"]], "modelopt.torch.export.vllm": [[59, "module-modelopt.torch.export.vllm"]], "modelopt.torch.opt": [[60, "module-modelopt.torch.opt"]], "modeloptfield() (in module modelopt.torch.opt.config)": [[61, "modelopt.torch.opt.config.ModeloptField"]], "customize_rule() (modeloptbaserule class method)": [[61, "modelopt.torch.opt.config.ModeloptBaseRule.customize_rule"]], "get() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.get"]], "get_field_name_from_key() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.get_field_name_from_key"]], "get_kwargs_for_create_model_with_rules() (in module modelopt.torch.opt.config)": [[61, "modelopt.torch.opt.config.get_kwargs_for_create_model_with_rules"]], "get_rule_type() (modeloptbaserule class method)": [[61, "modelopt.torch.opt.config.ModeloptBaseRule.get_rule_type"]], "items() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.items"]], "keys() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.keys"]], "model_dump() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump"]], "model_dump_json() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump_json"]], "modelopt.torch.opt.config": [[61, "module-modelopt.torch.opt.config"]], "register_default() (modeloptbaseruleconfig class method)": [[61, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.register_default"]], "unregister_default() (modeloptbaseruleconfig class method)": [[61, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.unregister_default"]], "update() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.update"]], "validate_rule() (modeloptbaserule class method)": [[61, "modelopt.torch.opt.config.ModeloptBaseRule.validate_rule"]], "values() (modeloptbaseconfig method)": [[61, "modelopt.torch.opt.config.ModeloptBaseConfig.values"]], "modeloptstatemanager (class in modelopt.torch.opt.conversion)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager"]], "__init__() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.__init__"]], "add_mode() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.add_mode"]], "apply_mode() (in module modelopt.torch.opt.conversion)": [[62, "modelopt.torch.opt.conversion.apply_mode"]], "check_mode() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.check_mode"]], "get_config_class() (modeloptstatemanager static method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.get_config_class"]], "has_state (modeloptstatemanager property)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.has_state"]], "is_converted() (modeloptstatemanager class method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.is_converted"]], "last_mode (modeloptstatemanager property)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.last_mode"]], "load_state_dict() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.load_state_dict"]], "modelopt.torch.opt.conversion": [[62, "module-modelopt.torch.opt.conversion"]], "modelopt_state() (in module modelopt.torch.opt.conversion)": [[62, "modelopt.torch.opt.conversion.modelopt_state"]], "modes_with_states() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.modes_with_states"]], "restore() (in module modelopt.torch.opt.conversion)": [[62, "modelopt.torch.opt.conversion.restore"]], "restore_from_modelopt_state() (in module modelopt.torch.opt.conversion)": [[62, "modelopt.torch.opt.conversion.restore_from_modelopt_state"]], "save() (in module modelopt.torch.opt.conversion)": [[62, "modelopt.torch.opt.conversion.save"]], "state_dict() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.state_dict"]], "transfer_state_dict() (modeloptstatemanager class method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.transfer_state_dict"]], "update_last_state_before_new_mode() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_new_mode"]], "update_last_state_before_save() (modeloptstatemanager method)": [[62, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_save"]], "dynamicmodule (class in modelopt.torch.opt.dynamic)": [[63, "modelopt.torch.opt.dynamic.DynamicModule"]], "dynamicspace (class in modelopt.torch.opt.dynamic)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace"]], "__init__() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.__init__"]], "__init__() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.__init__"]], "config() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.config"]], "convert() (dynamicmodule class method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.convert"]], "convert_to_dynamic() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.convert_to_dynamic"]], "export() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.export"]], "export() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.export"]], "extra_repr() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.extra_repr"]], "force_assign() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.force_assign"]], "freeze() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.freeze"]], "get_hparam() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.get_hparam"]], "get_hparam() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.get_hparam"]], "is_configurable() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.is_configurable"]], "is_dynamic() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.is_dynamic"]], "modelopt.torch.opt.dynamic": [[63, "module-modelopt.torch.opt.dynamic"]], "modify() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.modify"]], "named_dynamic_modules() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.named_dynamic_modules"]], "named_hparams() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.named_hparams"]], "named_hparams() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.named_hparams"]], "original_cls (dynamicmodule property)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.original_cls"]], "reset_dynamic_attributes() (dynamicmodule method)": [[63, "modelopt.torch.opt.dynamic.DynamicModule.reset_dynamic_attributes"]], "select() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.select"]], "size() (dynamicspace method)": [[63, "modelopt.torch.opt.dynamic.DynamicSpace.size"]], "activeslice (hparam attribute)": [[64, "modelopt.torch.opt.hparam.Hparam.ActiveSlice"]], "hparam (class in modelopt.torch.opt.hparam)": [[64, "modelopt.torch.opt.hparam.Hparam"]], "importance (hparam attribute)": [[64, "modelopt.torch.opt.hparam.Hparam.Importance"]], "importanceestimator (hparam attribute)": [[64, "modelopt.torch.opt.hparam.Hparam.ImportanceEstimator"]], "__init__() (hparam method)": [[64, "modelopt.torch.opt.hparam.Hparam.__init__"]], "active (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.active"]], "active_slice (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.active_slice"]], "choices (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.choices"]], "enforce_order() (hparam method)": [[64, "modelopt.torch.opt.hparam.Hparam.enforce_order"]], "importance (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.importance"]], "is_configurable (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.is_configurable"]], "is_sortable (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.is_sortable"]], "max (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.max"]], "min (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.min"]], "modelopt.torch.opt.hparam": [[64, "module-modelopt.torch.opt.hparam"]], "original (hparam property)": [[64, "modelopt.torch.opt.hparam.Hparam.original"]], "register_importance() (hparam method)": [[64, "modelopt.torch.opt.hparam.Hparam.register_importance"]], "modelopt.torch.opt.mode": [[65, "module-modelopt.torch.opt.mode"]], "modelopt.torch.opt.plugins": [[66, "module-modelopt.torch.opt.plugins"]], "basesearcher (class in modelopt.torch.opt.searcher)": [[67, "modelopt.torch.opt.searcher.BaseSearcher"]], "__init__() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.__init__"]], "after_search() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.after_search"]], "before_search() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.before_search"]], "config (basesearcher attribute)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.config"]], "constraints (basesearcher attribute)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.constraints"]], "construct_forward_loop() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.construct_forward_loop"]], "default_search_config (basesearcher property)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.default_search_config"]], "default_state_dict (basesearcher property)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.default_state_dict"]], "deployment (basesearcher attribute)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.deployment"]], "dummy_input (basesearcher attribute)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.dummy_input"]], "eval_score() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.eval_score"]], "forward_loop (basesearcher attribute)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.forward_loop"]], "has_score (basesearcher property)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.has_score"]], "load_search_checkpoint() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.load_search_checkpoint"]], "model (basesearcher attribute)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.model"]], "modelopt.torch.opt.searcher": [[67, "module-modelopt.torch.opt.searcher"]], "reset_search() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.reset_search"]], "run_search() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.run_search"]], "sanitize_search_config() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.sanitize_search_config"]], "save_search_checkpoint() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.save_search_checkpoint"]], "search() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.search"]], "state_dict() (basesearcher method)": [[67, "modelopt.torch.opt.searcher.BaseSearcher.state_dict"]], "get_hparam() (in module modelopt.torch.opt.utils)": [[68, "modelopt.torch.opt.utils.get_hparam"]], "is_configurable() (in module modelopt.torch.opt.utils)": [[68, "modelopt.torch.opt.utils.is_configurable"]], "is_dynamic() (in module modelopt.torch.opt.utils)": [[68, "modelopt.torch.opt.utils.is_dynamic"]], "modelopt.torch.opt.utils": [[68, "module-modelopt.torch.opt.utils"]], "named_hparams() (in module modelopt.torch.opt.utils)": [[68, "modelopt.torch.opt.utils.named_hparams"]], "search_space_size() (in module modelopt.torch.opt.utils)": [[68, "modelopt.torch.opt.utils.search_space_size"]], "modelopt.torch.quantization": [[69, "module-modelopt.torch.quantization"]], "autoquantizesearcher (class in modelopt.torch.quantization.algorithms)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher"]], "quantrecipe (class in modelopt.torch.quantization.algorithms)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipe"]], "quantrecipehparam (class in modelopt.torch.quantization.algorithms)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipeHparam"]], "unsupported_recipes (quantrecipe attribute)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipe.UNSUPPORTED_RECIPES"]], "__init__() (quantrecipe method)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipe.__init__"]], "__init__() (quantrecipehparam method)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.__init__"]], "active (quantrecipehparam property)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.active"]], "before_search() (autoquantizesearcher method)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.before_search"]], "candidate_stats (autoquantizesearcher attribute)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.candidate_stats"]], "compression (quantrecipe property)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipe.compression"]], "config (quantrecipe property)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipe.config"]], "default_search_config (autoquantizesearcher property)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.default_search_config"]], "default_state_dict (autoquantizesearcher property)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.default_state_dict"]], "insert_quant_recipe_hparams() (autoquantizesearcher class method)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.insert_quant_recipe_hparams"]], "link_to() (quantrecipehparam method)": [[70, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.link_to"]], "merge_search_hparam_by_rules() (autoquantizesearcher class method)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.merge_search_hparam_by_rules"]], "modelopt.torch.quantization.algorithms": [[70, "module-modelopt.torch.quantization.algorithms"]], "rules (autoquantizesearcher attribute)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.rules"]], "run_search() (autoquantizesearcher method)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.run_search"]], "sanitize_search_config() (autoquantizesearcher method)": [[70, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.sanitize_search_config"]], "modelopt.torch.quantization.calib": [[71, "module-modelopt.torch.quantization.calib"]], "modelopt.torch.quantization.calib.calibrator": [[72, "module-modelopt.torch.quantization.calib.calibrator"]], "histogramcalibrator (class in modelopt.torch.quantization.calib.histogram)": [[73, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator"]], "__init__() (histogramcalibrator method)": [[73, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.__init__"]], "calibrate_weights() (in module modelopt.torch.quantization.calib.histogram)": [[73, "modelopt.torch.quantization.calib.histogram.calibrate_weights"]], "collect() (histogramcalibrator method)": [[73, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.collect"]], "compute_amax() (histogramcalibrator method)": [[73, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.histogram": [[73, "module-modelopt.torch.quantization.calib.histogram"]], "reset() (histogramcalibrator method)": [[73, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.reset"]], "maxcalibrator (class in modelopt.torch.quantization.calib.max)": [[74, "modelopt.torch.quantization.calib.max.MaxCalibrator"]], "__init__() (maxcalibrator method)": [[74, "modelopt.torch.quantization.calib.max.MaxCalibrator.__init__"]], "amaxs (maxcalibrator property)": [[74, "modelopt.torch.quantization.calib.max.MaxCalibrator.amaxs"]], "collect() (maxcalibrator method)": [[74, "modelopt.torch.quantization.calib.max.MaxCalibrator.collect"]], "compute_amax() (maxcalibrator method)": [[74, "modelopt.torch.quantization.calib.max.MaxCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.max": [[74, "module-modelopt.torch.quantization.calib.max"]], "reset() (maxcalibrator method)": [[74, "modelopt.torch.quantization.calib.max.MaxCalibrator.reset"]], "additional_algorithm (realquantizeconfig attribute)": [[75, "modelopt.torch.quantization.config.RealQuantizeConfig.additional_algorithm"]], "algorithm (quantizeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizeConfig.algorithm"]], "alpha (smoothquantcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.SmoothQuantCalibConfig.alpha"]], "alpha_step (awqlitecalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQLiteCalibConfig.alpha_step"]], "axis (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.axis"]], "block_sizes (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.block_sizes"]], "calibrator (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.calibrator"]], "debug (awqclipcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQClipCalibConfig.debug"]], "debug (awqfullcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQFullCalibConfig.debug"]], "debug (awqlitecalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQLiteCalibConfig.debug"]], "enable (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.enable"]], "fake_quant (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.fake_quant"]], "learn_amax (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.learn_amax"]], "max_co_batch_size (awqclipcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQClipCalibConfig.max_co_batch_size"]], "max_tokens_per_batch (awqclipcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQClipCalibConfig.max_tokens_per_batch"]], "method (quantizealgorithmconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizeAlgorithmConfig.method"]], "min_clip_ratio (awqclipcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQClipCalibConfig.min_clip_ratio"]], "modelopt.torch.quantization.config": [[75, "module-modelopt.torch.quantization.config"]], "narrow_range (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.narrow_range"]], "num_bits (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.num_bits"]], "quant_cfg (quantizeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizeConfig.quant_cfg"]], "shrink_step (awqclipcalibconfig attribute)": [[75, "modelopt.torch.quantization.config.AWQClipCalibConfig.shrink_step"]], "trt_high_precision_dtype (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.trt_high_precision_dtype"]], "type (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.type"]], "unsigned (quantizerattributeconfig attribute)": [[75, "modelopt.torch.quantization.config.QuantizerAttributeConfig.unsigned"]], "modelopt.torch.quantization.conversion": [[76, "module-modelopt.torch.quantization.conversion"]], "register() (in module modelopt.torch.quantization.conversion)": [[76, "modelopt.torch.quantization.conversion.register"]], "replace_quant_module() (in module modelopt.torch.quantization.conversion)": [[76, "modelopt.torch.quantization.conversion.replace_quant_module"]], "set_quantizer_attribute() (in module modelopt.torch.quantization.conversion)": [[76, "modelopt.torch.quantization.conversion.set_quantizer_attribute"]], "set_quantizer_by_cfg() (in module modelopt.torch.quantization.conversion)": [[76, "modelopt.torch.quantization.conversion.set_quantizer_by_cfg"]], "unregister() (in module modelopt.torch.quantization.conversion)": [[76, "modelopt.torch.quantization.conversion.unregister"]], "get_cuda_ext() (in module modelopt.torch.quantization.extensions)": [[77, "modelopt.torch.quantization.extensions.get_cuda_ext"]], "get_cuda_ext_fp8() (in module modelopt.torch.quantization.extensions)": [[77, "modelopt.torch.quantization.extensions.get_cuda_ext_fp8"]], "modelopt.torch.quantization.extensions": [[77, "module-modelopt.torch.quantization.extensions"]], "quantizeexportmodedescriptor (class in modelopt.torch.quantization.mode)": [[78, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor"]], "quantizemodedescriptor (class in modelopt.torch.quantization.mode)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor"]], "config_class (quantizeexportmodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.config_class"]], "config_class (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.config_class"]], "convert (quantizeexportmodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.convert"]], "convert (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.convert"]], "export_mode (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.export_mode"]], "is_export_mode (quantizeexportmodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.is_export_mode"]], "modelopt.torch.quantization.mode": [[78, "module-modelopt.torch.quantization.mode"]], "name (quantizeexportmodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.name"]], "name (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.name"]], "next_modes (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.next_modes"]], "restore (quantizeexportmodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.restore"]], "restore (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.restore"]], "update_for_new_mode (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_new_mode"]], "update_for_save (quantizemodedescriptor property)": [[78, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_save"]], "calibrate() (in module modelopt.torch.quantization.model_calib)": [[79, "modelopt.torch.quantization.model_calib.calibrate"]], "modelopt.torch.quantization.model_calib": [[79, "module-modelopt.torch.quantization.model_calib"]], "postprocess_amax() (in module modelopt.torch.quantization.model_calib)": [[79, "modelopt.torch.quantization.model_calib.postprocess_amax"]], "auto_quantize() (in module modelopt.torch.quantization.model_quant)": [[80, "modelopt.torch.quantization.model_quant.auto_quantize"]], "disable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[80, "modelopt.torch.quantization.model_quant.disable_quantizer"]], "enable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[80, "modelopt.torch.quantization.model_quant.enable_quantizer"]], "fold_weight() (in module modelopt.torch.quantization.model_quant)": [[80, "modelopt.torch.quantization.model_quant.fold_weight"]], "modelopt.torch.quantization.model_quant": [[80, "module-modelopt.torch.quantization.model_quant"]], "print_quant_summary() (in module modelopt.torch.quantization.model_quant)": [[80, "modelopt.torch.quantization.model_quant.print_quant_summary"]], "quantize() (in module modelopt.torch.quantization.model_quant)": [[80, "modelopt.torch.quantization.model_quant.quantize"]], "modelopt.torch.quantization.nn": [[81, "module-modelopt.torch.quantization.nn"]], "clipfunction (class in modelopt.torch.quantization.nn.functional)": [[82, "modelopt.torch.quantization.nn.functional.ClipFunction"]], "backward() (clipfunction static method)": [[82, "modelopt.torch.quantization.nn.functional.ClipFunction.backward"]], "forward() (clipfunction static method)": [[82, "modelopt.torch.quantization.nn.functional.ClipFunction.forward"]], "modelopt.torch.quantization.nn.functional": [[82, "module-modelopt.torch.quantization.nn.functional"]], "modelopt.torch.quantization.nn.modules": [[83, "module-modelopt.torch.quantization.nn.modules"]], "clip (class in modelopt.torch.quantization.nn.modules.clip)": [[84, "modelopt.torch.quantization.nn.modules.clip.Clip"]], "__init__() (clip method)": [[84, "modelopt.torch.quantization.nn.modules.clip.Clip.__init__"]], "forward() (clip method)": [[84, "modelopt.torch.quantization.nn.modules.clip.Clip.forward"]], "modelopt.torch.quantization.nn.modules.clip": [[84, "module-modelopt.torch.quantization.nn.modules.clip"]], "modelopt.torch.quantization.nn.modules.quant_activations": [[85, "module-modelopt.torch.quantization.nn.modules.quant_activations"]], "modelopt.torch.quantization.nn.modules.quant_batchnorm": [[86, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"]], "conv1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.Conv1d"]], "conv2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.Conv2d"]], "conv3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.Conv3d"]], "convtranspose1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose1d"]], "convtranspose2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose2d"]], "convtranspose3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose3d"]], "quantconv1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d"]], "quantconv2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d"]], "quantconv3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d"]], "quantconvtranspose1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d"]], "quantconvtranspose2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d"]], "quantconvtranspose3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d"]], "default_quant_desc_weight (quantconv1d attribute)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv2d attribute)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv3d attribute)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose1d attribute)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose2d attribute)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose3d attribute)": [[87, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[87, "module-modelopt.torch.quantization.nn.modules.quant_conv"]], "quantinstancenorm1d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[88, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm1d"]], "quantinstancenorm2d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[88, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm2d"]], "quantinstancenorm3d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[88, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[88, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"]], "linear (in module modelopt.torch.quantization.nn.modules.quant_linear)": [[89, "modelopt.torch.quantization.nn.modules.quant_linear.Linear"]], "quantlinear (class in modelopt.torch.quantization.nn.modules.quant_linear)": [[89, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear"]], "default_quant_desc_weight (quantlinear attribute)": [[89, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[89, "module-modelopt.torch.quantization.nn.modules.quant_linear"]], "quantinputbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase"]], "quantlinearconvbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase"]], "default_quant_desc_input (quantinputbase attribute)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_input"]], "default_quant_desc_output (quantinputbase attribute)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_output"]], "default_quant_desc_weight (quantlinearconvbase attribute)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.default_quant_desc_weight"]], "forward() (quantinputbase method)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.forward"]], "forward() (quantlinearconvbase method)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.forward"]], "initialize_quantizer_with_dummy_states() (quantlinearconvbase static method)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.initialize_quantizer_with_dummy_states"]], "input_quantizer (quantinputbase attribute)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.input_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module": [[90, "module-modelopt.torch.quantization.nn.modules.quant_module"]], "output_quantizer (quantinputbase attribute)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.output_quantizer"]], "quantize_weight() (quantlinearconvbase method)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.quantize_weight"]], "weight_quantizer (quantlinearconvbase attribute)": [[90, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.weight_quantizer"]], "adaptiveavgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool1d"]], "adaptiveavgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool2d"]], "adaptiveavgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool3d"]], "avgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool1d"]], "avgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool2d"]], "avgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool3d"]], "maxpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool1d"]], "maxpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool2d"]], "maxpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool3d"]], "quantadaptiveavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool1d"]], "quantadaptiveavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool2d"]], "quantadaptiveavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool3d"]], "quantavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool1d"]], "quantavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool2d"]], "quantavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool3d"]], "quantmaxpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool1d"]], "quantmaxpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool2d"]], "quantmaxpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[91, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[91, "module-modelopt.torch.quantization.nn.modules.quant_pooling"]], "quantrnnbase (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase"]], "quantrnnfullbase (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNFullBase"]], "rnnlayerforward (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward"]], "vfrnnforward (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward"]], "__init__() (rnnlayerforward method)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward.__init__"]], "__init__() (vfrnnforward method)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward.__init__"]], "all_input_quantizers_disabled (quantrnnbase property)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.all_input_quantizers_disabled"]], "default_quant_desc_input (quantrnnbase attribute)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.default_quant_desc_input"]], "default_quant_desc_weight (quantrnnbase attribute)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.default_quant_desc_weight"]], "forward() (quantrnnbase method)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.forward"]], "forward() (vfrnnforward method)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward.forward"]], "functionals_to_replace (quantrnnbase property)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.functionals_to_replace"]], "get_quantized_rnn_layer_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_forward"]], "get_quantized_rnn_layer_variable_len_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_variable_len_forward"]], "get_quantized_rnn_layer_variable_len_reverse_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_variable_len_reverse_forward"]], "lstm_cell_with_proj() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.lstm_cell_with_proj"]], "modelopt.torch.quantization.nn.modules.quant_rnn": [[92, "module-modelopt.torch.quantization.nn.modules.quant_rnn"]], "quantize_weight() (quantrnnbase method)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.quantize_weight"]], "quantized_cell_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.quantized_cell_forward"]], "weight_quantizer (quantrnnbase attribute)": [[92, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.weight_quantizer"]], "sequentialquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer"]], "tensorquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer"]], "__init__() (sequentialquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.__init__"]], "__init__() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.__init__"]], "amax (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.amax"]], "axis (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.axis"]], "block_sizes (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.block_sizes"]], "clean_up_after_set_from_modelopt_state() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.clean_up_after_set_from_modelopt_state"]], "dequantize() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.dequantize"]], "disable() (sequentialquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.disable"]], "disable() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable"]], "disable_calib() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_calib"]], "disable_clip() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_clip"]], "disable_quant() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_quant"]], "enable() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable"]], "enable_calib() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_calib"]], "enable_clip() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_clip"]], "enable_quant() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_quant"]], "export_amax() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.export_amax"]], "extra_repr() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.extra_repr"]], "fake_quant (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.fake_quant"]], "forward() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.forward"]], "get_modelopt_state() (sequentialquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.get_modelopt_state"]], "get_modelopt_state() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.get_modelopt_state"]], "init_learn_amax() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.init_learn_amax"]], "is_enabled (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.is_enabled"]], "load_calib_amax() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.load_calib_amax"]], "maxbound (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.maxbound"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[93, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"]], "narrow_range (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.narrow_range"]], "num_bits (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.num_bits"]], "pre_quant_scale (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.pre_quant_scale"]], "replace_sequential_quantizer_with_single_quantizer() (sequentialquantizer static method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.replace_sequential_quantizer_with_single_quantizer"]], "reset_amax() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.reset_amax"]], "scale (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.scale"]], "set_from_attribute_config() (sequentialquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.set_from_attribute_config"]], "set_from_attribute_config() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_attribute_config"]], "set_from_modelopt_state() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_modelopt_state"]], "step_size (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.step_size"]], "sync_amax_across_distributed_group() (tensorquantizer method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.sync_amax_across_distributed_group"]], "tensor_quantizer_iterator() (sequentialquantizer static method)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.tensor_quantizer_iterator"]], "trt_high_precision_dtype (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.trt_high_precision_dtype"]], "unsigned (tensorquantizer property)": [[93, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.unsigned"]], "freeze_parameters() (in module modelopt.torch.quantization.optim)": [[94, "modelopt.torch.quantization.optim.freeze_parameters"]], "group_parameters() (in module modelopt.torch.quantization.optim)": [[94, "modelopt.torch.quantization.optim.group_parameters"]], "match_parameters() (in module modelopt.torch.quantization.optim)": [[94, "modelopt.torch.quantization.optim.match_parameters"]], "modelopt.torch.quantization.optim": [[94, "module-modelopt.torch.quantization.optim"]], "quant_weight_inplace() (in module modelopt.torch.quantization.optim)": [[94, "modelopt.torch.quantization.optim.quant_weight_inplace"]], "modelopt.torch.quantization.plugins": [[95, "module-modelopt.torch.quantization.plugins"]], "modelopt.torch.quantization.qtensor": [[96, "module-modelopt.torch.quantization.qtensor"]], "basequantizedtensor (class in modelopt.torch.quantization.qtensor.base_qtensor)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor"]], "qtensorwrapper (class in modelopt.torch.quantization.qtensor.base_qtensor)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper"]], "__init__() (basequantizedtensor method)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.__init__"]], "__new__() (qtensorwrapper static method)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper.__new__"]], "dequantize() (basequantizedtensor method)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.dequantize"]], "modelopt.torch.quantization.qtensor.base_qtensor": [[97, "module-modelopt.torch.quantization.qtensor.base_qtensor"]], "original_meta_tensor (basequantizedtensor attribute)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.original_meta_tensor"]], "quantize() (basequantizedtensor class method)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.quantize"]], "quantized_data (basequantizedtensor attribute)": [[97, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.quantized_data"]], "int4qtensor (class in modelopt.torch.quantization.qtensor.int4_tensor)": [[98, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor"]], "dequantize() (int4qtensor method)": [[98, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.dequantize"]], "modelopt.torch.quantization.qtensor.int4_tensor": [[98, "module-modelopt.torch.quantization.qtensor.int4_tensor"]], "quantize() (int4qtensor class method)": [[98, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.quantize"]], "quantized_data (int4qtensor attribute)": [[98, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.quantized_data"]], "nf4qtensor (class in modelopt.torch.quantization.qtensor.nf4_tensor)": [[99, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor"]], "dequantize() (nf4qtensor method)": [[99, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.dequantize"]], "double_quantization() (nf4qtensor class method)": [[99, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.double_quantization"]], "modelopt.torch.quantization.qtensor.nf4_tensor": [[99, "module-modelopt.torch.quantization.qtensor.nf4_tensor"]], "quantize() (nf4qtensor class method)": [[99, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.quantize"]], "quantized_data (nf4qtensor attribute)": [[99, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.quantized_data"]], "deactivate() (in module modelopt.torch.quantization.quant_modules)": [[100, "modelopt.torch.quantization.quant_modules.deactivate"]], "enable_onnx_export() (in module modelopt.torch.quantization.quant_modules)": [[100, "modelopt.torch.quantization.quant_modules.enable_onnx_export"]], "initialize() (in module modelopt.torch.quantization.quant_modules)": [[100, "modelopt.torch.quantization.quant_modules.initialize"]], "modelopt.torch.quantization.quant_modules": [[100, "module-modelopt.torch.quantization.quant_modules"]], "fakeaffinetensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[101, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction"]], "faketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[101, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction"]], "legacyfaketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[101, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction"]], "scalede4m3function (class in modelopt.torch.quantization.tensor_quant)": [[101, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function"]], "tensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[101, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction"]], "backward() (fakeaffinetensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.backward"]], "backward() (faketensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.backward"]], "backward() (legacyfaketensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.backward"]], "backward() (scalede4m3function static method)": [[101, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.backward"]], "backward() (tensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.backward"]], "forward() (fakeaffinetensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.forward"]], "forward() (faketensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.forward"]], "forward() (legacyfaketensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.forward"]], "forward() (scalede4m3function static method)": [[101, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.forward"]], "forward() (tensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.forward"]], "modelopt.torch.quantization.tensor_quant": [[101, "module-modelopt.torch.quantization.tensor_quant"]], "scaled_e4m3_abstract() (in module modelopt.torch.quantization.tensor_quant)": [[101, "modelopt.torch.quantization.tensor_quant.scaled_e4m3_abstract"]], "symbolic() (faketensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.symbolic"]], "symbolic() (scalede4m3function static method)": [[101, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.symbolic"]], "symbolic() (tensorquantfunction static method)": [[101, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.symbolic"]], "export_torch_mode() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.export_torch_mode"]], "is_quantized() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.is_quantized"]], "is_quantized_column_parallel_linear() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.is_quantized_column_parallel_linear"]], "is_quantized_layer_with_weight() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.is_quantized_layer_with_weight"]], "is_quantized_row_parallel_linear() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.is_quantized_row_parallel_linear"]], "is_torch_library_supported() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.is_torch_library_supported"]], "modelopt.torch.quantization.utils": [[102, "module-modelopt.torch.quantization.utils"]], "reduce_amax() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.reduce_amax"]], "replace_function() (in module modelopt.torch.quantization.utils)": [[102, "modelopt.torch.quantization.utils.replace_function"]], "modelopt.torch.sparsity": [[103, "module-modelopt.torch.sparsity"]], "modelopt.torch.sparsity.config": [[104, "module-modelopt.torch.sparsity.config"]], "nn_conv2d (sparsegptconfig attribute)": [[104, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_conv2d"]], "nn_conv2d (sparsemagnitudeconfig attribute)": [[104, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_conv2d"]], "nn_linear (sparsegptconfig attribute)": [[104, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_linear"]], "nn_linear (sparsemagnitudeconfig attribute)": [[104, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_linear"]], "magnitudesearcher (class in modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.MagnitudeSearcher"]], "compute_valid_1d_patterns() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.compute_valid_1d_patterns"]], "create_asp_mask() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.create_asp_mask"]], "fill() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.fill"]], "get_nmprune_info() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.get_nmprune_info"]], "m4n2_1d() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.m4n2_1d"]], "mn_1d_best() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.mn_1d_best"]], "modelopt.torch.sparsity.magnitude": [[105, "module-modelopt.torch.sparsity.magnitude"]], "reshape_1d() (in module modelopt.torch.sparsity.magnitude)": [[105, "modelopt.torch.sparsity.magnitude.reshape_1d"]], "exportsparsemodedescriptor (class in modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor"]], "sparsegptmodedescriptor (class in modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor"]], "sparsemagnitudemodedescriptor (class in modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor"]], "config_class (exportsparsemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.config_class"]], "config_class (sparsegptmodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.config_class"]], "config_class (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.config_class"]], "convert (exportsparsemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.convert"]], "convert (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.convert"]], "convert_sparse_model() (in module modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.convert_sparse_model"]], "export_mode (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.export_mode"]], "export_sparse() (in module modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.export_sparse"]], "is_export_mode (exportsparsemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.is_export_mode"]], "modelopt.torch.sparsity.mode": [[106, "module-modelopt.torch.sparsity.mode"]], "name (exportsparsemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.name"]], "name (sparsegptmodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.name"]], "name (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.name"]], "next_modes (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.next_modes"]], "restore (exportsparsemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.restore"]], "restore (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.restore"]], "restore_export_sparse() (in module modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.restore_export_sparse"]], "restore_sparse_model() (in module modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.restore_sparse_model"]], "search_algorithm (sparsegptmodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.search_algorithm"]], "search_algorithm (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.search_algorithm"]], "update_for_new_mode (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_new_mode"]], "update_for_save (sparsemagnitudemodedescriptor property)": [[106, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_save"]], "update_sparse_metadata() (in module modelopt.torch.sparsity.mode)": [[106, "modelopt.torch.sparsity.mode.update_sparse_metadata"]], "sparsemodule (class in modelopt.torch.sparsity.module)": [[107, "modelopt.torch.sparsity.module.SparseModule"]], "modelopt.torch.sparsity.module": [[107, "module-modelopt.torch.sparsity.module"]], "modify() (sparsemodule method)": [[107, "modelopt.torch.sparsity.module.SparseModule.modify"]], "set_mask() (sparsemodule method)": [[107, "modelopt.torch.sparsity.module.SparseModule.set_mask"]], "modelopt.torch.sparsity.plugins": [[108, "module-modelopt.torch.sparsity.plugins"]], "basesparsesearcher (class in modelopt.torch.sparsity.searcher)": [[109, "modelopt.torch.sparsity.searcher.BaseSparseSearcher"]], "default_search_config (basesparsesearcher property)": [[109, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_search_config"]], "default_state_dict (basesparsesearcher property)": [[109, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_state_dict"]], "modelopt.torch.sparsity.searcher": [[109, "module-modelopt.torch.sparsity.searcher"]], "run_search() (basesparsesearcher method)": [[109, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.run_search"]], "sanitize_search_config() (basesparsesearcher method)": [[109, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.sanitize_search_config"]], "sparsegptsearcher (class in modelopt.torch.sparsity.sparsegpt)": [[110, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher"]], "after_search() (sparsegptsearcher method)": [[110, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.after_search"]], "before_search() (sparsegptsearcher method)": [[110, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.before_search"]], "create_sgpt_mask() (in module modelopt.torch.sparsity.sparsegpt)": [[110, "modelopt.torch.sparsity.sparsegpt.create_sgpt_mask"]], "default_search_config (sparsegptsearcher property)": [[110, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.default_search_config"]], "invert() (in module modelopt.torch.sparsity.sparsegpt)": [[110, "modelopt.torch.sparsity.sparsegpt.invert"]], "modelopt.torch.sparsity.sparsegpt": [[110, "module-modelopt.torch.sparsity.sparsegpt"]], "prepare() (in module modelopt.torch.sparsity.sparsegpt)": [[110, "modelopt.torch.sparsity.sparsegpt.prepare"]], "export() (in module modelopt.torch.sparsity.sparsification)": [[111, "modelopt.torch.sparsity.sparsification.export"]], "modelopt.torch.sparsity.sparsification": [[111, "module-modelopt.torch.sparsity.sparsification"]], "sparsify() (in module modelopt.torch.sparsity.sparsification)": [[111, "modelopt.torch.sparsity.sparsification.sparsify"]], "modelopt.torch.utils": [[112, "module-modelopt.torch.utils"]], "load_cpp_extension() (in module modelopt.torch.utils.cpp_extension)": [[113, "modelopt.torch.utils.cpp_extension.load_cpp_extension"]], "modelopt.torch.utils.cpp_extension": [[113, "module-modelopt.torch.utils.cpp_extension"]], "create_forward_loop() (in module modelopt.torch.utils.dataset_utils)": [[114, "modelopt.torch.utils.dataset_utils.create_forward_loop"]], "get_dataset_dataloader() (in module modelopt.torch.utils.dataset_utils)": [[114, "modelopt.torch.utils.dataset_utils.get_dataset_dataloader"]], "modelopt.torch.utils.dataset_utils": [[114, "module-modelopt.torch.utils.dataset_utils"]], "backend() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.backend"]], "barrier() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.barrier"]], "get_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.get_data_parallel_group"]], "get_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.get_tensor_parallel_group"]], "is_available() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.is_available"]], "is_initialized() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.is_initialized"]], "is_master() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.is_master"]], "modelopt.torch.utils.distributed": [[115, "module-modelopt.torch.utils.distributed"]], "rank() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.rank"]], "set_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.set_data_parallel_group"]], "set_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.set_tensor_parallel_group"]], "size() (in module modelopt.torch.utils.distributed)": [[115, "modelopt.torch.utils.distributed.size"]], "match() (in module modelopt.torch.utils.graph)": [[116, "modelopt.torch.utils.graph.match"]], "modelopt.torch.utils.graph": [[116, "module-modelopt.torch.utils.graph"]], "list_closest_to_median() (in module modelopt.torch.utils.list)": [[117, "modelopt.torch.utils.list.list_closest_to_median"]], "modelopt.torch.utils.list": [[117, "module-modelopt.torch.utils.list"]], "stats() (in module modelopt.torch.utils.list)": [[117, "modelopt.torch.utils.list.stats"]], "val2list() (in module modelopt.torch.utils.list)": [[117, "modelopt.torch.utils.list.val2list"]], "val2tuple() (in module modelopt.torch.utils.list)": [[117, "modelopt.torch.utils.list.val2tuple"]], "deprecatederror": [[118, "modelopt.torch.utils.logging.DeprecatedError"]], "modelopt.torch.utils.logging": [[118, "module-modelopt.torch.utils.logging"]], "no_stdout() (in module modelopt.torch.utils.logging)": [[118, "modelopt.torch.utils.logging.no_stdout"]], "num2hrb() (in module modelopt.torch.utils.logging)": [[118, "modelopt.torch.utils.logging.num2hrb"]], "print_rank_0() (in module modelopt.torch.utils.logging)": [[118, "modelopt.torch.utils.logging.print_rank_0"]], "compare_dict() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.compare_dict"]], "create_param_grad_clear_hook() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.create_param_grad_clear_hook"]], "get_model_attributes() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.get_model_attributes"]], "get_module_device() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.get_module_device"]], "get_same_padding() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.get_same_padding"]], "init_model_from_model_like() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.init_model_from_model_like"]], "is_channels_last() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.is_channels_last"]], "is_parallel() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.is_parallel"]], "make_divisible() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.make_divisible"]], "model_to() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.model_to"]], "modelopt.torch.utils.network": [[119, "module-modelopt.torch.utils.network"]], "param_num() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.param_num"]], "param_num_from_forward() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.param_num_from_forward"]], "remove_bn() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.remove_bn"]], "run_forward_loop() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.run_forward_loop"]], "set_submodule() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.set_submodule"]], "standardize_constructor_args() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.standardize_constructor_args"]], "standardize_model_args() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.standardize_model_args"]], "standardize_model_like_tuple() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.standardize_model_like_tuple"]], "standardize_named_model_args() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.standardize_named_model_args"]], "unwrap_model() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.unwrap_model"]], "zero_grad() (in module modelopt.torch.utils.network)": [[119, "modelopt.torch.utils.network.zero_grad"]], "timer (class in modelopt.torch.utils.perf)": [[120, "modelopt.torch.utils.perf.Timer"]], "__init__() (timer method)": [[120, "modelopt.torch.utils.perf.Timer.__init__"]], "clear_cuda_cache() (in module modelopt.torch.utils.perf)": [[120, "modelopt.torch.utils.perf.clear_cuda_cache"]], "get_cuda_memory_stats() (in module modelopt.torch.utils.perf)": [[120, "modelopt.torch.utils.perf.get_cuda_memory_stats"]], "modelopt.torch.utils.perf": [[120, "module-modelopt.torch.utils.perf"]], "report_memory() (in module modelopt.torch.utils.perf)": [[120, "modelopt.torch.utils.perf.report_memory"]], "start() (timer method)": [[120, "modelopt.torch.utils.perf.Timer.start"]], "stop() (timer method)": [[120, "modelopt.torch.utils.perf.Timer.stop"]], "centroid() (in module modelopt.torch.utils.random)": [[121, "modelopt.torch.utils.random.centroid"]], "choice() (in module modelopt.torch.utils.random)": [[121, "modelopt.torch.utils.random.choice"]], "modelopt.torch.utils.random": [[121, "module-modelopt.torch.utils.random"]], "original() (in module modelopt.torch.utils.random)": [[121, "modelopt.torch.utils.random.original"]], "random() (in module modelopt.torch.utils.random)": [[121, "modelopt.torch.utils.random.random"]], "sample() (in module modelopt.torch.utils.random)": [[121, "modelopt.torch.utils.random.sample"]], "shuffle() (in module modelopt.torch.utils.random)": [[121, "modelopt.torch.utils.random.shuffle"]], "modelopt.torch.utils.tensor": [[122, "module-modelopt.torch.utils.tensor"]], "numpy_to_torch() (in module modelopt.torch.utils.tensor)": [[122, "modelopt.torch.utils.tensor.numpy_to_torch"]], "torch_detach() (in module modelopt.torch.utils.tensor)": [[122, "modelopt.torch.utils.tensor.torch_detach"]], "torch_to() (in module modelopt.torch.utils.tensor)": [[122, "modelopt.torch.utils.tensor.torch_to"]], "torch_to_numpy() (in module modelopt.torch.utils.tensor)": [[122, "modelopt.torch.utils.tensor.torch_to_numpy"]]}})